{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pymongo\n",
    "import tweepy\n",
    "\n",
    "with open('consumer_key.txt', 'r') as f:\n",
    "    consumer_key =  f.read()\n",
    "f.closed\n",
    "\n",
    "with open('consumer_secret.txt', 'r') as f:\n",
    "    consumer_secret = f.read()\n",
    "f.closed\n",
    "\n",
    "with open('access_key.txt', 'r') as f:\n",
    "    access_key = f.read()\n",
    "f.closed\n",
    "\n",
    "with open('access_secret.txt', 'r') as f:\n",
    "     access_secret = f.read()\n",
    "f.closed\n",
    "\n",
    "# Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key[:-1], consumer_secret[:-1])\n",
    "auth.set_access_token(access_key[:-1], access_secret[:-1])\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Test access\n",
    "\n",
    "USER_NAME = \"nurietta_17\"\n",
    "user = api.get_user(id=USER_NAME)\n",
    "user = user._json\n",
    "print (user['verified'])\n",
    "#print(json.dumps([user._json], sort_keys=True, indent=4, separators=(',',':')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected successfully!!!\n"
     ]
    }
   ],
   "source": [
    "# Connect with mongodb\n",
    "\n",
    "try:\n",
    "    with open(\"credentials.txt\", 'r', encoding='utf-8') as f:\n",
    "        [name,password,url,dbname]=f.read().splitlines()\n",
    "        conn=pymongo.MongoClient(\"mongodb://{}:{}@{}/{}\".format(name,password,url,dbname))\n",
    "    print (\"Connected successfully!!!\")\n",
    "except pymongo.errors.ConnectionFailure as e:\n",
    "    print (\"Could not connect to MongoDB: %s\" % e) \n",
    "    \n",
    "\n",
    "    \n",
    "db = conn['tweempact']\n",
    "collection = db['tweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n",
      "98\n"
     ]
    }
   ],
   "source": [
    "# Find 100 actual tweets located in Spain to store its user in mlab\n",
    "\n",
    "#collection = db['tweet_users']\n",
    "    \n",
    "search_results =api.search(q='*', geocode='39.3262345,-4.8380649,750km', count=100, lang='es')\n",
    "\n",
    "json_users = []\n",
    "print(len(search_results))\n",
    "for i in search_results:\n",
    "    document = i._json\n",
    "    #collection.insert_one(document)\n",
    "    document['id'] = str(document['id'])\n",
    "    json_users.append(document)\n",
    "    \n",
    "print(len(json_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_users' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f82f0ad77d07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnew_users\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_users\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mjson_users\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_users\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_users' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "new_users = new_users + json_users\n",
    "print(len(new_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pymongo.cursor.Cursor object at 0x7f4e25bc5d68>\n"
     ]
    }
   ],
   "source": [
    "# Get all the tweets stored in the collection \"tweet_users\" in mlab\n",
    "\n",
    "cursor = collection.find()\n",
    "print(cursor)\n",
    "\n",
    "# Obtain json \n",
    "json_docs = []\n",
    "for doc in cursor:\n",
    "    doc['_id'] = str(doc['_id'])\n",
    "    json_docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"_id\":\"5bd4a79db4c0e32bc7f902b1\",\n",
      "        \"contributors\":null,\n",
      "        \"coordinates\":null,\n",
      "        \"created_at\":\"Sat Oct 27 17:59:42 +0000 2018\",\n",
      "        \"entities\":{\n",
      "            \"hashtags\":[],\n",
      "            \"symbols\":[],\n",
      "            \"urls\":[],\n",
      "            \"user_mentions\":[\n",
      "                {\n",
      "                    \"id\":1031950877387620358,\n",
      "                    \"id_str\":\"1031950877387620358\",\n",
      "                    \"indices\":[\n",
      "                        0,\n",
      "                        11\n",
      "                    ],\n",
      "                    \"name\":\"spooky yume\\ud83d\\udd77\",\n",
      "                    \"screen_name\":\"__yumecchi\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"favorite_count\":0,\n",
      "        \"favorited\":false,\n",
      "        \"geo\":null,\n",
      "        \"id\":1056244057838641152,\n",
      "        \"id_str\":\"1056244057838641152\",\n",
      "        \"in_reply_to_screen_name\":\"__yumecchi\",\n",
      "        \"in_reply_to_status_id\":1056234978965626881,\n",
      "        \"in_reply_to_status_id_str\":\"1056234978965626881\",\n",
      "        \"in_reply_to_user_id\":1031950877387620358,\n",
      "        \"in_reply_to_user_id_str\":\"1031950877387620358\",\n",
      "        \"is_quote_status\":false,\n",
      "        \"lang\":\"es\",\n",
      "        \"metadata\":{\n",
      "            \"iso_language_code\":\"es\",\n",
      "            \"result_type\":\"recent\"\n",
      "        },\n",
      "        \"place\":null,\n",
      "        \"retweet_count\":0,\n",
      "        \"retweeted\":false,\n",
      "        \"source\":\"<a href=\\\"http://twitter.com\\\" rel=\\\"nofollow\\\">Twitter Web Client</a>\",\n",
      "        \"text\":\"@__yumecchi si q morbo\",\n",
      "        \"truncated\":false,\n",
      "        \"user\":{\n",
      "            \"contributors_enabled\":false,\n",
      "            \"created_at\":\"Tue Oct 28 16:21:57 +0000 2014\",\n",
      "            \"default_profile\":false,\n",
      "            \"default_profile_image\":false,\n",
      "            \"description\":\"\\u26a7 \\ud835\\udd24\\ud835\\udd2c\\ud835\\udd2c\\ud835\\udd21 \\ud835\\udd23\\ud835\\udd2c\\ud835\\udd2f \\ud835\\udd36\\ud835\\udd2c\\ud835\\udd32 \\u02d7\\u02cf\\u02cb @uglygothwannabe \\u02ce\\u02ca\\u02d7 \\ud83d\\udce8: dantedelosheros@gmail.com \\u3164\\u3164\",\n",
      "            \"entities\":{\n",
      "                \"description\":{\n",
      "                    \"urls\":[]\n",
      "                },\n",
      "                \"url\":{\n",
      "                    \"urls\":[\n",
      "                        {\n",
      "                            \"display_url\":\"listography.com/htgaywm\",\n",
      "                            \"expanded_url\":\"http://listography.com/htgaywm\",\n",
      "                            \"indices\":[\n",
      "                                0,\n",
      "                                23\n",
      "                            ],\n",
      "                            \"url\":\"https://t.co/QneVjDdjrv\"\n",
      "                        }\n",
      "                    ]\n",
      "                }\n",
      "            },\n",
      "            \"favourites_count\":30971,\n",
      "            \"follow_request_sent\":false,\n",
      "            \"followers_count\":369,\n",
      "            \"following\":false,\n",
      "            \"friends_count\":147,\n",
      "            \"geo_enabled\":false,\n",
      "            \"has_extended_profile\":true,\n",
      "            \"id\":2848383333,\n",
      "            \"id_str\":\"2848383333\",\n",
      "            \"is_translation_enabled\":false,\n",
      "            \"is_translator\":false,\n",
      "            \"lang\":\"es\",\n",
      "            \"listed_count\":11,\n",
      "            \"location\":\"Granada, Espa\\u00f1a\",\n",
      "            \"name\":\"dante\",\n",
      "            \"notifications\":false,\n",
      "            \"profile_background_color\":\"FFFFFF\",\n",
      "            \"profile_background_image_url\":\"http://abs.twimg.com/images/themes/theme1/bg.png\",\n",
      "            \"profile_background_image_url_https\":\"https://abs.twimg.com/images/themes/theme1/bg.png\",\n",
      "            \"profile_background_tile\":true,\n",
      "            \"profile_banner_url\":\"https://pbs.twimg.com/profile_banners/2848383333/1538994569\",\n",
      "            \"profile_image_url\":\"http://pbs.twimg.com/profile_images/1049245284495179776/Wvb4-JsG_normal.jpg\",\n",
      "            \"profile_image_url_https\":\"https://pbs.twimg.com/profile_images/1049245284495179776/Wvb4-JsG_normal.jpg\",\n",
      "            \"profile_link_color\":\"9E8FA5\",\n",
      "            \"profile_sidebar_border_color\":\"000000\",\n",
      "            \"profile_sidebar_fill_color\":\"000000\",\n",
      "            \"profile_text_color\":\"000000\",\n",
      "            \"profile_use_background_image\":true,\n",
      "            \"protected\":false,\n",
      "            \"screen_name\":\"deadzino\",\n",
      "            \"statuses_count\":24534,\n",
      "            \"time_zone\":null,\n",
      "            \"translator_type\":\"regular\",\n",
      "            \"url\":\"https://t.co/QneVjDdjrv\",\n",
      "            \"utc_offset\":null,\n",
      "            \"verified\":false\n",
      "        }\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Data format (uploaded to mlab in \"tweet_users\" collection)\n",
    "\n",
    "print(json.dumps([json_docs[0]], sort_keys=True, indent=4, separators=(',',':')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get all the usernames\n",
    "\n",
    "user_names = []\n",
    "\n",
    "for doc in json_users:\n",
    "    user_names.append(doc['user']['screen_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(user_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278\n"
     ]
    }
   ],
   "source": [
    "# Number of unique users found\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "user_names = set(user_names)\n",
    "print(len(user_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "antpogar\n",
      "DarylMaldonado\n",
      "menesess_pau\n",
      "Ura2019\n",
      "commiesans\n",
      "Yerbaalawita\n",
      "Kaytxar\n",
      "I3Aunizar\n",
      "GracielaLpez5\n",
      "Nurya1952\n",
      "Angelmg90\n",
      "_asgxv\n",
      "AlvatrosPubli\n",
      "thefromthetree\n",
      "irinaa_ce\n",
      "AlfredoRstrepo\n",
      "annasazzle\n",
      "EfectoCognitivo\n",
      "morbologo75\n",
      "igsan_madr\n",
      "gabinavarros\n",
      "cmnoya60\n",
      "gp_victor89\n",
      "salvaglnet\n",
      "Mildred12279353\n",
      "ElChikitoGH\n",
      "MonWoW_\n",
      "FerreroEU\n",
      "ciudadanodmund\n",
      "angelapeke16\n",
      "minnervaa\n",
      "chag_hai\n",
      "LeiretxoP\n",
      "firecrackerx\n",
      "AnaJorgegon\n",
      "Jusesantos28\n",
      "RotaDatos\n",
      "victordejotamar\n",
      "Postematico\n",
      "JaraTirado\n",
      "cristinetavg\n",
      "Nutriguia\n",
      "Victor_Corso\n",
      "CarolinaSarrion\n",
      "luciagarcia02\n",
      "aragonradio\n",
      "juanflm\n",
      "AjXirivella\n",
      "inmaCR\n",
      "AngelLargo1970\n",
      "Bea_sotelo\n",
      "ShadowsNessa\n",
      "Infinito81\n",
      "DiscosRuidosos\n",
      "pato_albert\n",
      "mercedesslopez8\n",
      "pipio44\n",
      "vmezadelc\n",
      "KateAusten5\n",
      "Egarcamp111\n",
      "InboxPublicitat\n",
      "esguilu\n",
      "SoniaGonzlezSa2\n",
      "anndrxa_\n",
      "angusticlavio\n",
      "elvictorjuan\n",
      "COMENTANDOGHVI2\n",
      "Salem_Lombardi\n",
      "liberal_mirada\n",
      "anaisleali\n",
      "LaNaveMadrid\n",
      "negociosyempren\n",
      "Themeele\n",
      "jpa1968fr\n",
      "jaimitollamas\n",
      "EJASOabogados\n",
      "AEHCOS\n",
      "firelovesrain\n",
      "JoseLui24493852\n",
      "cafes_eguia\n",
      "ElChikitoGH\n",
      "SenorSherry\n",
      "JAMonzon\n",
      "GigioGFX\n",
      "TCATCMAH\n",
      "Irekofitness\n",
      "vamp_rook\n",
      "nocuenhistorias\n",
      "KKanibal_\n",
      "monisotoc_\n",
      "farafiuu\n",
      "SraFloripondia\n",
      "dansanphoto\n",
      "Varvara_98\n",
      "UtreraPodemos\n",
      "Egarcamp111\n",
      "Carlos_BF_\n",
      "oneliaso\n",
      "democraticwines\n",
      "giselaro55\n"
     ]
    }
   ],
   "source": [
    "# Get 25 tweets of each user until 30th of September of 2018\n",
    "\n",
    "import time\n",
    "\n",
    "#MAX_ID = 1046439836939415562 # 30 of September\n",
    "MAX_ID = 1055786926802898945 # 26 of October\n",
    "\n",
    "all_tweets = []\n",
    "\n",
    "for user in user_names:\n",
    "    \n",
    "    try:\n",
    "        new_tweets = api.user_timeline(screen_name=user, count=25, max_id = MAX_ID)\n",
    "        \n",
    "    except tweepy.RateLimitError:\n",
    "        print('Rate limit error with user: %s' % user)\n",
    "        time.sleep(120)\n",
    "        continue\n",
    "    \n",
    "    except tweepy.TweepError:\n",
    "        print('Tweep error with user: %s' % user)\n",
    "        time.sleep(60)\n",
    "        continue\n",
    "        \n",
    "    print(user)\n",
    "        \n",
    "    all_tweets.extend(new_tweets)\n",
    "    \n",
    "    time.sleep(60)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2353\n"
     ]
    }
   ],
   "source": [
    "# Number of tweets from users located in Spain until 30th of September of 2018\n",
    "\n",
    "print(len(all_tweets))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1061533081197195265\n",
      "Sun Nov 11 08:16:23 +0000 2018\n",
      "1061298282637520896\n",
      "Sat Nov 10 16:43:23 +0000 2018\n",
      "1061052676283105281\n",
      "Sat Nov 10 00:27:26 +0000 2018\n",
      "1060997519805681664\n",
      "Fri Nov 09 20:48:15 +0000 2018\n",
      "1060987545213898752\n",
      "Fri Nov 09 20:08:37 +0000 2018\n",
      "1060976558532427778\n",
      "Fri Nov 09 19:24:58 +0000 2018\n",
      "1060517801033641984\n",
      "Thu Nov 08 13:02:01 +0000 2018\n",
      "1060292664665432065\n",
      "Wed Nov 07 22:07:25 +0000 2018\n",
      "1060292451523534848\n",
      "Wed Nov 07 22:06:34 +0000 2018\n",
      "1060267026424496128\n",
      "Wed Nov 07 20:25:32 +0000 2018\n",
      "1060262520341045248\n",
      "Wed Nov 07 20:07:38 +0000 2018\n",
      "1059964276847337472\n",
      "Wed Nov 07 00:22:31 +0000 2018\n",
      "1059947383663067137\n",
      "Tue Nov 06 23:15:23 +0000 2018\n",
      "1059910388463079424\n",
      "Tue Nov 06 20:48:23 +0000 2018\n",
      "1058155246130749442\n",
      "Fri Nov 02 00:34:04 +0000 2018\n",
      "1057010726768910338\n",
      "Mon Oct 29 20:46:10 +0000 2018\n",
      "1056665912684806144\n",
      "Sun Oct 28 21:56:00 +0000 2018\n",
      "1056665156338495488\n",
      "Sun Oct 28 21:52:59 +0000 2018\n",
      "1056510174675025920\n",
      "Sun Oct 28 11:37:09 +0000 2018\n",
      "1056176058700042240\n",
      "Sat Oct 27 13:29:29 +0000 2018\n",
      "1056175305965166592\n",
      "Sat Oct 27 13:26:30 +0000 2018\n",
      "1055940103296741378\n",
      "Fri Oct 26 21:51:53 +0000 2018\n",
      "1055917265902804992\n",
      "Fri Oct 26 20:21:08 +0000 2018\n",
      "1055916951208366081\n",
      "Fri Oct 26 20:19:53 +0000 2018\n",
      "1055787168700993536\n",
      "Fri Oct 26 11:44:11 +0000 2018\n",
      "1055786926802898945\n",
      "Fri Oct 26 11:43:13 +0000 2018\n",
      "1055105876091158528\n",
      "Wed Oct 24 14:36:58 +0000 2018\n",
      "1055105362272096257\n",
      "Wed Oct 24 14:34:55 +0000 2018\n",
      "1054799457617956865\n",
      "Tue Oct 23 18:19:22 +0000 2018\n",
      "1054306255496531969\n",
      "Mon Oct 22 09:39:34 +0000 2018\n"
     ]
    }
   ],
   "source": [
    "# Get tweet id from a known date\n",
    "\n",
    "n = api.user_timeline(screen_name='nachomartin83', count=30)\n",
    "for tweet in n:\n",
    "    print(tweet._json['id'])\n",
    "    print(tweet._json['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store all tweets found in mlab \"tweets\" collection\n",
    "\n",
    "collection = db['tweets']\n",
    "\n",
    "for tweet in all_tweets:\n",
    "    collection.insert_one(tweet._json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ************************************************************************************************************\n",
    "\n",
    "# Scrapping actual tweets to get some usernames:\n",
    "\n",
    "some_tweets = []\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    search_results =api.search(q='*', geocode='39.3262345,-4.8380649,750km', count=100, lang='es')\n",
    "\n",
    "    for i in search_results:\n",
    "        document = i._json\n",
    "        document['id'] = str(document['id'])\n",
    "        some_tweets.append(document)\n",
    "    \n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9822\n"
     ]
    }
   ],
   "source": [
    "print(len(some_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_names = []\n",
    "verified = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for doc in some_tweets:\n",
    "    user_names.append(doc['user']['screen_name'])\n",
    "    if doc['user']['verified']:\n",
    "        verified.append(doc['user']['screen_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9822\n",
      "122\n"
     ]
    }
   ],
   "source": [
    "print(len(user_names))\n",
    "print(len(verified))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7841\n"
     ]
    }
   ],
   "source": [
    "set_user_names = set(user_names)\n",
    "print(len(set_user_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "set_verified = set(verified)\n",
    "print(len(set_verified))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_10tweets(username):\n",
    "    \n",
    "    tweets_10 = []\n",
    "    count = 11\n",
    "    MAX_ID = 1061533081197195265 #11 November\n",
    "    aux = 0\n",
    "    \n",
    "    while len(tweets_10) < 11:\n",
    "        print('.', end='')\n",
    "        try:\n",
    "            tweets = api.user_timeline(screen_name=username, count=count, max_id = MAX_ID)\n",
    "        except tweepy.TweepError:\n",
    "            return 0, tweets_10\n",
    "        \n",
    "        for tweet in tweets:\n",
    "            doc = tweet._json\n",
    "            doc['id'] = str(doc['id'])\n",
    "            \n",
    "            if doc not in tweets_10 and not doc['text'].startswith('RT '):\n",
    "                tweets_10.append(doc)\n",
    "            else:\n",
    "                MAX_ID = doc['id']\n",
    "            \n",
    "            if len(tweets_10) == 11:\n",
    "                break\n",
    "        if aux > 10:\n",
    "            return 2, tweets_10\n",
    "        aux += 1\n",
    "    \n",
    "    return 1, tweets_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#user_names = user_names[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999\n"
     ]
    }
   ],
   "source": [
    "print(len(set_user_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "collection = db['users_noRT']\n",
    "cursor = collection.find()\n",
    "\n",
    "set_new_users = []\n",
    "repeated = []\n",
    "\n",
    "for doc in cursor:\n",
    "    if doc['name'] in set_user_names:\n",
    "        repeated.append(doc['name'])\n",
    "\n",
    "for u in set_verified:\n",
    "    if u not in repeated:\n",
    "        set_new_users.append(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n",
      "['Dani_Merono', 'EXNdigital', 'nachoMoL', 'FundacionCBG', 'Destinia', 'Cadiz_CFESports', 'ehbilducongreso', 'AusEmbEsp', 'teledonosti', 'COPE', 'victorjuste', 'xNavalha', 'bolsamania', 'SanRoqueLepe', 'NTremino', 'rielcano', 'xpericay', 'rne', 'ghoficial', 'jaimedeolano', 'hobby_consolas', 'indpcom', 'elperiodico', 'malonsocs', 'unelibros', 'Iberia', 'kj_mestre', 'edicionesiruela', 'PPSenado', 'diariosevilla', 'UPFBarcelona', 'sport', 'MaribelHOvera', 'rtve', 'JPelirrojo', 'polispol', 'emov_es', 'CiutadansBCN', 'pphuelva', 'anaisbernal', 'FranCasamayor', 'InformacionDGT', 'OBRADOIROCAB', 'ElPuerto', 'euroclub_europa', 'Lineamadrid', 'informativost5', 'Filmin', 'elcomerciodigit', 'GranadaFemenino', 'Cs_Andalucia', 'JonInarritu', 'kikollan', 'eaala', 'pjorge', 'noelceballos_', 'libertaddigital', 'Carre1Ascension', 'tferrerm', 'usal', 'cextremadura', 'Suni_Sanchez', 'ordago13', 'NatGeoEsp', 'cuore', 'harpersbazaarES', 'luis_quevedo', 'elopi23', 'amesanl', 'anamarcelloana', 'javierpadillab', 'La_Cerca', 'loreal_es', 'EmbFinMadrid', 'mamenmarquezvoz', 'DELOSSANTOSLEAL', 'el_pais', 'CanteraSFC', 'PoderJudicialEs', 'ajpaniagua', 'salvameoficial', 'eurospaincom', '24h_tve', 'informacion_es', 'IAyalaSender', 'LaVanguardia', 'TV_Mediterraneo', 'AhoraMadrid', 'rtvcyl', 'FemSantAdria', 'RealSociedad', 'crudo8', 'sepiegob', 'elCorreoWeb', 'car_and_driver', 'elpais_retina', 'EconomiaED_']\n"
     ]
    }
   ],
   "source": [
    "print(len(set_new_users))\n",
    "print(set_new_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_tweets = []\n",
    "status_0_users = []\n",
    "status_2_users = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "realmadrid\n",
      ".FCBarcelona\n",
      ".andresiniesta8\n",
      ".AlejandroSanz\n",
      ".3gerardpique\n",
      "..Pontifex_es\n",
      ".RafaelNadal\n",
      "..SergioRamos\n",
      ".enriqueiglesias\n",
      ".FCBarcelona_es\n",
      ".Rubiu5\n",
      "..XabiAlonso\n",
      "..D_DeGea\n",
      ".Carles5puyol\n",
      "..realmadriden\n",
      ".davidbisbal\n",
      "..cesc4official\n",
      "..Guaje7Villa\n",
      ".IkerCasillas\n",
      "..muyinteresante\n",
      "..juanmata8\n",
      ".paugasol\n",
      "..el_pais\n",
      ".aarbeloa17\n",
      ".....FCBarcelona_cat\n",
      ".vegetta777\n",
      "..mangelrogel\n",
      ".WillyrexYT\n",
      "..isco_alarcon\n",
      "..marca\n",
      ".._Pedro17_\n",
      "..aLexBY11\n",
      "..fifacom_es\n",
      "...AlvaroMorata\n",
      ".Atleti\n",
      "..LaLiga\n",
      "..21LVA\n",
      "...pabloalboran\n",
      "....Torres\n",
      "..Buenafuente\n",
      "..LuzuVlogs\n",
      "..officialpepe\n",
      "..DaniCarvajal92\n",
      "..SSantiagosegura\n",
      "..jordievole\n",
      "....auronplay\n",
      "..Thiago6\n",
      ".elmundoes\n",
      "..BoseOfficial\n",
      "..AbrahamMateo\n",
      "............Status : 2\n",
      "DANIROVIRA\n",
      "..rickyrubio9\n",
      "..ActualidadRT\n",
      "..mtvspain\n",
      ".Wismichu\n",
      "..ristomejide\n",
      "...2010MisterChip\n",
      "..MarcBartra\n",
      ".VogueSpain\n",
      ".JeseRodriguez10\n",
      ".BBVAworld\n",
      "._MaluOficial_\n",
      "..TownGamePlay\n",
      "..alo_oficial\n",
      "..AnderHerrera\n",
      ".Berto_Romero\n",
      "..danimartinezweb\n",
      "...diarioas\n",
      "..marcmarquez93\n",
      "..mundodeportivo\n",
      "..ifilosofia\n",
      ".nachofi1990\n",
      ".SergiRoberto10\n",
      "...El_Hormiguero\n",
      "..CristiPedroche\n",
      ".Pablo_Iglesias_\n",
      "....fifaworldcup_es\n",
      "..Rafinha\n",
      "..JordiAlba\n",
      "..SeFutbol\n",
      ".19SCazorla\n",
      "...CesarAzpi\n",
      ".TheGrefgYT\n",
      "..JordiWild\n",
      ".llorentefer19\n",
      "._anapastor_\n",
      "....perezreverte\n",
      "...AnnaSimonMari\n",
      ".ctello91\n",
      ".._danielmartin_\n",
      "..Cosmopolitan_es\n",
      ".mario_casas_\n",
      "....GUTY14HAZ\n",
      ".......MelendiOficial\n",
      "...........A3Noticias\n",
      ".El_Universo_Hoy\n",
      ".hola\n",
      ".lorenzo99\n",
      "..flofdezz\n",
      "..bunburyoficial\n",
      ".marianorajoy\n",
      "..pacoleonbarrios\n",
      "..virchugallardo\n",
      "..abc_es\n",
      ".OrtografiaReal\n",
      "............Status : 2\n",
      "HectorMorenoh\n",
      "..telecincoes\n",
      "..HectorBellerin\n",
      "...Los40\n",
      "..entrebellas\n",
      "..sport\n",
      ".filipeluis\n",
      "..albertocontador\n",
      ".epunset\n",
      ".......EFEnoticias\n",
      ".Mamdouh_Hamza\n",
      "..DaniMateoAgain\n",
      "..Javi8martinez\n",
      "..antena3com\n",
      "..20m\n",
      ".ahorapodemos\n",
      "...PReina25\n",
      "..24h_tve\n",
      "...Srcheeto\n",
      "..manuchao\n",
      ".elle_es\n",
      ".guardiacivil\n",
      ".rudy5fernandez\n",
      ".m8arteta\n",
      "..elmundotoday\n",
      "...museodelprado\n",
      "..RAEinforma\n",
      ".BelenEstebanM\n",
      "..enchiringuitotv\n",
      ".Status : 0\n",
      "MsJoseline\n",
      "..La_SER\n",
      ".valenciacf\n",
      "..ManuelaCarmena\n",
      "..microsiervos\n",
      "...DavidFerrer87\n",
      "...cuatro\n",
      "..riverakiko\n",
      ".sextaNoticias\n",
      "..Edurnity\n",
      "..NaturPictures\n",
      "..DjMaRiiO_90\n",
      ".europapress\n",
      "..eljueves\n",
      "..lafabricacrm\n",
      ".rtve\n",
      "...julia_otero\n",
      "..Albert_Rivera\n",
      "..elpais_tec\n",
      "..Lionel_Messi\n",
      ".eva_hache\n",
      ".GuillemBalague\n",
      "..gerardeulofeu\n",
      ".GLaraLopez\n",
      ".agarzon\n",
      ".....Lucasvazquez91\n",
      "..LaNoticiaViral\n",
      "........SipacateGuate\n",
      "...EL_Intermedio\n",
      ".Sabrinaquotes\n",
      ".Status : 0\n",
      "rfef\n",
      ".SportsCenter_nt\n",
      "..LaVanguardia\n",
      "....R9Soldado\n",
      "..As_TomasRoncero\n",
      "..estopaoficial\n",
      ".alanpulido\n",
      "..androides\n",
      ".DatoFemenino\n",
      ".Guarromantico_\n",
      ".TheSergioGarcia\n",
      "..BoKrkic\n",
      ".Carlos_Latre\n",
      "....13_Pinto\n",
      "...eldiarioes\n",
      ".sanchezcastejon\n",
      "..David_Busta\n",
      "..byViruZz\n",
      "..CISC\n",
      ".Koke6\n",
      ".SevillaFC\n",
      ".laSextaTV\n",
      "..publico_es\n",
      ".RecetasLigeras\n",
      ".iescolar\n",
      "..adidas_ES\n",
      ".JoseMotatv\n",
      ".....avange_anderson\n",
      ".Status : 0\n",
      "jpedrerol\n",
      "..sonypictures_es\n",
      "..applesfera\n",
      "..melomoreno\n",
      "..eGranero11\n",
      "...CasaREal\n",
      ".soypabloibanez\n",
      ".."
     ]
    }
   ],
   "source": [
    "import time\n",
    "for name in set_new_users:\n",
    "    print(name)\n",
    "    status, tweets = get_10tweets(name)\n",
    "    time.sleep(30)\n",
    "    if status == 1:\n",
    "        list_of_tweets.extend(tweets)\n",
    "    elif status == 0:\n",
    "        print(\"Status : 0\")\n",
    "        status_0_users.append(name)\n",
    "    else:\n",
    "        print(\"Status : 2\")\n",
    "        status_2_users.append(name)\n",
    "        list_of_tweets.extend(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2145\n"
     ]
    }
   ],
   "source": [
    "print(len(list_of_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "collection = db['users_noRT']\n",
    "for name in set_new_users:\n",
    "    doc = {}\n",
    "    doc['name'] = name\n",
    "    collection.insert_one(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "collection = db['tweets_noRT']\n",
    "for tweet in list_of_tweets:\n",
    "    collection.insert_one(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_usernames_1 = set_user_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "486\n"
     ]
    }
   ],
   "source": [
    "print(len(set_usernames_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_tweets_1 = list_of_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3927\n"
     ]
    }
   ],
   "source": [
    "print(len(set_tweets_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_usernames_2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for name in set_user_names:\n",
    "    if name not in set_usernames_1:\n",
    "        set_usernames_2.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1035\n"
     ]
    }
   ],
   "source": [
    "print(len(set_usernames_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "collection = db['users_noRT']\n",
    "for name in set_usernames_2:\n",
    "    doc = {}\n",
    "    doc['name'] = name\n",
    "    collection.insert_one(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_tweets_2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for tweet in list_of_tweets:\n",
    "    if tweet not in set_tweets_1:\n",
    "        set_tweets_2.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6679\n"
     ]
    }
   ],
   "source": [
    "print(len(set_tweets_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "collection = db['tweets_noRT']\n",
    "for tweet in set_tweets_2:\n",
    "    collection.insert_one(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "collection = db['users_noRT']\n",
    "cursor = collection.find()\n",
    "\n",
    "for doc in cursor:\n",
    "    if doc['name'] in status_0_users:\n",
    "        collection.delete_one({'name': doc['name']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    }
   ],
   "source": [
    "print(len(status_0_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537\n"
     ]
    }
   ],
   "source": [
    "print(len(status_2_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#************************************************************************************\n",
    "# Scrap some verified users\n",
    "set_new_users = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('verified-users.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        set_new_users.append(line)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n"
     ]
    }
   ],
   "source": [
    "print(len(set_new_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
