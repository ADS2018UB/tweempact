{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>j_user</th>\n",
       "      <th>created_at</th>\n",
       "      <th>followers_user</th>\n",
       "      <th>FC</th>\n",
       "      <th>RT</th>\n",
       "      <th>trending_topic</th>\n",
       "      <th>hashtags_text</th>\n",
       "      <th>id</th>\n",
       "      <th>hour</th>\n",
       "      <th>class_rt</th>\n",
       "      <th>class_fc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Desde el #FCJumilla damos nuestra más sincera ...</td>\n",
       "      <td>{'id': 2664945430, 'id_str': '2664945430', 'na...</td>\n",
       "      <td>2018-09-30 15:58:44</td>\n",
       "      <td>7162</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0                     [ 'FCJumilla']\\r\\n1     ...</td>\n",
       "      <td>2.664945e+09</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Me estoy volviendo loca hasta por cada una de ...</td>\n",
       "      <td>{'id': 713359736, 'id_str': '713359736', 'name...</td>\n",
       "      <td>2018-09-24 03:05:47</td>\n",
       "      <td>531</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0                     [ 'FCJumilla']\\r\\n1     ...</td>\n",
       "      <td>7.133597e+08</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>🏟 | El #FCJumilla ya está en La Condomina   ⚽️...</td>\n",
       "      <td>{'id': 2664945430, 'id_str': '2664945430', 'na...</td>\n",
       "      <td>2018-09-30 15:38:18</td>\n",
       "      <td>7162</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0                     [ 'FCJumilla']\\r\\n1     ...</td>\n",
       "      <td>2.664945e+09</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>📹 | El vestuario del #FCJumilla en La Condomin...</td>\n",
       "      <td>{'id': 2664945430, 'id_str': '2664945430', 'na...</td>\n",
       "      <td>2018-09-30 15:19:29</td>\n",
       "      <td>7162</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0                     [ 'FCJumilla']\\r\\n1     ...</td>\n",
       "      <td>2.664945e+09</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>📑 Jornada 6 | El colegiado andaluz Guzmán Mans...</td>\n",
       "      <td>{'id': 2664945430, 'id_str': '2664945430', 'na...</td>\n",
       "      <td>2018-09-30 15:10:30</td>\n",
       "      <td>7162</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0                     [ 'FCJumilla']\\r\\n1     ...</td>\n",
       "      <td>2.664945e+09</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              Tweet  \\\n",
       "0           0  Desde el #FCJumilla damos nuestra más sincera ...   \n",
       "1           1  Me estoy volviendo loca hasta por cada una de ...   \n",
       "2           2  🏟 | El #FCJumilla ya está en La Condomina   ⚽️...   \n",
       "3           3  📹 | El vestuario del #FCJumilla en La Condomin...   \n",
       "4           4  📑 Jornada 6 | El colegiado andaluz Guzmán Mans...   \n",
       "\n",
       "                                              j_user           created_at  \\\n",
       "0  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:58:44   \n",
       "1  {'id': 713359736, 'id_str': '713359736', 'name...  2018-09-24 03:05:47   \n",
       "2  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:38:18   \n",
       "3  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:19:29   \n",
       "4  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:10:30   \n",
       "\n",
       "   followers_user  FC  RT  trending_topic  \\\n",
       "0            7162  18   4             0.0   \n",
       "1             531   0   0             0.0   \n",
       "2            7162   4   2             0.0   \n",
       "3            7162  21   6             0.0   \n",
       "4            7162   0   0             0.0   \n",
       "\n",
       "                                       hashtags_text            id  hour  \\\n",
       "0  0                     [ 'FCJumilla']\\r\\n1     ...  2.664945e+09  15.0   \n",
       "1  0                     [ 'FCJumilla']\\r\\n1     ...  7.133597e+08   3.0   \n",
       "2  0                     [ 'FCJumilla']\\r\\n1     ...  2.664945e+09  15.0   \n",
       "3  0                     [ 'FCJumilla']\\r\\n1     ...  2.664945e+09  15.0   \n",
       "4  0                     [ 'FCJumilla']\\r\\n1     ...  2.664945e+09  15.0   \n",
       "\n",
       "   class_rt  class_fc  \n",
       "0       0.0       1.0  \n",
       "1       0.0       0.0  \n",
       "2       0.0       1.0  \n",
       "3       0.0       1.0  \n",
       "4       0.0       1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = pd.read_csv('tweet_amb_ids_match.csv')\n",
    "file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_FC = file['FC']\n",
    "Y_RT = file['RT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y0\n",
      "0.8628735037007706\n",
      "[13136  7007  2861  1557  1090   763   544   431   374   566]\n",
      "\n",
      "y1:\n",
      "0.08653406841095307\n",
      "[1320  530  291  211  138  110   72   55   63   51]\n",
      "\n",
      "y2:\n",
      "0.02823550912247571\n",
      "[298 144  95  75  67  60  60  40  45  43]\n",
      "\n",
      "y3:\n",
      "0.014407115226462795\n",
      "[126  79  63  50  44  25  22  19  23  22]\n",
      "\n",
      "y4:\n",
      "0.007949803539337821\n",
      "[143  55  19  20   7   8   2   1   4   2]\n"
     ]
    }
   ],
   "source": [
    "print('y0')\n",
    "y0_fc = Y_FC[np.asarray(Y_FC)<=10]\n",
    "pes0 = (np.asarray(y0_fc).shape[0])/(np.asarray(Y_FC).shape[0])\n",
    "print(pes0)\n",
    "hist, bin_edges = np.histogram(y0_fc)\n",
    "print(hist)\n",
    "print('\\ny1:')\n",
    "y1_fc = Y_FC[np.asarray(Y_FC)>10]\n",
    "y1_fc = y1_fc[np.asarray(y1_fc)<=100]\n",
    "pes1 = (np.asarray(y1_fc).shape[0])/(np.asarray(Y_FC).shape[0])\n",
    "print(pes1)\n",
    "hist, bin_edges = np.histogram(y1_fc)\n",
    "print(hist)\n",
    "print('\\ny2:')\n",
    "y2_fc = Y_FC[np.asarray(Y_FC)>100]\n",
    "y2_fc = y2_fc[np.asarray(y2_fc)<=1000]\n",
    "pes2 = (np.asarray(y2_fc).shape[0])/(np.asarray(Y_FC).shape[0])\n",
    "print(pes2)\n",
    "hist, bin_edges = np.histogram(y2_fc)\n",
    "print(hist)\n",
    "print('\\ny3:')\n",
    "y3_fc = Y_FC[np.asarray(Y_FC)>1000]\n",
    "y3_fc = y3_fc[np.asarray(y3_fc)<=5000]\n",
    "pes3 = (np.asarray(y3_fc).shape[0])/(np.asarray(Y_FC).shape[0])\n",
    "print(pes3)\n",
    "hist, bin_edges = np.histogram(y3_fc)\n",
    "print(hist)\n",
    "print('\\ny4:')\n",
    "y4_fc = Y_FC[np.asarray(Y_FC)>5000]\n",
    "pes4 = (np.asarray(y4_fc).shape[0])/(np.asarray(Y_FC).shape[0])\n",
    "print(pes4)\n",
    "hist, bin_edges = np.histogram(y4_fc)\n",
    "print(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y0\n",
      "0.8800219304925223\n",
      "[21735     0  3741     0  1460     0   912     0   627   417]\n",
      "\n",
      "y1:\n",
      "0.05948646096676921\n",
      "[597 210 349 145 127 185  84 113  54  89]\n",
      "\n",
      "y2:\n",
      "0.030002132131217447\n",
      "[293 173 122  92  78  62  59  46  39  21]\n",
      "\n",
      "y3:\n",
      "0.019311017026590722\n",
      "[145 104  85  59  62  32  46  39  33  29]\n",
      "\n",
      "y4:\n",
      "0.011178459382900307\n",
      "[269  47  20   7   8   6   4   1   3   2]\n",
      "\n",
      " Suma de pesos: 1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "# Separem Y_RT entre 5 grups: aquells que tenen menys de 5, aquells que tenen entre 6- 20, \n",
    "# aquells que tenen entre 21 - 100, aquells que tenen entre 100 i 500 i aquells que tenen mes de 500\n",
    "# Fem 4 models, nomes per aquells que tenen a partir de 6\n",
    "\n",
    "print('y0')\n",
    "y0_rt = Y_RT[np.asarray(Y_RT)<=5]\n",
    "pes0 = (np.asarray(y0_rt).shape[0])/(np.asarray(Y_RT).shape[0])\n",
    "print(pes0)\n",
    "hist, bin_edges = np.histogram(y0_rt)\n",
    "print(hist)\n",
    "print('\\ny1:')\n",
    "y1_rt = Y_RT[np.asarray(Y_RT)>5]\n",
    "y1_rt = y1_rt[np.asarray(y1_rt)<=20]\n",
    "pes1 = (np.asarray(y1_rt).shape[0])/(np.asarray(Y_RT).shape[0])\n",
    "print(pes1)\n",
    "hist, bin_edges = np.histogram(y1_rt)\n",
    "print(hist)\n",
    "print('\\ny2:')\n",
    "y2_rt = Y_RT[np.asarray(Y_RT)>20]\n",
    "y2_rt = y2_rt[np.asarray(y2_rt)<=100]\n",
    "pes2 = (np.asarray(y2_rt).shape[0])/(np.asarray(Y_RT).shape[0])\n",
    "print(pes2)\n",
    "hist, bin_edges = np.histogram(y2_rt)\n",
    "print(hist)\n",
    "print('\\ny3:')\n",
    "y3_rt = Y_RT[np.asarray(Y_RT)>100]\n",
    "y3_rt = y3_rt[np.asarray(y3_rt)<=500]\n",
    "pes3 = (np.asarray(y3_rt).shape[0])/(np.asarray(Y_RT).shape[0])\n",
    "print(pes3)\n",
    "hist, bin_edges = np.histogram(y3_rt)\n",
    "print(hist)\n",
    "print('\\ny4:')\n",
    "y4_rt = Y_RT[np.asarray(Y_RT)>500]\n",
    "pes4 = (np.asarray(y4_rt).shape[0])/(np.asarray(Y_RT).shape[0])\n",
    "print(pes4)\n",
    "hist, bin_edges = np.histogram(y4_rt)\n",
    "print(hist)\n",
    "\n",
    "print('\\n Suma de pesos:', pes0+pes1+pes2+pes3+pes4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "file['class_fc'] = np.zeros(file.shape[0])\n",
    "file['class_rt'] = np.zeros(file.shape[0])\n",
    "\n",
    "file['class_fc'][y1_fc.index] = 1\n",
    "file['class_fc'][y2_fc.index] = 2\n",
    "file['class_fc'][y3_fc.index] = 3\n",
    "file['class_fc'][y4_fc.index] = 4\n",
    "\n",
    "file['class_rt'][y1_rt.index] = 1\n",
    "file['class_rt'][y2_rt.index] = 2\n",
    "file['class_rt'][y3_rt.index] = 3\n",
    "file['class_rt'][y4_rt.index] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>j_user</th>\n",
       "      <th>created_at</th>\n",
       "      <th>followers_user</th>\n",
       "      <th>FC</th>\n",
       "      <th>RT</th>\n",
       "      <th>trending_topic</th>\n",
       "      <th>hashtags_text</th>\n",
       "      <th>id</th>\n",
       "      <th>hour</th>\n",
       "      <th>class_rt</th>\n",
       "      <th>class_fc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Desde el #FCJumilla damos nuestra más sincera ...</td>\n",
       "      <td>{'id': 2664945430, 'id_str': '2664945430', 'na...</td>\n",
       "      <td>2018-09-30 15:58:44</td>\n",
       "      <td>7162</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0                     [ 'FCJumilla']\\r\\n1     ...</td>\n",
       "      <td>2.664945e+09</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Me estoy volviendo loca hasta por cada una de ...</td>\n",
       "      <td>{'id': 713359736, 'id_str': '713359736', 'name...</td>\n",
       "      <td>2018-09-24 03:05:47</td>\n",
       "      <td>531</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0                     [ 'FCJumilla']\\r\\n1     ...</td>\n",
       "      <td>7.133597e+08</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>🏟 | El #FCJumilla ya está en La Condomina   ⚽️...</td>\n",
       "      <td>{'id': 2664945430, 'id_str': '2664945430', 'na...</td>\n",
       "      <td>2018-09-30 15:38:18</td>\n",
       "      <td>7162</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0                     [ 'FCJumilla']\\r\\n1     ...</td>\n",
       "      <td>2.664945e+09</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>📹 | El vestuario del #FCJumilla en La Condomin...</td>\n",
       "      <td>{'id': 2664945430, 'id_str': '2664945430', 'na...</td>\n",
       "      <td>2018-09-30 15:19:29</td>\n",
       "      <td>7162</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0                     [ 'FCJumilla']\\r\\n1     ...</td>\n",
       "      <td>2.664945e+09</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>📑 Jornada 6 | El colegiado andaluz Guzmán Mans...</td>\n",
       "      <td>{'id': 2664945430, 'id_str': '2664945430', 'na...</td>\n",
       "      <td>2018-09-30 15:10:30</td>\n",
       "      <td>7162</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0                     [ 'FCJumilla']\\r\\n1     ...</td>\n",
       "      <td>2.664945e+09</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              Tweet  \\\n",
       "0           0  Desde el #FCJumilla damos nuestra más sincera ...   \n",
       "1           1  Me estoy volviendo loca hasta por cada una de ...   \n",
       "2           2  🏟 | El #FCJumilla ya está en La Condomina   ⚽️...   \n",
       "3           3  📹 | El vestuario del #FCJumilla en La Condomin...   \n",
       "4           4  📑 Jornada 6 | El colegiado andaluz Guzmán Mans...   \n",
       "\n",
       "                                              j_user           created_at  \\\n",
       "0  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:58:44   \n",
       "1  {'id': 713359736, 'id_str': '713359736', 'name...  2018-09-24 03:05:47   \n",
       "2  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:38:18   \n",
       "3  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:19:29   \n",
       "4  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:10:30   \n",
       "\n",
       "   followers_user  FC  RT  trending_topic  \\\n",
       "0            7162  18   4             0.0   \n",
       "1             531   0   0             0.0   \n",
       "2            7162   4   2             0.0   \n",
       "3            7162  21   6             0.0   \n",
       "4            7162   0   0             0.0   \n",
       "\n",
       "                                       hashtags_text            id  hour  \\\n",
       "0  0                     [ 'FCJumilla']\\r\\n1     ...  2.664945e+09  15.0   \n",
       "1  0                     [ 'FCJumilla']\\r\\n1     ...  7.133597e+08   3.0   \n",
       "2  0                     [ 'FCJumilla']\\r\\n1     ...  2.664945e+09  15.0   \n",
       "3  0                     [ 'FCJumilla']\\r\\n1     ...  2.664945e+09  15.0   \n",
       "4  0                     [ 'FCJumilla']\\r\\n1     ...  2.664945e+09  15.0   \n",
       "\n",
       "   class_rt  class_fc  \n",
       "0       0.0       1.0  \n",
       "1       0.0       0.0  \n",
       "2       0.0       0.0  \n",
       "3       1.0       1.0  \n",
       "4       0.0       0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_0 = file[file['class_fc']==0]\n",
    "aux_1 = file[file['class_fc']==1]\n",
    "aux_2 = file[file['class_fc']==2]\n",
    "aux_3 = file[file['class_fc']==3]\n",
    "aux_4 = file[file['class_fc']==4]\n",
    "y_0 = aux_0['FC']\n",
    "y_1 = aux_1['FC']\n",
    "y_2 = aux_2['FC']\n",
    "y_3 = aux_3['FC']\n",
    "y_4 = aux_4['FC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10\n",
      "11 100\n",
      "101 1000\n",
      "1001 4997\n",
      "5015 77142\n"
     ]
    }
   ],
   "source": [
    "print(min(y_0),max(y_0))\n",
    "print(min(y_1),max(y_1))\n",
    "print(min(y_2),max(y_2))\n",
    "print(min(y_3),max(y_3))\n",
    "print(min(y_4),max(y_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5\n",
      "6 20\n",
      "21 100\n",
      "101 500\n",
      "502 16587\n"
     ]
    }
   ],
   "source": [
    "aux_0 = file[file['class_rt']==0]\n",
    "aux_1 = file[file['class_rt']==1]\n",
    "aux_2 = file[file['class_rt']==2]\n",
    "aux_3 = file[file['class_rt']==3]\n",
    "aux_4 = file[file['class_rt']==4]\n",
    "y_0 = aux_0['RT']\n",
    "y_1 = aux_1['RT']\n",
    "y_2 = aux_2['RT']\n",
    "y_3 = aux_3['RT']\n",
    "y_4 = aux_4['RT']\n",
    "\n",
    "print(min(y_0),max(y_0))\n",
    "print(min(y_1),max(y_1))\n",
    "print(min(y_2),max(y_2))\n",
    "print(min(y_3),max(y_3))\n",
    "print(min(y_4),max(y_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fins aquí tenim la base de dades d'author i tweet juntes, i s'han afegit dues columnes segons el grup de rt i el grup de fc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ara preparem les dades per aplicar el model que separa en grups a author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "numl = len(file.index.values)\n",
    "cols = ['followers_count','friends_count','listed_count','favourites_count','statuses_count']\n",
    "\n",
    "X_aut = pd.DataFrame(columns = cols) #X que utilitzem pel model d'authors\n",
    "\n",
    "for col in cols:\n",
    "    X_aut[col]=np.zeros(numl)\n",
    "for line in range(numl):\n",
    "    dic = ast.literal_eval(file['j_user'][line])\n",
    "    for col in cols:\n",
    "        X_aut[col][line] = int(dic[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>statuses_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7162.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>2804.0</td>\n",
       "      <td>8466.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>531.0</td>\n",
       "      <td>1623.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2618.0</td>\n",
       "      <td>6907.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7162.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>2804.0</td>\n",
       "      <td>8466.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7162.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>2804.0</td>\n",
       "      <td>8466.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7162.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>2804.0</td>\n",
       "      <td>8466.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   followers_count  friends_count  listed_count  favourites_count  \\\n",
       "0           7162.0          334.0          92.0            2804.0   \n",
       "1            531.0         1623.0           0.0            2618.0   \n",
       "2           7162.0          334.0          92.0            2804.0   \n",
       "3           7162.0          334.0          92.0            2804.0   \n",
       "4           7162.0          334.0          92.0            2804.0   \n",
       "\n",
       "   statuses_count  \n",
       "0          8466.0  \n",
       "1          6907.0  \n",
       "2          8466.0  \n",
       "3          8466.0  \n",
       "4          8466.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_aut.head() #son les x\n",
    "#file['class_rt'] son les y per RT\n",
    "#file['class_fc'] son les y per FC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ara fem el model per determinal el grup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#model to determine which class\n",
    "\n",
    "#Neural networks\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "#for FC\n",
    "\n",
    "r_state = [0,1,2,3,4,5,42,43,44,45]\n",
    "\n",
    "acc_fc = np.zeros((len(r_state),1))\n",
    "\n",
    "for i in range(len(r_state)):\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X_aut, file['class_fc'], train_size=0.7, random_state=r_state[i])\n",
    "    \n",
    "    #Your code here\n",
    "    scaler = StandardScaler()\n",
    "    scaler = scaler.fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test) \n",
    "\n",
    "    mlp = MLPClassifier() #MLP\n",
    "    mlp.fit(X_train_scaled,y_train)\n",
    "    yhat_mlp = mlp.predict(X_test_scaled) \n",
    "    \n",
    "    acc_fc[i,0] = metrics.accuracy_score(y_test,yhat_mlp)\n",
    "\n",
    "mlp = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x1a167477f0>,\n",
       "  <matplotlib.lines.Line2D at 0x1a16747c88>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x1a167590f0>,\n",
       "  <matplotlib.lines.Line2D at 0x1a16759518>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x1a167476a0>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x1a16759940>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x1a16759d68>],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADjxJREFUeJzt3W2InWV+x/HvL4lPjU0ayVDQiU0E2xqw6O5BpQtLayrEtOiLImtcF9IGXZZGtkugVSps1r6Vsn0RF7KtD1iJZG1L00W0hQoLEkpOfIiJ0TYNa5wqZGwCFoXGh39fnCvrcRyZex6cycTvBwbOfZ3r3Oe6IZ6v933mzElVIUnSkoVegCTp7GAQJEmAQZAkNQZBkgQYBElSYxAkSYBBkCQ1BkGSBBgESVKzbKEXMB2rV6+utWvXLvQyJGlROXDgwDtVNTLVvEUVhLVr19Lv9xd6GZK0qCR5o8s8LxlJkgCDIElqDIIkCTAIkqTGIEiSAIMgSWoMgiQJMAiSpGZRfTBNmi9J5uV5/E5znU0MgjSJ6b5QJ/HFXYuel4wkSYBBkCQ1BkGSBBgESVJjECRJgEGQJDUGQZIEGARJUmMQJEmAQZAkNQZBkgQYBElSYxAkSUDHICTZmOT1JEeT3DvJ/ZcneS7Ji0kOJtnUxs9L8liSV5IcSXLfhMctbY/56dwcjiRppqYMQpKlwE7gZmA9sDnJ+gnT7gf2VNW1wO3AQ238NuCCqroa+Crw7SRrhx73XeDIbA5AkjQ3upwhXAccrapjVXUaeBK4dcKcAla02yuBt4bGlydZBlwEnAbeBUgyCvw+8DezOgJJ0pzoEoTLgDeHtsfa2LAdwJ1JxoCngXva+FPAe8DbwHHgwao62e77IfBnwMczWrkkaU51CcJk3yU48auhNgOPVtUosAl4PMkSBmcXHwGXAuuA7UmuSPIHwImqOjDlkyd3J+kn6Y+Pj3dYriRpJroEYQxYM7Q9yieXhM7YCuwBqKp9wIXAauAO4Jmq+qCqTgDPAz3ga8AtSX7O4BLUjUn+brInr6pdVdWrqt7IyEjnA5MkTU+XIOwHrkyyLsn5DN403jthznFgA0CSqxgEYbyN35iB5cANwGtVdV9VjVbV2ra/f6uqO+fkiCRJMzJlEKrqQ2Ab8CyD3wjaU1WHkzyQ5JY2bTtwV5KXgd3Alhp84/hO4GLgEIOwPFJVB7+A45AkzVIGr9uLQ6/Xq36/v9DLkD4jCYvpvyV9uSQ5UFW9qeb5SWVJEmAQJEmNQZAkAQZBktQYBEkSYBAkSY1BkCQBBkGS1BgESRJgECRJjUGQJAEGQZLUGARJEmAQJEmNQZAkAQZBktQYBEkSYBAkSY1BkCQBBkGS1BgESRJgECRJzbKFXoD0Rbvkkks4derUF/48Sb7Q/a9atYqTJ09+oc+hLzeDoHPeqVOnqKqFXsasfdHBkbxkJEkCDIIkqTEIkiTAIEiSGoMgSQIMgiSp6RSEJBuTvJ7kaJJ7J7n/8iTPJXkxycEkm9r4eUkeS/JKkiNJ7mvja9r8I0kOJ/nu3B6WJGm6pvwcQpKlwE7gJmAM2J9kb1W9OjTtfmBPVf0oyXrgaWAtcBtwQVVdneSXgFeT7Ab+D9heVS8k+WXgQJJ/nbBPSdI86nKGcB1wtKqOVdVp4Eng1glzCljRbq8E3hoaX55kGXARcBp4t6rerqoXAKrqf4EjwGWzOhJJ0qx0CcJlwJtD22N89sV7B3BnkjEGZwf3tPGngPeAt4HjwINV9anP3idZC1wL/Pv0li5JmktdgjDZ5+Un/h2AzcCjVTUKbAIeT7KEwdnFR8ClwDpge5IrfrHj5GLg74E/rap3J33y5O4k/ST98fHxDsuVJM1ElyCMAWuGtkf55JLQGVuBPQBVtQ+4EFgN3AE8U1UfVNUJ4HmgB4M3nBnE4Imq+ofPe/Kq2lVVvarqjYyMdDsqSdK0dQnCfuDKJOuSnA/cDuydMOc4sAEgyVUMgjDexm/MwHLgBuC1DP5K198CR6rqr+bmUCRJszFlEKrqQ2Ab8CyDN3/3VNXhJA8kuaVN2w7cleRlYDewpQZ/XnIncDFwiEFYHqmqg8DXgG8xiMVL7WfTXB+cJKm7LKY/C9zr9arf7y/0MrTIJDln/vz1uXAcmn9JDlRVb6p5flJZkgQYBElSYxAkSYBfoakvgfr+CtixcqGXMWv1/RVTT5JmwSDonJcfvHtOvBmbhNqx0KvQucxLRpIkwCBIkhqDIEkCDIIkqTEIkiTAIEiSGoMgSQIMgiSpMQiSJMAgSJIagyBJAgyCJKkxCJIkwCBIkhqDIEkCDIIkqTEIkiTAIEiSGoMgSQIMgiSpMQiSJMAgSJIagyBJAgyCJKnpFIQkG5O8nuRoknsnuf/yJM8leTHJwSSb2vh5SR5L8kqSI0nu67pPSdL8mjIISZYCO4GbgfXA5iTrJ0y7H9hTVdcCtwMPtfHbgAuq6mrgq8C3k6ztuE9J0jzqcoZwHXC0qo5V1WngSeDWCXMKWNFurwTeGhpfnmQZcBFwGni34z4lSfOoSxAuA94c2h5rY8N2AHcmGQOeBu5p408B7wFvA8eBB6vqZMd9SpLmUZcgZJKxmrC9GXi0qkaBTcDjSZYwOBP4CLgUWAdsT3JFx30Onjy5O0k/SX98fLzDciVJM9ElCGPAmqHtUT65JHTGVmAPQFXtAy4EVgN3AM9U1QdVdQJ4Huh13Cdtf7uqqldVvZGRkQ7LlSTNRJcg7AeuTLIuyfkM3jTeO2HOcWADQJKrGARhvI3fmIHlwA3Aax33KUmaR1MGoao+BLYBzwJHGPw20eEkDyS5pU3bDtyV5GVgN7ClqorBbxJdDBxiEIFHqurg5+1zjo9NkjQNGbxuLw69Xq/6/f5CL0OLTBIW07/zz3OuHIfmX5IDVdWbap6fVJYkAQZBktQYBEkSYBAkSY1BkCQBBkGS1BgESRJgECRJjUGQJAEGQZLUGARJEmAQJEmNQZAkAQZBktQYBEkSYBAkSY1BkCQBBkGS1BgESRJgECRJjUGQJAEGQZLUGARJEmAQJEmNQZAkAQZBktQYBEkSYBAkSY1BkCQBBkGS1HQKQpKNSV5PcjTJvZPcf3mS55K8mORgkk1t/JtJXhr6+TjJNe2+zUleafOfSbJ6bg9NkjQdUwYhyVJgJ3AzsB7YnGT9hGn3A3uq6lrgduAhgKp6oqquqaprgG8BP6+ql5IsA/4a+N2q+i3gILBtrg5KkjR9Xc4QrgOOVtWxqjoNPAncOmFOASva7ZXAW5PsZzOwu91O+1meJO2xkz1GkjRPlnWYcxnw5tD2GHD9hDk7gH9Jcg+wHPi9SfbzDVpIquqDJN8BXgHeA/4T+JNprVySNKe6nCFkkrGasL0ZeLSqRoFNwONJfrHvJNcD71fVobZ9HvAd4FrgUgaXjO6b9MmTu5P0k/THx8c7LFeSNBNdgjAGrBnaHuWzl3e2AnsAqmofcCEw/Cbx7XxyuQjgmjb3v6qq2mN/e7Inr6pdVdWrqt7IyEiH5UqSZqJLEPYDVyZZl+R8Bi/ueyfMOQ5sAEhyFYMgjLftJcBtDN57OOO/gfVJzrzC3wQcmelBSJJmb8r3EKrqwyTbgGeBpcDDVXU4yQNAv6r2AtuBHyf5HoPLSVva//kDfB0Yq6pjQ/t8K8kPgJ8l+QB4A9gylwcmSZqefPK6ffbr9XrV7/cXehlaZJKwmP6df55z5Tg0/5IcqKreVPP8pLIkCej2a6fSojf4uMvitmrVqoVegs5xBkHnvPm4zOLlHJ0LvGQkSQIMgiSpMQiSJMAgSJIagyBJAgyCJKkxCJIkwCBIkhqDIEkCDIIkqTEIkiTAIEiSGoMgSQIMgiSpMQiSJMAgSJIagyBJAgyCJKkxCJIkwCBIkhqDIEkCDIIkqTEIkiTAIEiSGoMgSQIMgiSpMQiSJKBjEJJsTPJ6kqNJ7p3k/suTPJfkxSQHk2xq499M8tLQz8dJrmn3nZ9kV5L/SPJakj+c20OTJE3HsqkmJFkK7ARuAsaA/Un2VtWrQ9PuB/ZU1Y+SrAeeBtZW1RPAE20/VwP/VFUvtcf8BXCiqn49yRLgkjk7KknStE0ZBOA64GhVHQNI8iRwKzAchAJWtNsrgbcm2c9mYPfQ9h8DvwlQVR8D70xr5ZKkOdXlktFlwJtD22NtbNgO4M4kYwzODu6ZZD/foAUhya+0sb9M8kKSnyT51cmePMndSfpJ+uPj4x2WK0maiS5ByCRjNWF7M/BoVY0Cm4DH22WgwQ6S64H3q+pQG1oGjALPV9VXgH3Ag5M9eVXtqqpeVfVGRkY6LFeSNBNdgjAGrBnaHuWzl4S2AnsAqmofcCGweuj+2/n05aL/Ad4H/rFt/wT4SudVS5LmXJcg7AeuTLIuyfkMXtz3TphzHNgAkOQqBkEYb9tLgNuAJ89MrqoC/hn4nTa0gU+/JyFJmmdTvqlcVR8m2QY8CywFHq6qw0keAPpVtRfYDvw4yfcYXE7a0l70Ab4OjJ15U3rInzO4tPRDBvH4o7k5JEnSTOST1+2zX6/Xq36/v9DLkD4jCYvpvyV9uSQ5UFW9qeb5SWVJEmAQJEmNQZAkAQZBktQYBEkSYBAkSY1BkCQBBkGS1BgESRJgECRJjUGQJAEGQZLUGARJEmAQJEmNQZAkAQZBktQYBEkSYBAkSY1BkCQBsGyhFyCdjZLMy2P8HmadTQyCNAlfqPVl5CUjSRJgECRJjUGQJAEGQZLUGARJEmAQJEmNQZAkAQZBktRkMX0AJ8k48MZCr0OaxGrgnYVehPQ5fq2qRqaatKiCIJ2tkvSrqrfQ65Bmw0tGkiTAIEiSGoMgzY1dC70AabZ8D0GSBHiGIElqDII0C0keTnIiyaGFXos0WwZBmp1HgY0LvQhpLhgEaRaq6mfAyYVehzQXDIIkCTAIkqTGIEiSAIMgSWoMgjQLSXYD+4DfSDKWZOtCr0maKT+pLEkCPEOQJDUGQZIEGARJUmMQJEmAQZAkNQZBkgQYBElSYxAkSQD8P6fkpyfkHqxtAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.boxplot(acc_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model to determine which class\n",
    "\n",
    "#Neural networks\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "#for RT\n",
    "\n",
    "r_state = [0,1,2,3,4,5,42,43,44,45]\n",
    "\n",
    "acc_rt = np.zeros((len(r_state),1))\n",
    "\n",
    "for i in range(len(r_state)):\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X_aut, file['class_rt'], train_size=0.7, random_state=r_state[i])\n",
    "    \n",
    "    #Your code here\n",
    "    scaler = StandardScaler()\n",
    "    scaler = scaler.fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test) \n",
    "\n",
    "    mlp = MLPClassifier() #MLP\n",
    "    mlp.fit(X_train_scaled,y_train)\n",
    "    yhat_mlp = mlp.predict(X_test_scaled) \n",
    "    \n",
    "    acc_rt[i,0] = metrics.accuracy_score(y_test,yhat_mlp)\n",
    "\n",
    "mlp = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x1126d5898>,\n",
       "  <matplotlib.lines.Line2D at 0x1126d5d30>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x1126de198>,\n",
       "  <matplotlib.lines.Line2D at 0x1126de5c0>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x1126d5748>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x1126de9e8>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x1126dee10>],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.boxplot(acc_rt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Els models utilitzats són \"sklearn.neural_network.MLPClassifier()\" i tenen una accuracy del 88-89% de mitjana:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for FC: 0.8803756345177665\n",
      "Mean accuracy for RT: 0.8889137055837564\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean accuracy for FC:\",np.mean(acc_fc))\n",
    "print(\"Mean accuracy for RT:\",np.mean(acc_rt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn import neighbors\n",
    "from sklearn import svm\n",
    "from sklearn import ensemble\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X_aut_new_RT,Y_aut_RT,test_size=0.3,train_size=0.7,random_state=42)\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X_aut_new_RT,Y_aut_RT,test_size=0.3,train_size=0.7,random_state=42)\n",
    "GBC = ensemble.GradientBoostingClassifier(random_state=42)\n",
    "GBC.fit(X_train,y_train)\n",
    "yhat_GBC = GBC.predict(X_test)\n",
    "metrics.accuracy_score(y_test,yhat_GBC)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aut = './clean_newauthors.csv'\n",
    "data_aut = pd.read_csv(df_aut, sep=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RT_l10</th>\n",
       "      <th>FC_l10</th>\n",
       "      <th>FC</th>\n",
       "      <th>RT</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>listed_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.4</td>\n",
       "      <td>15.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19645.0</td>\n",
       "      <td>662.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4221.0</td>\n",
       "      <td>340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.9</td>\n",
       "      <td>37.2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1133925.0</td>\n",
       "      <td>9745.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5386.0</td>\n",
       "      <td>304.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RT_l10  FC_l10    FC    RT  followers_count  listed_count\n",
       "0     2.4    15.5   0.0   0.0          19645.0         662.0\n",
       "1     0.2     0.8   1.0   0.0           4221.0         340.0\n",
       "2    17.9    37.2  21.0  10.0        1133925.0        9745.0\n",
       "3     0.4     1.7   0.0   0.0           5386.0         304.0\n",
       "4     2.3     3.4   0.0   0.0           1072.0         101.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_aut = data_aut.drop(['Unnamed: 0','sd_RT','sd_FC','friends_count','favourites_count','statuses_count'], axis=1)\n",
    "X_aut.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_aut =  data_aut[['FC','RT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174\n",
      "2204\n"
     ]
    }
   ],
   "source": [
    "y = np.array(Y_aut['RT'])\n",
    "\n",
    "y[y <= 15] = 1\n",
    "y[y > 15] = 0\n",
    "\n",
    "X = X_aut.drop(['FC','RT'], axis=1)\n",
    "\n",
    "print(len(y[y==0]))\n",
    "print(len(y[y==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.92857143 0.93417367 0.94537815 0.92997199 0.93977591 0.93977591\n",
      "  0.94257703 0.06442577]\n",
      " [0.95378151 0.94257703 0.95518207 0.93417367 0.94677871 0.94677871\n",
      "  0.96358543 0.06022409]\n",
      " [0.93277311 0.94257703 0.95238095 0.92857143 0.93837535 0.93837535\n",
      "  0.94817927 0.06722689]\n",
      " [0.93557423 0.92577031 0.94957983 0.92016807 0.92997199 0.92997199\n",
      "  0.94957983 0.92577031]\n",
      " [0.93697479 0.92857143 0.93417367 0.92296919 0.94117647 0.94117647\n",
      "  0.94397759 0.07282913]\n",
      " [0.94537815 0.94117647 0.95798319 0.93557423 0.94537815 0.94537815\n",
      "  0.95798319 0.05882353]\n",
      " [0.95238095 0.94397759 0.96078431 0.94257703 0.95378151 0.95378151\n",
      "  0.96218487 0.05322129]\n",
      " [0.93137255 0.93697479 0.96218487 0.92857143 0.94397759 0.94397759\n",
      "  0.95518207 0.06862745]\n",
      " [0.93417367 0.93977591 0.96498599 0.94257703 0.95378151 0.95378151\n",
      "  0.96078431 0.05182073]\n",
      " [0.94257703 0.94117647 0.95658263 0.93417367 0.94677871 0.94677871\n",
      "  0.95518207 0.06022409]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn import neighbors\n",
    "from sklearn import svm\n",
    "from sklearn import ensemble\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "###for RT\n",
    "r_state = [0,1,2,3,4,5,42,43,44,45]\n",
    "\n",
    "acc = np.zeros((len(r_state),8))\n",
    "\n",
    "for i in range(len(r_state)):\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size=0.7, random_state=r_state[i])\n",
    "    \n",
    "    #Your code here\n",
    "    scaler = StandardScaler()\n",
    "    scaler = scaler.fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    \n",
    "    nn1 = neighbors.KNeighborsClassifier(n_neighbors=1) #1NN\n",
    "    nn1.fit(X_train_scaled,y_train)\n",
    "    yhat_nn1 = nn1.predict(X_test_scaled) \n",
    "\n",
    "    nn3 = neighbors.KNeighborsClassifier(n_neighbors=3) #3NN\n",
    "    nn3.fit(X_train_scaled,y_train)\n",
    "    yhat_nn3 = nn3.predict(X_test_scaled) \n",
    "    \n",
    "    tr = tree.DecisionTreeClassifier() #Decision Tree\n",
    "    tr.fit(X_train_scaled,y_train)\n",
    "    yhat_tr = tr.predict(X_test_scaled)\n",
    "    \n",
    "    svm10 = svm.SVC(C=10.0,gamma = 1e-5,random_state=42) \n",
    "    svm10.fit(X_train_scaled,y_train)\n",
    "    yhat_svm10 = svm10.predict(X_test_scaled)\n",
    "    \n",
    "    svm100 = svm.SVC(C=100.0,gamma = 1e-5,random_state=42)\n",
    "    svm100.fit(X_train_scaled,y_train)\n",
    "    yhat_svm100= svm100.predict(X_test_scaled)\n",
    "    \n",
    "    svm1000 = svm.SVC(C=1000.0,gamma = 1e-6,random_state=42)\n",
    "    svm1000.fit(X_train_scaled,y_train)\n",
    "    yhat_svm1000 = svm1000.predict(X_test_scaled)\n",
    "    \n",
    "    GBC = ensemble.GradientBoostingClassifier(random_state=42)\n",
    "    GBC.fit(X_train_scaled,y_train)\n",
    "    yhat_GBC = GBC.predict(X_test_scaled)\n",
    "    \n",
    "    clf = KMeans(n_clusters=2)\n",
    "    clf.fit(X_train_scaled,y_train)\n",
    "    yhat_clf = clf.predict(X_test_scaled)\n",
    "    \n",
    "    acc[i,0] = metrics.accuracy_score(y_test,yhat_tr)\n",
    "    acc[i,1] = metrics.accuracy_score(y_test,yhat_nn1)\n",
    "    acc[i,2] = metrics.accuracy_score(y_test,yhat_nn3)\n",
    "    acc[i,3] = metrics.accuracy_score(y_test,yhat_svm10)\n",
    "    acc[i,4] = metrics.accuracy_score(y_test,yhat_svm100)\n",
    "    acc[i,5] = metrics.accuracy_score(y_test,yhat_svm1000)\n",
    "    acc[i,6] = metrics.accuracy_score(y_test,yhat_GBC)\n",
    "    acc[i,7] = metrics.accuracy_score(y_test,yhat_clf)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-66ef512d77f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# FC Histogram\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY_aut\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FC'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdensity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_aut\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FC'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of FC classes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Frequency'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mhist\u001b[0;34m(x, bins, range, density, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, normed, hold, data, **kwargs)\u001b[0m\n\u001b[1;32m   3130\u001b[0m                       \u001b[0mhisttype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhisttype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3131\u001b[0m                       \u001b[0mrwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3132\u001b[0;31m                       stacked=stacked, normed=normed, data=data, **kwargs)\n\u001b[0m\u001b[1;32m   3133\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3134\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1853\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1855\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mhist\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   6604\u001b[0m                 patch = _barfunc(bins[:-1]+boffset, height, width,\n\u001b[1;32m   6605\u001b[0m                                  \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'center'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6606\u001b[0;31m                                  color=c, **{bottom_kwarg: bottom})\n\u001b[0m\u001b[1;32m   6607\u001b[0m                 \u001b[0mpatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6608\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstacked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1853\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1855\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2276\u001b[0m                 \u001b[0medgecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2277\u001b[0m                 \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2278\u001b[0;31m                 \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'_nolegend_'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2279\u001b[0m                 )\n\u001b[1;32m   2280\u001b[0m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/patches.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, xy, width, height, angle, **kwargs)\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_height\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mangle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mangle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m         \u001b[0;31m# Note: This cannot be calculated until this is added to an Axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rect_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIdentityTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# FREQUENCY PLOT\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "\n",
    "# FC Histogram\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.hist(x=Y_aut['FC'],density=1, bins=int(np.max(Y_aut['FC']))) \n",
    "plt.xlabel('Number of FC classes')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlim(0, 35)\n",
    "\n",
    "# FC Histogram\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.hist(x=Y_aut['RT'],density=1, bins=int(np.max(Y_aut['RT']))) \n",
    "plt.xlabel('Number of RT classes')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlim(0, 12.5)\n",
    "\n",
    "y_FC35 = sorted(np.where(Y_aut['FC']>35)[0])\n",
    "y_RT35 = sorted(np.where(Y_aut['RT']>35)[0])\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.hist(x=y_FC35, bins=int(np.max(Y_aut['FC'])/10)) \n",
    "plt.subplot(2, 2, 4)\n",
    "plt.hist(x=y_RT35, bins=int(np.max(Y_aut['RT'])/10)) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1922, 4)\n",
      "(1922, 1)\n"
     ]
    }
   ],
   "source": [
    "X_aut_pois_FC_menys15 = X_aut[X_aut['FC']<3]\n",
    "X_aut_pois_RT_menys15 = X_aut[X_aut['RT']<3]\n",
    "\n",
    "X_aut_pois_FC_mes15 = X_aut[X_aut['FC']>5]\n",
    "X_aut_pois_RT_mes15 = X_aut[X_aut['RT']>5]\n",
    "\n",
    "\n",
    "Y_aut_RT =  X_aut_pois_RT_menys15[['RT']]\n",
    "Y_aut_FC =  X_aut_pois_FC_menys15[['FC']]\n",
    "\n",
    "\n",
    "\n",
    "X_aut_new_RT = X_aut_pois_RT_menys15.drop(['FC','RT'], axis=1)\n",
    "X_aut_new_FC = X_aut_pois_FC_menys15.drop(['RT'], axis=1)\n",
    "\n",
    "print(X_aut_new_RT.shape)\n",
    "\n",
    "print(Y_aut_RT.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.804159445407279"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn import neighbors\n",
    "from sklearn import svm\n",
    "from sklearn import ensemble\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X_aut_new_RT,Y_aut_RT,test_size=0.3,train_size=0.7,random_state=42)\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X_aut_new_RT,Y_aut_RT,test_size=0.3,train_size=0.7,random_state=42)\n",
    "GBC = ensemble.GradientBoostingClassifier(random_state=42)\n",
    "GBC.fit(X_train,y_train)\n",
    "yhat_GBC = GBC.predict(X_test)\n",
    "metrics.accuracy_score(y_test,yhat_GBC)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './tweet.csv'\n",
    "data = pd.read_csv(filename, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "1060974074799775746    2\n",
       "1060975078630809600    2\n",
       "1060976088380256256    2\n",
       "1060974115832676353    2\n",
       "1060975059559481350    2\n",
       "1061341603984490496    2\n",
       "1060975842304638977    2\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hi ha més d'un tweet per 'id' en alguns casos (màxim 4)\n",
    "ctrl_01 = data.groupby('id').id.count()\n",
    "ctrl_01.sort_values().tail(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check number of zeros in  'FC' and 'RT' of our sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Una accuarcy semblant a aquest ratios seria dolenta, ha de ser molt més\n",
      "0.40010965246261154 0.6620267430172703\n"
     ]
    }
   ],
   "source": [
    "zero_ratio_FC = data.loc[data.index[data['FC'] > 0]].shape[0]/data.shape[0]\n",
    "zero_ratio_RT = data.loc[data.index[data['RT'] > 0]].shape[0]/data.shape[0]\n",
    "\n",
    "print('Una accuarcy semblant a aquest ratios seria dolenta, ha de ser molt més')\n",
    "print(1-zero_ratio_FC, 1-zero_ratio_RT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>j_user</th>\n",
       "      <th>created_at</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1046429145914384386</td>\n",
       "      <td>Desde el #FCJumilla damos nuestra más sincera ...</td>\n",
       "      <td>{'id': 2664945430, 'id_str': '2664945430', 'na...</td>\n",
       "      <td>2018-09-30 15:58:44</td>\n",
       "      <td>{'hashtags': [{'text': 'FCJumilla', 'indices':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1044060298443919367</td>\n",
       "      <td>Me estoy volviendo loca hasta por cada una de ...</td>\n",
       "      <td>{'id': 713359736, 'id_str': '713359736', 'name...</td>\n",
       "      <td>2018-09-24 03:05:47</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1046424001214648320</td>\n",
       "      <td>🏟 | El #FCJumilla ya está en La Condomina   ⚽️...</td>\n",
       "      <td>{'id': 2664945430, 'id_str': '2664945430', 'na...</td>\n",
       "      <td>2018-09-30 15:38:18</td>\n",
       "      <td>{'hashtags': [{'text': 'FCJumilla', 'indices':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1046419267279818752</td>\n",
       "      <td>📹 | El vestuario del #FCJumilla en La Condomin...</td>\n",
       "      <td>{'id': 2664945430, 'id_str': '2664945430', 'na...</td>\n",
       "      <td>2018-09-30 15:19:29</td>\n",
       "      <td>{'hashtags': [{'text': 'FCJumilla', 'indices':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1046417005451128832</td>\n",
       "      <td>📑 Jornada 6 | El colegiado andaluz Guzmán Mans...</td>\n",
       "      <td>{'id': 2664945430, 'id_str': '2664945430', 'na...</td>\n",
       "      <td>2018-09-30 15:10:30</td>\n",
       "      <td>{'hashtags': [{'text': 'UCAMMurciaJumilla', 'i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                              Tweet  \\\n",
       "0  1046429145914384386  Desde el #FCJumilla damos nuestra más sincera ...   \n",
       "1  1044060298443919367  Me estoy volviendo loca hasta por cada una de ...   \n",
       "2  1046424001214648320  🏟 | El #FCJumilla ya está en La Condomina   ⚽️...   \n",
       "3  1046419267279818752  📹 | El vestuario del #FCJumilla en La Condomin...   \n",
       "4  1046417005451128832  📑 Jornada 6 | El colegiado andaluz Guzmán Mans...   \n",
       "\n",
       "                                              j_user           created_at  \\\n",
       "0  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:58:44   \n",
       "1  {'id': 713359736, 'id_str': '713359736', 'name...  2018-09-24 03:05:47   \n",
       "2  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:38:18   \n",
       "3  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:19:29   \n",
       "4  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:10:30   \n",
       "\n",
       "                                            entities  \n",
       "0  {'hashtags': [{'text': 'FCJumilla', 'indices':...  \n",
       "1  {'hashtags': [], 'symbols': [], 'user_mentions...  \n",
       "2  {'hashtags': [{'text': 'FCJumilla', 'indices':...  \n",
       "3  {'hashtags': [{'text': 'FCJumilla', 'indices':...  \n",
       "4  {'hashtags': [{'text': 'UCAMMurciaJumilla', 'i...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.drop(['Unnamed: 0','FC','RT','trending_topic','followers_user','trending_topic'], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FC</th>\n",
       "      <th>RT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FC  RT\n",
       "0  18   4\n",
       "1   0   0\n",
       "2   4   2\n",
       "3  21   6\n",
       "4   0   0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = data[['FC','RT']]\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# FREQUENCY PLOT\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "\n",
    "# FC Histogram\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.hist(x=Y['FC'],density=1, bins=int(np.max(Y['FC']))) \n",
    "plt.xlabel('Number of FC classes')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlim(0, 35)\n",
    "\n",
    "# FC Histogram\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.hist(x=Y['RT'],density=1, bins=int(np.max(Y['RT']))) \n",
    "plt.xlabel('Number of RT classes')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlim(0, 12.5)\n",
    "\n",
    "y_FC35 = sorted(np.where(Y['FC']>35)[0])\n",
    "y_RT35 = sorted(np.where(Y['RT']>35)[0])\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.hist(x=y_FC35, bins=int(np.max(Y['FC'])/10)) \n",
    "plt.subplot(2, 2, 4)\n",
    "plt.hist(x=y_RT35, bins=int(np.max(Y['RT'])/10)) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resum: La majoria de 'FC' es concentra entre 0 i 10 i entre 0 i 5 a 'RT'. Això podria infuir a l'hora de fer els models xq la BBDD de tweets amb 'FC' i 'RT' es molt petita i la predicció serà dolenta. No els podem considerar Outliers perquè realment no ho són (gent famosa per exemple). Hauriem de fer diferents models per diferents grups de persones, és a dir, en funció de la mitja dels RT i FC anteriors aplicar-li un model o altres. Podem separar la mostra no per FC i RT sinó per RT_l10, sd_RT, FC_l10 i/o sd_FC que ve de la bbdd 'author'. L'aplicació podria aplicarte un model o un altre amb els paràmetres estimats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2410 1539 32831\n"
     ]
    }
   ],
   "source": [
    "print(len(np.where(Y['FC']>35)[0]), len(np.where(Y['RT']>35)[0]), len(Y)) #2410 1539 32831"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La següent funció assigna una classe a cada interval. En total 137 classes 137 intervals. A mesura que els FC i els RT augmenten també augmenta l'amplada del interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class segmenta():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.intervals = {}\n",
    "    \n",
    "    def transform(self,y):\n",
    "        k, z = 0, 0\n",
    "        for a, b in [[15,5],\n",
    "                     [100,5],\n",
    "                     [200,10],\n",
    "                     [500,20],\n",
    "                     [1000,50],\n",
    "                     [5000,100],\n",
    "                     [10000,500],\n",
    "                     [50000,2000]]: \n",
    "            for i in np.arange(z,a,b):\n",
    "                self.intervals[k] = [i,i+b-1]\n",
    "                k+=1\n",
    "            z = a\n",
    "        self.intervals[k] = [50000,99999999]\n",
    "\n",
    "        y = np.reshape(y.values, (-1,1))\n",
    "        for j in self.intervals:\n",
    "            c = self.intervals[j]\n",
    "            idx = np.where(np.logical_and(y>=c[0],y<=c[1]))[0]\n",
    "            y[idx] = j\n",
    "\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "Y = data[['FC','RT']]\n",
    "\n",
    "segFC = segmenta()\n",
    "Y['FC'] = segFC.transform(Y['FC'])\n",
    "\n",
    "segRT = segmenta()\n",
    "Y['RT'] = segRT.transform(Y['RT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FC</th>\n",
       "      <th>RT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32826</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32827</th>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32828</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32829</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32830</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       FC  RT\n",
       "32826   2   0\n",
       "32827  20  12\n",
       "32828   8   4\n",
       "32829   0   0\n",
       "32830   1   0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location i Tweets###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import re #regular expressions\n",
    "import unidecode as udc\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from unicodedata import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['location'] = [ast.literal_eval(data['j_user'][i])['location'] for i in range(X.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>j_user</th>\n",
       "      <th>created_at</th>\n",
       "      <th>entities</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1046429145914384386</td>\n",
       "      <td>Desde el #FCJumilla damos nuestra más sincera ...</td>\n",
       "      <td>{'id': 2664945430, 'id_str': '2664945430', 'na...</td>\n",
       "      <td>2018-09-30 15:58:44</td>\n",
       "      <td>{'hashtags': [{'text': 'FCJumilla', 'indices':...</td>\n",
       "      <td>Jumilla, España</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1044060298443919367</td>\n",
       "      <td>Me estoy volviendo loca hasta por cada una de ...</td>\n",
       "      <td>{'id': 713359736, 'id_str': '713359736', 'name...</td>\n",
       "      <td>2018-09-24 03:05:47</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>Atlantida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1046424001214648320</td>\n",
       "      <td>🏟 | El #FCJumilla ya está en La Condomina   ⚽️...</td>\n",
       "      <td>{'id': 2664945430, 'id_str': '2664945430', 'na...</td>\n",
       "      <td>2018-09-30 15:38:18</td>\n",
       "      <td>{'hashtags': [{'text': 'FCJumilla', 'indices':...</td>\n",
       "      <td>Jumilla, España</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1046419267279818752</td>\n",
       "      <td>📹 | El vestuario del #FCJumilla en La Condomin...</td>\n",
       "      <td>{'id': 2664945430, 'id_str': '2664945430', 'na...</td>\n",
       "      <td>2018-09-30 15:19:29</td>\n",
       "      <td>{'hashtags': [{'text': 'FCJumilla', 'indices':...</td>\n",
       "      <td>Jumilla, España</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1046417005451128832</td>\n",
       "      <td>📑 Jornada 6 | El colegiado andaluz Guzmán Mans...</td>\n",
       "      <td>{'id': 2664945430, 'id_str': '2664945430', 'na...</td>\n",
       "      <td>2018-09-30 15:10:30</td>\n",
       "      <td>{'hashtags': [{'text': 'UCAMMurciaJumilla', 'i...</td>\n",
       "      <td>Jumilla, España</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                              Tweet  \\\n",
       "0  1046429145914384386  Desde el #FCJumilla damos nuestra más sincera ...   \n",
       "1  1044060298443919367  Me estoy volviendo loca hasta por cada una de ...   \n",
       "2  1046424001214648320  🏟 | El #FCJumilla ya está en La Condomina   ⚽️...   \n",
       "3  1046419267279818752  📹 | El vestuario del #FCJumilla en La Condomin...   \n",
       "4  1046417005451128832  📑 Jornada 6 | El colegiado andaluz Guzmán Mans...   \n",
       "\n",
       "                                              j_user           created_at  \\\n",
       "0  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:58:44   \n",
       "1  {'id': 713359736, 'id_str': '713359736', 'name...  2018-09-24 03:05:47   \n",
       "2  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:38:18   \n",
       "3  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:19:29   \n",
       "4  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:10:30   \n",
       "\n",
       "                                            entities         location  \n",
       "0  {'hashtags': [{'text': 'FCJumilla', 'indices':...  Jumilla, España  \n",
       "1  {'hashtags': [], 'symbols': [], 'user_mentions...        Atlantida  \n",
       "2  {'hashtags': [{'text': 'FCJumilla', 'indices':...  Jumilla, España  \n",
       "3  {'hashtags': [{'text': 'FCJumilla', 'indices':...  Jumilla, España  \n",
       "4  {'hashtags': [{'text': 'UCAMMurciaJumilla', 'i...  Jumilla, España  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1a Opció: Token, analyze, ...\n",
    "\n",
    "Script Núria en el que es treuen les paraules que no aporten informació com conectors, articles, ... per utilitzaro com a stop words en el 'CountVectorizer':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './eliminar_paraules.xlsx'\n",
    "elim = pd.read_excel(filename, header=None)\n",
    "\n",
    "y=elim[0]\n",
    "for i in range(len(elim)):\n",
    "    y[i] = re.sub(\n",
    "            r\"([^n\\u0300-\\u036f]|n(?!\\u0303(?![\\u0300-\\u036f])))[\\u0300-\\u036f]+\", r\"\\1\", \n",
    "            normalize( \"NFD\", y[i]), 0, re.I)\n",
    "y = y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer1 = CountVectorizer(min_df=0.0001, stop_words=y, strip_accents='unicode') # Tweets \n",
    "vectorizer2 = CountVectorizer(min_df=0.001, stop_words=y, strip_accents='unicode') # location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLASSIFIERS ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifiers importation\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn import neural_network\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Others\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model, metrics, model_selection\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [ neural_network.MLPClassifier(),\n",
    "                linear_model.LogisticRegression(),\n",
    "                KNeighborsClassifier(3),\n",
    "                SVC(kernel=\"rbf\", C=1, probability=True),\n",
    "#               NuSVC(probability=True),\n",
    "                DecisionTreeClassifier(),\n",
    "                RandomForestClassifier(),\n",
    "                AdaBoostClassifier(),\n",
    "                GradientBoostingClassifier(),\n",
    "                GaussianNB(),\n",
    "                BernoulliNB()\n",
    "#               LinearDiscriminantAnalysis(),\n",
    "#               QuadraticDiscriminantAnalysis()\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FC\n",
    "Y_FC = Y['FC']\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X,Y_FC,test_size=0.3,train_size=0.7,random_state=42)\n",
    "\n",
    "#Process and convert data \n",
    "a1 = vectorizer1.fit_transform(X_train['Tweet'])\n",
    "a1 = a1.todense()                                                                                                                                                                                                                                         \n",
    "#a2 = vectorizer2.fit_transform(X_train['location'])\n",
    "#a2 = a2.todense() \n",
    "#X_train = np.concatenate((a1, a2), axis=1)\n",
    "X_train = a1\n",
    "y_train = y_train.values\n",
    "\n",
    "b1 = vectorizer1.transform(X_test['Tweet'])\n",
    "b1 = b1.todense()\n",
    "#b2 = vectorizer2.transform(X_test['location'])\n",
    "#b2 = b2.todense()\n",
    "#X_test = np.concatenate((b1, b2), axis=1)\n",
    "X_test = b1\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22981, 9871)\n",
      "(9850, 9871)\n",
      "0.9676689439101867\n",
      "0.9602030456852791\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "# Percentatge número de files amb tot zeros despres de natejar la bbdd (X_train i X_test)\n",
    "print(X_train[np.where(X_train.sum(axis=1)>0)].shape[1]/X_train.shape[0])\n",
    "print(X_test[np.where(X_test.sum(axis=1)>0)].shape[1]/X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier 0.7068020304568527\n",
      "LogisticRegression 0.7751269035532995\n"
     ]
    }
   ],
   "source": [
    "# Logging for Visual Comparison\n",
    "log_cols=[\"Classifier\", \"Accuracy\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "for clf in classifiers:\n",
    "\n",
    "    clf.fit(X_train,y_train)\n",
    "    name = clf.__class__.__name__\n",
    "\n",
    "    yhat = clf.predict(X_test).reshape(-1,1)\n",
    "    acc = metrics.accuracy_score(y_test, yhat)  \n",
    "    print(name, acc)\n",
    "    yhat_prob = clf.predict_proba(X_test)\n",
    "\n",
    "    log_entry = pd.DataFrame([[name, acc*100]], columns=log_cols)\n",
    "    log = log.append(log_entry)\n",
    "\n",
    "# ACCURACY GRAPHIC \n",
    "sns.set_color_codes(\"muted\")\n",
    "sns.barplot(x='Accuracy', y='Classifier', data=log, color=\"b\")\n",
    "\n",
    "plt.xlabel('Accuracy %')\n",
    "plt.title('Classifier Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>73.801816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>59.091986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Classifier   Accuracy\n",
       "0       MLPClassifier  73.801816\n",
       "0  LogisticRegression  59.091986"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RT\n",
    "Y_RT = Y['RT']\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X,Y_RT,test_size=0.3,train_size=0.7,random_state=42)\n",
    "\n",
    "#Process and convert data \n",
    "a1 = vectorizer1.fit_transform(X_train['Tweet'])\n",
    "a1 = a1.todense()                                                                                                                                                                                                                                         \n",
    "#a2 = vectorizer2.fit_transform(X_train['location'])\n",
    "#a2 = a2.todense() \n",
    "#X_train = np.concatenate((a1, a2), axis=1)\n",
    "X_train = a1\n",
    "y_train = y_train.values\n",
    "\n",
    "b1 = vectorizer1.transform(X_test['Tweet'])\n",
    "b1 = b1.todense()\n",
    "#b2 = vectorizer2.transform(X_test['location'])\n",
    "#b2 = b2.todense()\n",
    "#X_test = np.concatenate((b1, b2), axis=1)\n",
    "X_test = b1\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "# Percentatge número de files amb tot zeros despres de natejar la bbdd (X_train i X_test)\n",
    "print(X_train[np.where(X_train.sum(axis=1)>0)].shape[1]/X_train.shape[0])\n",
    "print(X_test[np.where(X_test.sum(axis=1)>0)].shape[1]/X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging for Visual Comparison\n",
    "log_cols=[\"Classifier\", \"Accuracy\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "for clf in classifiers:\n",
    "\n",
    "    clf.fit(X_train,y_train)\n",
    "    name = clf.__class__.__name__\n",
    "\n",
    "    yhat = clf.predict(X_test).reshape(-1,1)\n",
    "    acc = metrics.accuracy_score(y_test, yhat)   \n",
    "    yhat_prob = clf.predict_proba(X_test)\n",
    "\n",
    "    log_entry = pd.DataFrame([[name, acc*100]], columns=log_cols)\n",
    "    log = log.append(log_entry)\n",
    "\n",
    "# ACCURACY GRAPHIC \n",
    "sns.set_color_codes(\"muted\")\n",
    "sns.barplot(x='Accuracy', y='Classifier', data=log, color=\"b\")\n",
    "\n",
    "plt.xlabel('Accuracy %')\n",
    "plt.title('Classifier Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(Y_RT)\n",
    "\n",
    "y[y <= 215] = 1\n",
    "y[y > 250] = 0\n",
    "\n",
    "print(len(y[y==0]))\n",
    "print(len(y[y==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn import neighbors\n",
    "from sklearn import svm\n",
    "from sklearn import ensemble\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "###for RT\n",
    "r_state = [0,1,2,3,4,5,42,43,44,45]\n",
    "\n",
    "acc = np.zeros((len(r_state),8))\n",
    "\n",
    "for i in range(len(r_state)):\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size=0.7, random_state=r_state[i])\n",
    "    \n",
    "    #Your code here\n",
    "    scaler = StandardScaler()\n",
    "    scaler = scaler.fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    \n",
    "    nn1 = neighbors.KNeighborsClassifier(n_neighbors=1) #1NN\n",
    "    nn1.fit(X_train_scaled,y_train)\n",
    "    yhat_nn1 = nn1.predict(X_test_scaled) \n",
    "\n",
    "    nn3 = neighbors.KNeighborsClassifier(n_neighbors=3) #3NN\n",
    "    nn3.fit(X_train_scaled,y_train)\n",
    "    yhat_nn3 = nn3.predict(X_test_scaled) \n",
    "    \n",
    "    tr = tree.DecisionTreeClassifier() #Decision Tree\n",
    "    tr.fit(X_train_scaled,y_train)\n",
    "    yhat_tr = tr.predict(X_test_scaled)\n",
    "    \n",
    "    svm10 = svm.SVC(C=10.0,gamma = 1e-5,random_state=42) \n",
    "    svm10.fit(X_train_scaled,y_train)\n",
    "    yhat_svm10 = svm10.predict(X_test_scaled)\n",
    "    \n",
    "    svm100 = svm.SVC(C=100.0,gamma = 1e-5,random_state=42)\n",
    "    svm100.fit(X_train_scaled,y_train)\n",
    "    yhat_svm100= svm100.predict(X_test_scaled)\n",
    "    \n",
    "    svm1000 = svm.SVC(C=1000.0,gamma = 1e-6,random_state=42)\n",
    "    svm1000.fit(X_train_scaled,y_train)\n",
    "    yhat_svm1000 = svm1000.predict(X_test_scaled)\n",
    "    \n",
    "    GBC = ensemble.GradientBoostingClassifier(random_state=42)\n",
    "    GBC.fit(X_train_scaled,y_train)\n",
    "    yhat_GBC = GBC.predict(X_test_scaled)\n",
    "    \n",
    "    clf = KMeans(n_clusters=2)\n",
    "    clf.fit(X_train_scaled,y_train)\n",
    "    yhat_clf = clf.predict(X_test_scaled)\n",
    "    \n",
    "    acc[i,0] = metrics.accuracy_score(y_test,yhat_tr)\n",
    "    acc[i,1] = metrics.accuracy_score(y_test,yhat_nn1)\n",
    "    acc[i,2] = metrics.accuracy_score(y_test,yhat_nn3)\n",
    "    acc[i,3] = metrics.accuracy_score(y_test,yhat_svm10)\n",
    "    acc[i,4] = metrics.accuracy_score(y_test,yhat_svm100)\n",
    "    acc[i,5] = metrics.accuracy_score(y_test,yhat_svm1000)\n",
    "    acc[i,6] = metrics.accuracy_score(y_test,yhat_GBC)\n",
    "    acc[i,7] = metrics.accuracy_score(y_test,yhat_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
