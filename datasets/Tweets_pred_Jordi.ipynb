{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>j_user</th>\n",
       "      <th>created_at</th>\n",
       "      <th>followers_user</th>\n",
       "      <th>FC</th>\n",
       "      <th>RT</th>\n",
       "      <th>trending_topic</th>\n",
       "      <th>hashtags_text</th>\n",
       "      <th>id</th>\n",
       "      <th>hour</th>\n",
       "      <th>class_rt</th>\n",
       "      <th>class_fc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Desde el #FCJumilla damos nuestra m√°s sincera ...</td>\n",
       "      <td>{'id': 2664945430, 'id_str': '2664945430', 'na...</td>\n",
       "      <td>2018-09-30 15:58:44</td>\n",
       "      <td>7162</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0                     [ 'FCJumilla']\\r\\n1     ...</td>\n",
       "      <td>2.664945e+09</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Me estoy volviendo loca hasta por cada una de ...</td>\n",
       "      <td>{'id': 713359736, 'id_str': '713359736', 'name...</td>\n",
       "      <td>2018-09-24 03:05:47</td>\n",
       "      <td>531</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0                     [ 'FCJumilla']\\r\\n1     ...</td>\n",
       "      <td>7.133597e+08</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>üèü | El #FCJumilla ya est√° en La Condomina   ‚öΩÔ∏è...</td>\n",
       "      <td>{'id': 2664945430, 'id_str': '2664945430', 'na...</td>\n",
       "      <td>2018-09-30 15:38:18</td>\n",
       "      <td>7162</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0                     [ 'FCJumilla']\\r\\n1     ...</td>\n",
       "      <td>2.664945e+09</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>üìπ | El vestuario del #FCJumilla en La Condomin...</td>\n",
       "      <td>{'id': 2664945430, 'id_str': '2664945430', 'na...</td>\n",
       "      <td>2018-09-30 15:19:29</td>\n",
       "      <td>7162</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0                     [ 'FCJumilla']\\r\\n1     ...</td>\n",
       "      <td>2.664945e+09</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>üìë Jornada 6 | El colegiado andaluz Guzm√°n Mans...</td>\n",
       "      <td>{'id': 2664945430, 'id_str': '2664945430', 'na...</td>\n",
       "      <td>2018-09-30 15:10:30</td>\n",
       "      <td>7162</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0                     [ 'FCJumilla']\\r\\n1     ...</td>\n",
       "      <td>2.664945e+09</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              Tweet  \\\n",
       "0           0  Desde el #FCJumilla damos nuestra m√°s sincera ...   \n",
       "1           1  Me estoy volviendo loca hasta por cada una de ...   \n",
       "2           2  üèü | El #FCJumilla ya est√° en La Condomina   ‚öΩÔ∏è...   \n",
       "3           3  üìπ | El vestuario del #FCJumilla en La Condomin...   \n",
       "4           4  üìë Jornada 6 | El colegiado andaluz Guzm√°n Mans...   \n",
       "\n",
       "                                              j_user           created_at  \\\n",
       "0  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:58:44   \n",
       "1  {'id': 713359736, 'id_str': '713359736', 'name...  2018-09-24 03:05:47   \n",
       "2  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:38:18   \n",
       "3  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:19:29   \n",
       "4  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:10:30   \n",
       "\n",
       "   followers_user  FC  RT  trending_topic  \\\n",
       "0            7162  18   4             0.0   \n",
       "1             531   0   0             0.0   \n",
       "2            7162   4   2             0.0   \n",
       "3            7162  21   6             0.0   \n",
       "4            7162   0   0             0.0   \n",
       "\n",
       "                                       hashtags_text            id  hour  \\\n",
       "0  0                     [ 'FCJumilla']\\r\\n1     ...  2.664945e+09  15.0   \n",
       "1  0                     [ 'FCJumilla']\\r\\n1     ...  7.133597e+08   3.0   \n",
       "2  0                     [ 'FCJumilla']\\r\\n1     ...  2.664945e+09  15.0   \n",
       "3  0                     [ 'FCJumilla']\\r\\n1     ...  2.664945e+09  15.0   \n",
       "4  0                     [ 'FCJumilla']\\r\\n1     ...  2.664945e+09  15.0   \n",
       "\n",
       "   class_rt  class_fc  \n",
       "0       0.0       1.0  \n",
       "1       0.0       0.0  \n",
       "2       0.0       1.0  \n",
       "3       0.0       1.0  \n",
       "4       0.0       1.0  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = pd.read_csv('tweet_amb_ids_match.csv')\n",
    "file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y0\n",
      "0.8628735037007706\n",
      "[13136  7007  2861  1557  1090   763   544   431   374   566]\n",
      "\n",
      "y1:\n",
      "0.08653406841095307\n",
      "[1320  530  291  211  138  110   72   55   63   51]\n",
      "\n",
      "y2:\n",
      "0.02823550912247571\n",
      "[298 144  95  75  67  60  60  40  45  43]\n",
      "\n",
      "y3:\n",
      "0.014407115226462795\n",
      "[126  79  63  50  44  25  22  19  23  22]\n",
      "\n",
      "y4:\n",
      "0.007949803539337821\n",
      "[143  55  19  20   7   8   2   1   4   2]\n"
     ]
    }
   ],
   "source": [
    "print('y0')\n",
    "y0_fc = Y_FC[np.asarray(Y_FC)<=10]\n",
    "pes0 = (np.asarray(y0_fc).shape[0])/(np.asarray(Y_FC).shape[0])\n",
    "print(pes0)\n",
    "hist, bin_edges = np.histogram(y0_fc)\n",
    "print(hist)\n",
    "print('\\ny1:')\n",
    "y1_fc = Y_FC[np.asarray(Y_FC)>10]\n",
    "y1_fc = y1_fc[np.asarray(y1_fc)<=100]\n",
    "pes1 = (np.asarray(y1_fc).shape[0])/(np.asarray(Y_FC).shape[0])\n",
    "print(pes1)\n",
    "hist, bin_edges = np.histogram(y1_fc)\n",
    "print(hist)\n",
    "print('\\ny2:')\n",
    "y2_fc = Y_FC[np.asarray(Y_FC)>100]\n",
    "y2_fc = y2_fc[np.asarray(y2_fc)<=1000]\n",
    "pes2 = (np.asarray(y2_fc).shape[0])/(np.asarray(Y_FC).shape[0])\n",
    "print(pes2)\n",
    "hist, bin_edges = np.histogram(y2_fc)\n",
    "print(hist)\n",
    "print('\\ny3:')\n",
    "y3_fc = Y_FC[np.asarray(Y_FC)>1000]\n",
    "y3_fc = y3_fc[np.asarray(y3_fc)<=5000]\n",
    "pes3 = (np.asarray(y3_fc).shape[0])/(np.asarray(Y_FC).shape[0])\n",
    "print(pes3)\n",
    "hist, bin_edges = np.histogram(y3_fc)\n",
    "print(hist)\n",
    "print('\\ny4:')\n",
    "y4_fc = Y_FC[np.asarray(Y_FC)>5000]\n",
    "pes4 = (np.asarray(y4_fc).shape[0])/(np.asarray(Y_FC).shape[0])\n",
    "print(pes4)\n",
    "hist, bin_edges = np.histogram(y4_fc)\n",
    "print(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y0\n",
      "0.8800219304925223\n",
      "[21735     0  3741     0  1460     0   912     0   627   417]\n",
      "\n",
      "y1:\n",
      "0.05948646096676921\n",
      "[597 210 349 145 127 185  84 113  54  89]\n",
      "\n",
      "y2:\n",
      "0.030002132131217447\n",
      "[293 173 122  92  78  62  59  46  39  21]\n",
      "\n",
      "y3:\n",
      "0.019311017026590722\n",
      "[145 104  85  59  62  32  46  39  33  29]\n",
      "\n",
      "y4:\n",
      "0.011178459382900307\n",
      "[269  47  20   7   8   6   4   1   3   2]\n",
      "\n",
      " Suma de pesos: 1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "# Separem Y_RT entre 5 grups: aquells que tenen menys de 5, aquells que tenen entre 6- 20, \n",
    "# aquells que tenen entre 21 - 100, aquells que tenen entre 100 i 500 i aquells que tenen mes de 500\n",
    "# Fem 4 models, nomes per aquells que tenen a partir de 6\n",
    "\n",
    "print('y0')\n",
    "y0_rt = Y_RT[np.asarray(Y_RT)<=5]\n",
    "pes0 = (np.asarray(y0_rt).shape[0])/(np.asarray(Y_RT).shape[0])\n",
    "print(pes0)\n",
    "hist, bin_edges = np.histogram(y0_rt)\n",
    "print(hist)\n",
    "print('\\ny1:')\n",
    "y1_rt = Y_RT[np.asarray(Y_RT)>5]\n",
    "y1_rt = y1_rt[np.asarray(y1_rt)<=20]\n",
    "pes1 = (np.asarray(y1_rt).shape[0])/(np.asarray(Y_RT).shape[0])\n",
    "print(pes1)\n",
    "hist, bin_edges = np.histogram(y1_rt)\n",
    "print(hist)\n",
    "print('\\ny2:')\n",
    "y2_rt = Y_RT[np.asarray(Y_RT)>20]\n",
    "y2_rt = y2_rt[np.asarray(y2_rt)<=100]\n",
    "pes2 = (np.asarray(y2_rt).shape[0])/(np.asarray(Y_RT).shape[0])\n",
    "print(pes2)\n",
    "hist, bin_edges = np.histogram(y2_rt)\n",
    "print(hist)\n",
    "print('\\ny3:')\n",
    "y3_rt = Y_RT[np.asarray(Y_RT)>100]\n",
    "y3_rt = y3_rt[np.asarray(y3_rt)<=500]\n",
    "pes3 = (np.asarray(y3_rt).shape[0])/(np.asarray(Y_RT).shape[0])\n",
    "print(pes3)\n",
    "hist, bin_edges = np.histogram(y3_rt)\n",
    "print(hist)\n",
    "print('\\ny4:')\n",
    "y4_rt = Y_RT[np.asarray(Y_RT)>500]\n",
    "pes4 = (np.asarray(y4_rt).shape[0])/(np.asarray(Y_RT).shape[0])\n",
    "print(pes4)\n",
    "hist, bin_edges = np.histogram(y4_rt)\n",
    "print(hist)\n",
    "\n",
    "print('\\n Suma de pesos:', pes0+pes1+pes2+pes3+pes4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "file['class_fc'] = np.zeros(file.shape[0])\n",
    "file['class_rt'] = np.zeros(file.shape[0])\n",
    "\n",
    "file['class_fc'][y1_fc.index] = 1\n",
    "file['class_fc'][y2_fc.index] = 2\n",
    "file['class_fc'][y3_fc.index] = 3\n",
    "file['class_fc'][y4_fc.index] = 4\n",
    "\n",
    "file['class_rt'][y1_rt.index] = 1\n",
    "file['class_rt'][y2_rt.index] = 2\n",
    "file['class_rt'][y3_rt.index] = 3\n",
    "file['class_rt'][y4_rt.index] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>j_user</th>\n",
       "      <th>created_at</th>\n",
       "      <th>followers_user</th>\n",
       "      <th>FC</th>\n",
       "      <th>RT</th>\n",
       "      <th>trending_topic</th>\n",
       "      <th>hashtags_text</th>\n",
       "      <th>id</th>\n",
       "      <th>hour</th>\n",
       "      <th>class_rt</th>\n",
       "      <th>class_fc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Desde el #FCJumilla damos nuestra m√°s sincera ...</td>\n",
       "      <td>{'id': 2664945430, 'id_str': '2664945430', 'na...</td>\n",
       "      <td>2018-09-30 15:58:44</td>\n",
       "      <td>7162</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0                     [ 'FCJumilla']\\r\\n1     ...</td>\n",
       "      <td>2.664945e+09</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Me estoy volviendo loca hasta por cada una de ...</td>\n",
       "      <td>{'id': 713359736, 'id_str': '713359736', 'name...</td>\n",
       "      <td>2018-09-24 03:05:47</td>\n",
       "      <td>531</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0                     [ 'FCJumilla']\\r\\n1     ...</td>\n",
       "      <td>7.133597e+08</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>üèü | El #FCJumilla ya est√° en La Condomina   ‚öΩÔ∏è...</td>\n",
       "      <td>{'id': 2664945430, 'id_str': '2664945430', 'na...</td>\n",
       "      <td>2018-09-30 15:38:18</td>\n",
       "      <td>7162</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0                     [ 'FCJumilla']\\r\\n1     ...</td>\n",
       "      <td>2.664945e+09</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>üìπ | El vestuario del #FCJumilla en La Condomin...</td>\n",
       "      <td>{'id': 2664945430, 'id_str': '2664945430', 'na...</td>\n",
       "      <td>2018-09-30 15:19:29</td>\n",
       "      <td>7162</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0                     [ 'FCJumilla']\\r\\n1     ...</td>\n",
       "      <td>2.664945e+09</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>üìë Jornada 6 | El colegiado andaluz Guzm√°n Mans...</td>\n",
       "      <td>{'id': 2664945430, 'id_str': '2664945430', 'na...</td>\n",
       "      <td>2018-09-30 15:10:30</td>\n",
       "      <td>7162</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0                     [ 'FCJumilla']\\r\\n1     ...</td>\n",
       "      <td>2.664945e+09</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              Tweet  \\\n",
       "0           0  Desde el #FCJumilla damos nuestra m√°s sincera ...   \n",
       "1           1  Me estoy volviendo loca hasta por cada una de ...   \n",
       "2           2  üèü | El #FCJumilla ya est√° en La Condomina   ‚öΩÔ∏è...   \n",
       "3           3  üìπ | El vestuario del #FCJumilla en La Condomin...   \n",
       "4           4  üìë Jornada 6 | El colegiado andaluz Guzm√°n Mans...   \n",
       "\n",
       "                                              j_user           created_at  \\\n",
       "0  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:58:44   \n",
       "1  {'id': 713359736, 'id_str': '713359736', 'name...  2018-09-24 03:05:47   \n",
       "2  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:38:18   \n",
       "3  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:19:29   \n",
       "4  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:10:30   \n",
       "\n",
       "   followers_user  FC  RT  trending_topic  \\\n",
       "0            7162  18   4             0.0   \n",
       "1             531   0   0             0.0   \n",
       "2            7162   4   2             0.0   \n",
       "3            7162  21   6             0.0   \n",
       "4            7162   0   0             0.0   \n",
       "\n",
       "                                       hashtags_text            id  hour  \\\n",
       "0  0                     [ 'FCJumilla']\\r\\n1     ...  2.664945e+09  15.0   \n",
       "1  0                     [ 'FCJumilla']\\r\\n1     ...  7.133597e+08   3.0   \n",
       "2  0                     [ 'FCJumilla']\\r\\n1     ...  2.664945e+09  15.0   \n",
       "3  0                     [ 'FCJumilla']\\r\\n1     ...  2.664945e+09  15.0   \n",
       "4  0                     [ 'FCJumilla']\\r\\n1     ...  2.664945e+09  15.0   \n",
       "\n",
       "   class_rt  class_fc  \n",
       "0       0.0       1.0  \n",
       "1       0.0       0.0  \n",
       "2       0.0       0.0  \n",
       "3       1.0       1.0  \n",
       "4       0.0       0.0  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_0 = file[file['class_fc']==0]\n",
    "aux_1 = file[file['class_fc']==1]\n",
    "aux_2 = file[file['class_fc']==2]\n",
    "aux_3 = file[file['class_fc']==3]\n",
    "aux_4 = file[file['class_fc']==4]\n",
    "y_0 = aux_0['FC']\n",
    "y_1 = aux_1['FC']\n",
    "y_2 = aux_2['FC']\n",
    "y_3 = aux_3['FC']\n",
    "y_4 = aux_4['FC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10\n",
      "11 100\n",
      "101 1000\n",
      "1001 4997\n",
      "5015 77142\n"
     ]
    }
   ],
   "source": [
    "print(min(y_0),max(y_0))\n",
    "print(min(y_1),max(y_1))\n",
    "print(min(y_2),max(y_2))\n",
    "print(min(y_3),max(y_3))\n",
    "print(min(y_4),max(y_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5\n",
      "6 20\n",
      "21 100\n",
      "101 500\n",
      "502 16587\n"
     ]
    }
   ],
   "source": [
    "aux_0 = file[file['class_rt']==0]\n",
    "aux_1 = file[file['class_rt']==1]\n",
    "aux_2 = file[file['class_rt']==2]\n",
    "aux_3 = file[file['class_rt']==3]\n",
    "aux_4 = file[file['class_rt']==4]\n",
    "y_0 = aux_0['RT']\n",
    "y_1 = aux_1['RT']\n",
    "y_2 = aux_2['RT']\n",
    "y_3 = aux_3['RT']\n",
    "y_4 = aux_4['RT']\n",
    "\n",
    "print(min(y_0),max(y_0))\n",
    "print(min(y_1),max(y_1))\n",
    "print(min(y_2),max(y_2))\n",
    "print(min(y_3),max(y_3))\n",
    "print(min(y_4),max(y_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fins aqu√≠ tenim la base de dades d'author i tweet juntes, i s'han afegit dues columnes segons el grup de rt i el grup de fc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ara preparem les dades per aplicar el model que separa en grups a author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model to determine which class\n",
    "\n",
    "#Neural networks\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#for FC\n",
    "\n",
    "r_state = [0,1,2,3,4,5,42,43,44,45]\n",
    "\n",
    "acc = np.zeros((len(r_state),1))\n",
    "\n",
    "for i in range(len(r_state)):\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y_FC, train_size=0.7, random_state=r_state[i])\n",
    "    \n",
    "    #Your code here\n",
    "    scaler = StandardScaler()\n",
    "    scaler = scaler.fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test) \n",
    "\n",
    "    mlp = MLPClassifier() #MLP\n",
    "    mlp.fit(X_train_scaled,y_train)\n",
    "    yhat_mlp = mlp.predict(X_test_scaled) \n",
    "    \n",
    "    acc[i,0] = metrics.accuracy_score(y_test,yhat_mlp)\n",
    "\n",
    "mlp = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn import neighbors\n",
    "from sklearn import svm\n",
    "from sklearn import ensemble\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X_aut_new_RT,Y_aut_RT,test_size=0.3,train_size=0.7,random_state=42)\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X_aut_new_RT,Y_aut_RT,test_size=0.3,train_size=0.7,random_state=42)\n",
    "GBC = ensemble.GradientBoostingClassifier(random_state=42)\n",
    "GBC.fit(X_train,y_train)\n",
    "yhat_GBC = GBC.predict(X_test)\n",
    "metrics.accuracy_score(y_test,yhat_GBC)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aut = './clean_newauthors.csv'\n",
    "data_aut = pd.read_csv(df_aut, sep=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RT_l10</th>\n",
       "      <th>FC_l10</th>\n",
       "      <th>FC</th>\n",
       "      <th>RT</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>listed_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.4</td>\n",
       "      <td>15.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19645.0</td>\n",
       "      <td>662.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4221.0</td>\n",
       "      <td>340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.9</td>\n",
       "      <td>37.2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1133925.0</td>\n",
       "      <td>9745.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5386.0</td>\n",
       "      <td>304.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RT_l10  FC_l10    FC    RT  followers_count  listed_count\n",
       "0     2.4    15.5   0.0   0.0          19645.0         662.0\n",
       "1     0.2     0.8   1.0   0.0           4221.0         340.0\n",
       "2    17.9    37.2  21.0  10.0        1133925.0        9745.0\n",
       "3     0.4     1.7   0.0   0.0           5386.0         304.0\n",
       "4     2.3     3.4   0.0   0.0           1072.0         101.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_aut = data_aut.drop(['Unnamed: 0','sd_RT','sd_FC','friends_count','favourites_count','statuses_count'], axis=1)\n",
    "X_aut.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_aut =  data_aut[['FC','RT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174\n",
      "2204\n"
     ]
    }
   ],
   "source": [
    "y = np.array(Y_aut['RT'])\n",
    "\n",
    "y[y <= 15] = 1\n",
    "y[y > 15] = 0\n",
    "\n",
    "X = X_aut.drop(['FC','RT'], axis=1)\n",
    "\n",
    "print(len(y[y==0]))\n",
    "print(len(y[y==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.92857143 0.93417367 0.94537815 0.92997199 0.93977591 0.93977591\n",
      "  0.94257703 0.06442577]\n",
      " [0.95378151 0.94257703 0.95518207 0.93417367 0.94677871 0.94677871\n",
      "  0.96358543 0.06022409]\n",
      " [0.93277311 0.94257703 0.95238095 0.92857143 0.93837535 0.93837535\n",
      "  0.94817927 0.06722689]\n",
      " [0.93557423 0.92577031 0.94957983 0.92016807 0.92997199 0.92997199\n",
      "  0.94957983 0.92577031]\n",
      " [0.93697479 0.92857143 0.93417367 0.92296919 0.94117647 0.94117647\n",
      "  0.94397759 0.07282913]\n",
      " [0.94537815 0.94117647 0.95798319 0.93557423 0.94537815 0.94537815\n",
      "  0.95798319 0.05882353]\n",
      " [0.95238095 0.94397759 0.96078431 0.94257703 0.95378151 0.95378151\n",
      "  0.96218487 0.05322129]\n",
      " [0.93137255 0.93697479 0.96218487 0.92857143 0.94397759 0.94397759\n",
      "  0.95518207 0.06862745]\n",
      " [0.93417367 0.93977591 0.96498599 0.94257703 0.95378151 0.95378151\n",
      "  0.96078431 0.05182073]\n",
      " [0.94257703 0.94117647 0.95658263 0.93417367 0.94677871 0.94677871\n",
      "  0.95518207 0.06022409]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn import neighbors\n",
    "from sklearn import svm\n",
    "from sklearn import ensemble\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "###for RT\n",
    "r_state = [0,1,2,3,4,5,42,43,44,45]\n",
    "\n",
    "acc = np.zeros((len(r_state),8))\n",
    "\n",
    "for i in range(len(r_state)):\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size=0.7, random_state=r_state[i])\n",
    "    \n",
    "    #Your code here\n",
    "    scaler = StandardScaler()\n",
    "    scaler = scaler.fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    \n",
    "    nn1 = neighbors.KNeighborsClassifier(n_neighbors=1) #1NN\n",
    "    nn1.fit(X_train_scaled,y_train)\n",
    "    yhat_nn1 = nn1.predict(X_test_scaled) \n",
    "\n",
    "    nn3 = neighbors.KNeighborsClassifier(n_neighbors=3) #3NN\n",
    "    nn3.fit(X_train_scaled,y_train)\n",
    "    yhat_nn3 = nn3.predict(X_test_scaled) \n",
    "    \n",
    "    tr = tree.DecisionTreeClassifier() #Decision Tree\n",
    "    tr.fit(X_train_scaled,y_train)\n",
    "    yhat_tr = tr.predict(X_test_scaled)\n",
    "    \n",
    "    svm10 = svm.SVC(C=10.0,gamma = 1e-5,random_state=42) \n",
    "    svm10.fit(X_train_scaled,y_train)\n",
    "    yhat_svm10 = svm10.predict(X_test_scaled)\n",
    "    \n",
    "    svm100 = svm.SVC(C=100.0,gamma = 1e-5,random_state=42)\n",
    "    svm100.fit(X_train_scaled,y_train)\n",
    "    yhat_svm100= svm100.predict(X_test_scaled)\n",
    "    \n",
    "    svm1000 = svm.SVC(C=1000.0,gamma = 1e-6,random_state=42)\n",
    "    svm1000.fit(X_train_scaled,y_train)\n",
    "    yhat_svm1000 = svm1000.predict(X_test_scaled)\n",
    "    \n",
    "    GBC = ensemble.GradientBoostingClassifier(random_state=42)\n",
    "    GBC.fit(X_train_scaled,y_train)\n",
    "    yhat_GBC = GBC.predict(X_test_scaled)\n",
    "    \n",
    "    clf = KMeans(n_clusters=2)\n",
    "    clf.fit(X_train_scaled,y_train)\n",
    "    yhat_clf = clf.predict(X_test_scaled)\n",
    "    \n",
    "    acc[i,0] = metrics.accuracy_score(y_test,yhat_tr)\n",
    "    acc[i,1] = metrics.accuracy_score(y_test,yhat_nn1)\n",
    "    acc[i,2] = metrics.accuracy_score(y_test,yhat_nn3)\n",
    "    acc[i,3] = metrics.accuracy_score(y_test,yhat_svm10)\n",
    "    acc[i,4] = metrics.accuracy_score(y_test,yhat_svm100)\n",
    "    acc[i,5] = metrics.accuracy_score(y_test,yhat_svm1000)\n",
    "    acc[i,6] = metrics.accuracy_score(y_test,yhat_GBC)\n",
    "    acc[i,7] = metrics.accuracy_score(y_test,yhat_clf)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-66ef512d77f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# FC Histogram\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY_aut\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FC'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdensity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_aut\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FC'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of FC classes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Frequency'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mhist\u001b[0;34m(x, bins, range, density, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, normed, hold, data, **kwargs)\u001b[0m\n\u001b[1;32m   3130\u001b[0m                       \u001b[0mhisttype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhisttype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3131\u001b[0m                       \u001b[0mrwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3132\u001b[0;31m                       stacked=stacked, normed=normed, data=data, **kwargs)\n\u001b[0m\u001b[1;32m   3133\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3134\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1853\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1855\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mhist\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   6604\u001b[0m                 patch = _barfunc(bins[:-1]+boffset, height, width,\n\u001b[1;32m   6605\u001b[0m                                  \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'center'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6606\u001b[0;31m                                  color=c, **{bottom_kwarg: bottom})\n\u001b[0m\u001b[1;32m   6607\u001b[0m                 \u001b[0mpatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6608\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstacked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1853\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1855\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2276\u001b[0m                 \u001b[0medgecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2277\u001b[0m                 \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2278\u001b[0;31m                 \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'_nolegend_'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2279\u001b[0m                 )\n\u001b[1;32m   2280\u001b[0m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/patches.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, xy, width, height, angle, **kwargs)\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_height\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mangle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mangle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m         \u001b[0;31m# Note: This cannot be calculated until this is added to an Axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rect_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIdentityTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# FREQUENCY PLOT\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "\n",
    "# FC Histogram\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.hist(x=Y_aut['FC'],density=1, bins=int(np.max(Y_aut['FC']))) \n",
    "plt.xlabel('Number of FC classes')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlim(0, 35)\n",
    "\n",
    "# FC Histogram\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.hist(x=Y_aut['RT'],density=1, bins=int(np.max(Y_aut['RT']))) \n",
    "plt.xlabel('Number of RT classes')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlim(0, 12.5)\n",
    "\n",
    "y_FC35 = sorted(np.where(Y_aut['FC']>35)[0])\n",
    "y_RT35 = sorted(np.where(Y_aut['RT']>35)[0])\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.hist(x=y_FC35, bins=int(np.max(Y_aut['FC'])/10)) \n",
    "plt.subplot(2, 2, 4)\n",
    "plt.hist(x=y_RT35, bins=int(np.max(Y_aut['RT'])/10)) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1922, 4)\n",
      "(1922, 1)\n"
     ]
    }
   ],
   "source": [
    "X_aut_pois_FC_menys15 = X_aut[X_aut['FC']<3]\n",
    "X_aut_pois_RT_menys15 = X_aut[X_aut['RT']<3]\n",
    "\n",
    "X_aut_pois_FC_mes15 = X_aut[X_aut['FC']>5]\n",
    "X_aut_pois_RT_mes15 = X_aut[X_aut['RT']>5]\n",
    "\n",
    "\n",
    "Y_aut_RT =  X_aut_pois_RT_menys15[['RT']]\n",
    "Y_aut_FC =  X_aut_pois_FC_menys15[['FC']]\n",
    "\n",
    "\n",
    "\n",
    "X_aut_new_RT = X_aut_pois_RT_menys15.drop(['FC','RT'], axis=1)\n",
    "X_aut_new_FC = X_aut_pois_FC_menys15.drop(['RT'], axis=1)\n",
    "\n",
    "print(X_aut_new_RT.shape)\n",
    "\n",
    "print(Y_aut_RT.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.804159445407279"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn import neighbors\n",
    "from sklearn import svm\n",
    "from sklearn import ensemble\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X_aut_new_RT,Y_aut_RT,test_size=0.3,train_size=0.7,random_state=42)\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X_aut_new_RT,Y_aut_RT,test_size=0.3,train_size=0.7,random_state=42)\n",
    "GBC = ensemble.GradientBoostingClassifier(random_state=42)\n",
    "GBC.fit(X_train,y_train)\n",
    "yhat_GBC = GBC.predict(X_test)\n",
    "metrics.accuracy_score(y_test,yhat_GBC)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './tweet.csv'\n",
    "data = pd.read_csv(filename, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "1060974074799775746    2\n",
       "1060975078630809600    2\n",
       "1060976088380256256    2\n",
       "1060974115832676353    2\n",
       "1060975059559481350    2\n",
       "1061341603984490496    2\n",
       "1060975842304638977    2\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hi ha m√©s d'un tweet per 'id' en alguns casos (m√†xim 4)\n",
    "ctrl_01 = data.groupby('id').id.count()\n",
    "ctrl_01.sort_values().tail(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check number of zeros in  'FC' and 'RT' of our sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Una accuarcy semblant a aquest ratios seria dolenta, ha de ser molt m√©s\n",
      "0.40010965246261154 0.6620267430172703\n"
     ]
    }
   ],
   "source": [
    "zero_ratio_FC = data.loc[data.index[data['FC'] > 0]].shape[0]/data.shape[0]\n",
    "zero_ratio_RT = data.loc[data.index[data['RT'] > 0]].shape[0]/data.shape[0]\n",
    "\n",
    "print('Una accuarcy semblant a aquest ratios seria dolenta, ha de ser molt m√©s')\n",
    "print(1-zero_ratio_FC, 1-zero_ratio_RT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>j_user</th>\n",
       "      <th>created_at</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1046429145914384386</td>\n",
       "      <td>Desde el #FCJumilla damos nuestra m√°s sincera ...</td>\n",
       "      <td>{'id': 2664945430, 'id_str': '2664945430', 'na...</td>\n",
       "      <td>2018-09-30 15:58:44</td>\n",
       "      <td>{'hashtags': [{'text': 'FCJumilla', 'indices':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1044060298443919367</td>\n",
       "      <td>Me estoy volviendo loca hasta por cada una de ...</td>\n",
       "      <td>{'id': 713359736, 'id_str': '713359736', 'name...</td>\n",
       "      <td>2018-09-24 03:05:47</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1046424001214648320</td>\n",
       "      <td>üèü | El #FCJumilla ya est√° en La Condomina   ‚öΩÔ∏è...</td>\n",
       "      <td>{'id': 2664945430, 'id_str': '2664945430', 'na...</td>\n",
       "      <td>2018-09-30 15:38:18</td>\n",
       "      <td>{'hashtags': [{'text': 'FCJumilla', 'indices':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1046419267279818752</td>\n",
       "      <td>üìπ | El vestuario del #FCJumilla en La Condomin...</td>\n",
       "      <td>{'id': 2664945430, 'id_str': '2664945430', 'na...</td>\n",
       "      <td>2018-09-30 15:19:29</td>\n",
       "      <td>{'hashtags': [{'text': 'FCJumilla', 'indices':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1046417005451128832</td>\n",
       "      <td>üìë Jornada 6 | El colegiado andaluz Guzm√°n Mans...</td>\n",
       "      <td>{'id': 2664945430, 'id_str': '2664945430', 'na...</td>\n",
       "      <td>2018-09-30 15:10:30</td>\n",
       "      <td>{'hashtags': [{'text': 'UCAMMurciaJumilla', 'i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                              Tweet  \\\n",
       "0  1046429145914384386  Desde el #FCJumilla damos nuestra m√°s sincera ...   \n",
       "1  1044060298443919367  Me estoy volviendo loca hasta por cada una de ...   \n",
       "2  1046424001214648320  üèü | El #FCJumilla ya est√° en La Condomina   ‚öΩÔ∏è...   \n",
       "3  1046419267279818752  üìπ | El vestuario del #FCJumilla en La Condomin...   \n",
       "4  1046417005451128832  üìë Jornada 6 | El colegiado andaluz Guzm√°n Mans...   \n",
       "\n",
       "                                              j_user           created_at  \\\n",
       "0  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:58:44   \n",
       "1  {'id': 713359736, 'id_str': '713359736', 'name...  2018-09-24 03:05:47   \n",
       "2  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:38:18   \n",
       "3  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:19:29   \n",
       "4  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:10:30   \n",
       "\n",
       "                                            entities  \n",
       "0  {'hashtags': [{'text': 'FCJumilla', 'indices':...  \n",
       "1  {'hashtags': [], 'symbols': [], 'user_mentions...  \n",
       "2  {'hashtags': [{'text': 'FCJumilla', 'indices':...  \n",
       "3  {'hashtags': [{'text': 'FCJumilla', 'indices':...  \n",
       "4  {'hashtags': [{'text': 'UCAMMurciaJumilla', 'i...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.drop(['Unnamed: 0','FC','RT','trending_topic','followers_user','trending_topic'], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FC</th>\n",
       "      <th>RT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FC  RT\n",
       "0  18   4\n",
       "1   0   0\n",
       "2   4   2\n",
       "3  21   6\n",
       "4   0   0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = data[['FC','RT']]\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# FREQUENCY PLOT\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "\n",
    "# FC Histogram\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.hist(x=Y['FC'],density=1, bins=int(np.max(Y['FC']))) \n",
    "plt.xlabel('Number of FC classes')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlim(0, 35)\n",
    "\n",
    "# FC Histogram\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.hist(x=Y['RT'],density=1, bins=int(np.max(Y['RT']))) \n",
    "plt.xlabel('Number of RT classes')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlim(0, 12.5)\n",
    "\n",
    "y_FC35 = sorted(np.where(Y['FC']>35)[0])\n",
    "y_RT35 = sorted(np.where(Y['RT']>35)[0])\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.hist(x=y_FC35, bins=int(np.max(Y['FC'])/10)) \n",
    "plt.subplot(2, 2, 4)\n",
    "plt.hist(x=y_RT35, bins=int(np.max(Y['RT'])/10)) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resum: La majoria de 'FC' es concentra entre 0 i 10 i entre 0 i 5 a 'RT'. Aix√≤ podria infuir a l'hora de fer els models xq la BBDD de tweets amb 'FC' i 'RT' es molt petita i la predicci√≥ ser√† dolenta. No els podem considerar Outliers perqu√® realment no ho s√≥n (gent famosa per exemple). Hauriem de fer diferents models per diferents grups de persones, √©s a dir, en funci√≥ de la mitja dels RT i FC anteriors aplicar-li un model o altres. Podem separar la mostra no per FC i RT sin√≥ per RT_l10, sd_RT, FC_l10 i/o sd_FC que ve de la bbdd 'author'. L'aplicaci√≥ podria aplicarte un model o un altre amb els par√†metres estimats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2410 1539 32831\n"
     ]
    }
   ],
   "source": [
    "print(len(np.where(Y['FC']>35)[0]), len(np.where(Y['RT']>35)[0]), len(Y)) #2410 1539 32831"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La seg√ºent funci√≥ assigna una classe a cada interval. En total 137 classes 137 intervals. A mesura que els FC i els RT augmenten tamb√© augmenta l'amplada del interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class segmenta():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.intervals = {}\n",
    "    \n",
    "    def transform(self,y):\n",
    "        k, z = 0, 0\n",
    "        for a, b in [[15,5],\n",
    "                     [100,5],\n",
    "                     [200,10],\n",
    "                     [500,20],\n",
    "                     [1000,50],\n",
    "                     [5000,100],\n",
    "                     [10000,500],\n",
    "                     [50000,2000]]: \n",
    "            for i in np.arange(z,a,b):\n",
    "                self.intervals[k] = [i,i+b-1]\n",
    "                k+=1\n",
    "            z = a\n",
    "        self.intervals[k] = [50000,99999999]\n",
    "\n",
    "        y = np.reshape(y.values, (-1,1))\n",
    "        for j in self.intervals:\n",
    "            c = self.intervals[j]\n",
    "            idx = np.where(np.logical_and(y>=c[0],y<=c[1]))[0]\n",
    "            y[idx] = j\n",
    "\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "Y = data[['FC','RT']]\n",
    "\n",
    "segFC = segmenta()\n",
    "Y['FC'] = segFC.transform(Y['FC'])\n",
    "\n",
    "segRT = segmenta()\n",
    "Y['RT'] = segRT.transform(Y['RT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FC</th>\n",
       "      <th>RT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32826</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32827</th>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32828</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32829</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32830</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       FC  RT\n",
       "32826   2   0\n",
       "32827  20  12\n",
       "32828   8   4\n",
       "32829   0   0\n",
       "32830   1   0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location i Tweets###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import re #regular expressions\n",
    "import unidecode as udc\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from unicodedata import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['location'] = [ast.literal_eval(data['j_user'][i])['location'] for i in range(X.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>j_user</th>\n",
       "      <th>created_at</th>\n",
       "      <th>entities</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1046429145914384386</td>\n",
       "      <td>Desde el #FCJumilla damos nuestra m√°s sincera ...</td>\n",
       "      <td>{'id': 2664945430, 'id_str': '2664945430', 'na...</td>\n",
       "      <td>2018-09-30 15:58:44</td>\n",
       "      <td>{'hashtags': [{'text': 'FCJumilla', 'indices':...</td>\n",
       "      <td>Jumilla, Espa√±a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1044060298443919367</td>\n",
       "      <td>Me estoy volviendo loca hasta por cada una de ...</td>\n",
       "      <td>{'id': 713359736, 'id_str': '713359736', 'name...</td>\n",
       "      <td>2018-09-24 03:05:47</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>Atlantida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1046424001214648320</td>\n",
       "      <td>üèü | El #FCJumilla ya est√° en La Condomina   ‚öΩÔ∏è...</td>\n",
       "      <td>{'id': 2664945430, 'id_str': '2664945430', 'na...</td>\n",
       "      <td>2018-09-30 15:38:18</td>\n",
       "      <td>{'hashtags': [{'text': 'FCJumilla', 'indices':...</td>\n",
       "      <td>Jumilla, Espa√±a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1046419267279818752</td>\n",
       "      <td>üìπ | El vestuario del #FCJumilla en La Condomin...</td>\n",
       "      <td>{'id': 2664945430, 'id_str': '2664945430', 'na...</td>\n",
       "      <td>2018-09-30 15:19:29</td>\n",
       "      <td>{'hashtags': [{'text': 'FCJumilla', 'indices':...</td>\n",
       "      <td>Jumilla, Espa√±a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1046417005451128832</td>\n",
       "      <td>üìë Jornada 6 | El colegiado andaluz Guzm√°n Mans...</td>\n",
       "      <td>{'id': 2664945430, 'id_str': '2664945430', 'na...</td>\n",
       "      <td>2018-09-30 15:10:30</td>\n",
       "      <td>{'hashtags': [{'text': 'UCAMMurciaJumilla', 'i...</td>\n",
       "      <td>Jumilla, Espa√±a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                              Tweet  \\\n",
       "0  1046429145914384386  Desde el #FCJumilla damos nuestra m√°s sincera ...   \n",
       "1  1044060298443919367  Me estoy volviendo loca hasta por cada una de ...   \n",
       "2  1046424001214648320  üèü | El #FCJumilla ya est√° en La Condomina   ‚öΩÔ∏è...   \n",
       "3  1046419267279818752  üìπ | El vestuario del #FCJumilla en La Condomin...   \n",
       "4  1046417005451128832  üìë Jornada 6 | El colegiado andaluz Guzm√°n Mans...   \n",
       "\n",
       "                                              j_user           created_at  \\\n",
       "0  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:58:44   \n",
       "1  {'id': 713359736, 'id_str': '713359736', 'name...  2018-09-24 03:05:47   \n",
       "2  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:38:18   \n",
       "3  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:19:29   \n",
       "4  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:10:30   \n",
       "\n",
       "                                            entities         location  \n",
       "0  {'hashtags': [{'text': 'FCJumilla', 'indices':...  Jumilla, Espa√±a  \n",
       "1  {'hashtags': [], 'symbols': [], 'user_mentions...        Atlantida  \n",
       "2  {'hashtags': [{'text': 'FCJumilla', 'indices':...  Jumilla, Espa√±a  \n",
       "3  {'hashtags': [{'text': 'FCJumilla', 'indices':...  Jumilla, Espa√±a  \n",
       "4  {'hashtags': [{'text': 'UCAMMurciaJumilla', 'i...  Jumilla, Espa√±a  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1a Opci√≥: Token, analyze, ...\n",
    "\n",
    "Script N√∫ria en el que es treuen les paraules que no aporten informaci√≥ com conectors, articles, ... per utilitzaro com a stop words en el 'CountVectorizer':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './eliminar_paraules.xlsx'\n",
    "elim = pd.read_excel(filename, header=None)\n",
    "\n",
    "y=elim[0]\n",
    "for i in range(len(elim)):\n",
    "    y[i] = re.sub(\n",
    "            r\"([^n\\u0300-\\u036f]|n(?!\\u0303(?![\\u0300-\\u036f])))[\\u0300-\\u036f]+\", r\"\\1\", \n",
    "            normalize( \"NFD\", y[i]), 0, re.I)\n",
    "y = y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer1 = CountVectorizer(min_df=0.0001, stop_words=y, strip_accents='unicode') # Tweets \n",
    "vectorizer2 = CountVectorizer(min_df=0.001, stop_words=y, strip_accents='unicode') # location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLASSIFIERS ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifiers importation\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn import neural_network\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Others\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model, metrics, model_selection\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [ neural_network.MLPClassifier(),\n",
    "                linear_model.LogisticRegression(),\n",
    "                KNeighborsClassifier(3),\n",
    "                SVC(kernel=\"rbf\", C=1, probability=True),\n",
    "#               NuSVC(probability=True),\n",
    "                DecisionTreeClassifier(),\n",
    "                RandomForestClassifier(),\n",
    "                AdaBoostClassifier(),\n",
    "                GradientBoostingClassifier(),\n",
    "                GaussianNB(),\n",
    "                BernoulliNB()\n",
    "#               LinearDiscriminantAnalysis(),\n",
    "#               QuadraticDiscriminantAnalysis()\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FC\n",
    "Y_FC = Y['FC']\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X,Y_FC,test_size=0.3,train_size=0.7,random_state=42)\n",
    "\n",
    "#Process and convert data \n",
    "a1 = vectorizer1.fit_transform(X_train['Tweet'])\n",
    "a1 = a1.todense()                                                                                                                                                                                                                                         \n",
    "#a2 = vectorizer2.fit_transform(X_train['location'])\n",
    "#a2 = a2.todense() \n",
    "#X_train = np.concatenate((a1, a2), axis=1)\n",
    "X_train = a1\n",
    "y_train = y_train.values\n",
    "\n",
    "b1 = vectorizer1.transform(X_test['Tweet'])\n",
    "b1 = b1.todense()\n",
    "#b2 = vectorizer2.transform(X_test['location'])\n",
    "#b2 = b2.todense()\n",
    "#X_test = np.concatenate((b1, b2), axis=1)\n",
    "X_test = b1\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22981, 9871)\n",
      "(9850, 9871)\n",
      "0.9676689439101867\n",
      "0.9602030456852791\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "# Percentatge n√∫mero de files amb tot zeros despres de natejar la bbdd (X_train i X_test)\n",
    "print(X_train[np.where(X_train.sum(axis=1)>0)].shape[1]/X_train.shape[0])\n",
    "print(X_test[np.where(X_test.sum(axis=1)>0)].shape[1]/X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier 0.7068020304568527\n",
      "LogisticRegression 0.7751269035532995\n"
     ]
    }
   ],
   "source": [
    "# Logging for Visual Comparison\n",
    "log_cols=[\"Classifier\", \"Accuracy\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "for clf in classifiers:\n",
    "\n",
    "    clf.fit(X_train,y_train)\n",
    "    name = clf.__class__.__name__\n",
    "\n",
    "    yhat = clf.predict(X_test).reshape(-1,1)\n",
    "    acc = metrics.accuracy_score(y_test, yhat)  \n",
    "    print(name, acc)\n",
    "    yhat_prob = clf.predict_proba(X_test)\n",
    "\n",
    "    log_entry = pd.DataFrame([[name, acc*100]], columns=log_cols)\n",
    "    log = log.append(log_entry)\n",
    "\n",
    "# ACCURACY GRAPHIC \n",
    "sns.set_color_codes(\"muted\")\n",
    "sns.barplot(x='Accuracy', y='Classifier', data=log, color=\"b\")\n",
    "\n",
    "plt.xlabel('Accuracy %')\n",
    "plt.title('Classifier Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>73.801816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>59.091986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Classifier   Accuracy\n",
       "0       MLPClassifier  73.801816\n",
       "0  LogisticRegression  59.091986"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RT\n",
    "Y_RT = Y['RT']\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X,Y_RT,test_size=0.3,train_size=0.7,random_state=42)\n",
    "\n",
    "#Process and convert data \n",
    "a1 = vectorizer1.fit_transform(X_train['Tweet'])\n",
    "a1 = a1.todense()                                                                                                                                                                                                                                         \n",
    "#a2 = vectorizer2.fit_transform(X_train['location'])\n",
    "#a2 = a2.todense() \n",
    "#X_train = np.concatenate((a1, a2), axis=1)\n",
    "X_train = a1\n",
    "y_train = y_train.values\n",
    "\n",
    "b1 = vectorizer1.transform(X_test['Tweet'])\n",
    "b1 = b1.todense()\n",
    "#b2 = vectorizer2.transform(X_test['location'])\n",
    "#b2 = b2.todense()\n",
    "#X_test = np.concatenate((b1, b2), axis=1)\n",
    "X_test = b1\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "# Percentatge n√∫mero de files amb tot zeros despres de natejar la bbdd (X_train i X_test)\n",
    "print(X_train[np.where(X_train.sum(axis=1)>0)].shape[1]/X_train.shape[0])\n",
    "print(X_test[np.where(X_test.sum(axis=1)>0)].shape[1]/X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging for Visual Comparison\n",
    "log_cols=[\"Classifier\", \"Accuracy\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "for clf in classifiers:\n",
    "\n",
    "    clf.fit(X_train,y_train)\n",
    "    name = clf.__class__.__name__\n",
    "\n",
    "    yhat = clf.predict(X_test).reshape(-1,1)\n",
    "    acc = metrics.accuracy_score(y_test, yhat)   \n",
    "    yhat_prob = clf.predict_proba(X_test)\n",
    "\n",
    "    log_entry = pd.DataFrame([[name, acc*100]], columns=log_cols)\n",
    "    log = log.append(log_entry)\n",
    "\n",
    "# ACCURACY GRAPHIC \n",
    "sns.set_color_codes(\"muted\")\n",
    "sns.barplot(x='Accuracy', y='Classifier', data=log, color=\"b\")\n",
    "\n",
    "plt.xlabel('Accuracy %')\n",
    "plt.title('Classifier Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(Y_RT)\n",
    "\n",
    "y[y <= 215] = 1\n",
    "y[y > 250] = 0\n",
    "\n",
    "print(len(y[y==0]))\n",
    "print(len(y[y==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn import neighbors\n",
    "from sklearn import svm\n",
    "from sklearn import ensemble\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "###for RT\n",
    "r_state = [0,1,2,3,4,5,42,43,44,45]\n",
    "\n",
    "acc = np.zeros((len(r_state),8))\n",
    "\n",
    "for i in range(len(r_state)):\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size=0.7, random_state=r_state[i])\n",
    "    \n",
    "    #Your code here\n",
    "    scaler = StandardScaler()\n",
    "    scaler = scaler.fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    \n",
    "    nn1 = neighbors.KNeighborsClassifier(n_neighbors=1) #1NN\n",
    "    nn1.fit(X_train_scaled,y_train)\n",
    "    yhat_nn1 = nn1.predict(X_test_scaled) \n",
    "\n",
    "    nn3 = neighbors.KNeighborsClassifier(n_neighbors=3) #3NN\n",
    "    nn3.fit(X_train_scaled,y_train)\n",
    "    yhat_nn3 = nn3.predict(X_test_scaled) \n",
    "    \n",
    "    tr = tree.DecisionTreeClassifier() #Decision Tree\n",
    "    tr.fit(X_train_scaled,y_train)\n",
    "    yhat_tr = tr.predict(X_test_scaled)\n",
    "    \n",
    "    svm10 = svm.SVC(C=10.0,gamma = 1e-5,random_state=42) \n",
    "    svm10.fit(X_train_scaled,y_train)\n",
    "    yhat_svm10 = svm10.predict(X_test_scaled)\n",
    "    \n",
    "    svm100 = svm.SVC(C=100.0,gamma = 1e-5,random_state=42)\n",
    "    svm100.fit(X_train_scaled,y_train)\n",
    "    yhat_svm100= svm100.predict(X_test_scaled)\n",
    "    \n",
    "    svm1000 = svm.SVC(C=1000.0,gamma = 1e-6,random_state=42)\n",
    "    svm1000.fit(X_train_scaled,y_train)\n",
    "    yhat_svm1000 = svm1000.predict(X_test_scaled)\n",
    "    \n",
    "    GBC = ensemble.GradientBoostingClassifier(random_state=42)\n",
    "    GBC.fit(X_train_scaled,y_train)\n",
    "    yhat_GBC = GBC.predict(X_test_scaled)\n",
    "    \n",
    "    clf = KMeans(n_clusters=2)\n",
    "    clf.fit(X_train_scaled,y_train)\n",
    "    yhat_clf = clf.predict(X_test_scaled)\n",
    "    \n",
    "    acc[i,0] = metrics.accuracy_score(y_test,yhat_tr)\n",
    "    acc[i,1] = metrics.accuracy_score(y_test,yhat_nn1)\n",
    "    acc[i,2] = metrics.accuracy_score(y_test,yhat_nn3)\n",
    "    acc[i,3] = metrics.accuracy_score(y_test,yhat_svm10)\n",
    "    acc[i,4] = metrics.accuracy_score(y_test,yhat_svm100)\n",
    "    acc[i,5] = metrics.accuracy_score(y_test,yhat_svm1000)\n",
    "    acc[i,6] = metrics.accuracy_score(y_test,yhat_GBC)\n",
    "    acc[i,7] = metrics.accuracy_score(y_test,yhat_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
