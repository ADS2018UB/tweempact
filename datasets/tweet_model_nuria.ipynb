{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import model_selection, linear_model, ensemble, svm, tree, metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import neighbors\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"X_tweet_nuria.csv\")\n",
    "y_fc = pd.read_csv(\"y_fc_tweet_nuria.csv\", header = None)\n",
    "y_rt = pd.read_csv(\"y_rt_tweet_nuria.csv\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fc = np.array(y_fc)\n",
    "y_rt = np.array(y_rt)\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fc = np.concatenate(y_fc)\n",
    "y_rt = np.concatenate(y_rt)\n",
    "print(y_fc)\n",
    "print(y_rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = model_selection.KFold(n_splits = 10, shuffle=True, random_state=42)\n",
    "cv.get_n_splits(X)\n",
    "\n",
    "acc = np.zeros((10,11))\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 11)\n",
    "nn1 = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "nn3 = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "nn10 = neighbors.KNeighborsClassifier(n_neighbors=10)\n",
    "nn12 = neighbors.KNeighborsClassifier(n_neighbors=12)\n",
    "tr = tree.DecisionTreeClassifier()\n",
    "svm10 = svm.SVC(C=10.0,gamma = 1e-5,random_state=42) \n",
    "svm100 = svm.SVC(C=100.0,gamma = 1e-5,random_state=42)\n",
    "svm1000 = svm.SVC(C=1000.0,gamma = 1e-6,random_state=42)\n",
    "GBC = ensemble.GradientBoostingClassifier(random_state=42)\n",
    "nb = BernoulliNB()\n",
    "gauss = GaussianNB()\n",
    "clf2 = KMeans(n_clusters=2)\n",
    "clf3 = KMeans(n_clusters=3)\n",
    "clf5 = KMeans(n_clusters=5)\n",
    "clf10 = KMeans(n_clusters=10)\n",
    "etc = ExtraTreesClassifier()\n",
    "abc = AdaBoostClassifier(n_estimators=100) \n",
    "gbc = GradientBoostingClassifier(n_estimators=100)\n",
    "gbr = GradientBoostingRegressor(n_estimators=100) \n",
    "mlp = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for train_idx, test_idx in cv.split(X):\n",
    "    X_train,y_train = X[train_idx,:],y_fc[train_idx]\n",
    "    X_test,y_test = X[test_idx,:],y_fc[test_idx]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled=scaler.fit_transform(X_train)\n",
    "    \n",
    "    rf.fit(X_train_scaled,y_train)\n",
    "    print('.')\n",
    "    nn1.fit(X_train_scaled,y_train)\n",
    "    print('.')\n",
    "    nn3.fit(X_train_scaled,y_train)\n",
    "    print('.')\n",
    "    nn10.fit(X_train_scaled,y_train)\n",
    "    print('.')\n",
    "    nn12.fit(X_train_scaled,y_train)\n",
    "    print('.')\n",
    "    tr.fit(X_train_scaled,y_train)\n",
    "    print('.')\n",
    "    #svm10.fit(X_train_scaled,y_train)\n",
    "    print('.')\n",
    "    #svm100.fit(X_train_scaled,y_train)\n",
    "    print('.')\n",
    "    #svm1000.fit(X_train_scaled,y_train)\n",
    "    print('.')\n",
    "    GBC.fit(X_train_scaled,y_train)\n",
    "    print('.')\n",
    "    nb.fit(X_train_scaled,y_train)\n",
    "    print('.')\n",
    "    gauss.fit(X_train_scaled,y_train)\n",
    "    print('.')\n",
    "    clf2.fit(X_train_scaled,y_train)\n",
    "    print('.')\n",
    "    clf3.fit(X_train_scaled,y_train)\n",
    "    print('.')\n",
    "    #clf5.fit(X_train_scaled,y_train)\n",
    "    print('.')\n",
    "    #clf10.fit(X_train_scaled,y_train)\n",
    "    print('.')\n",
    "    #etc.fit(X_train_scaled,y_train)\n",
    "    print('.')\n",
    "    #abc.fit(X_train_scaled,y_train)\n",
    "    print('.')\n",
    "    #gbc.fit(X_train_scaled,y_train)\n",
    "    print('.')\n",
    "    #gbr.fit(X_train_scaled,y_train)\n",
    "    print('.')\n",
    "    #mlp.fit(X_train_scaled,y_train)\n",
    "    \n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    yhat_rf = rf.predict(X_test_scaled).reshape(-1,1)\n",
    "    print('1...\\n')\n",
    "    yhat_nn1 = nn1.predict(X_test_scaled).reshape(-1,1)\n",
    "    print('2...\\n')\n",
    "    yhat_nn3 = nn3.predict(X_test_scaled).reshape(-1,1)\n",
    "    print('3...\\n')\n",
    "    yhat_nn10 = nn10.predict(X_test_scaled).reshape(-1,1)\n",
    "    print('4...\\n')\n",
    "    yhat_nn12 = nn12.predict(X_test_scaled).reshape(-1,1)\n",
    "    print('5...\\n')\n",
    "    yhat_tr = tr.predict(X_test_scaled).reshape(-1,1)\n",
    "    print('6...\\n')\n",
    "    #yhat_svm10 = svm10.predict(X_test_scaled).reshape(-1,1)\n",
    "    print('7...\\n')\n",
    "    #yhat_svm100 = svm100.predict(X_test_scaled).reshape(-1,1)\n",
    "    print('8...\\n')\n",
    "    #yhat_svm1000 = svm1000.predict(X_test_scaled).reshape(-1,1)\n",
    "    print('9...\\n')\n",
    "    yhat_GBC = GBC.predict(X_test_scaled).reshape(-1,1)\n",
    "    print('10...\\n')\n",
    "    yhat_nb = nb.predict(X_test_scaled).reshape(-1,1)\n",
    "    print('11...\\n')\n",
    "    yhat_gauss = gauss.predict(X_test_scaled).reshape(-1,1)\n",
    "    print('12...\\n')\n",
    "    yhat_clf2 = clf2.predict(X_test_scaled).reshape(-1,1)\n",
    "    print('13...\\n')\n",
    "    yhat_clf3 = clf3.predict(X_test_scaled).reshape(-1,1)\n",
    "    print('14...\\n')\n",
    "    #yhat_clf5 = clf5.predict(X_test_scaled).reshape(-1,1)\n",
    "    print('15...\\n')\n",
    "    #yhat_clf10 = clf10.predict(X_test_scaled).reshape(-1,1)\n",
    "    print('16...\\n')\n",
    "    #yhat_etc = etc.predict(X_test_scaled).reshape(-1,1)\n",
    "    print('17...\\n')\n",
    "    #yhat_abc = abc.predict(X_test_scaled).reshape(-1,1)\n",
    "    print('18...\\n')\n",
    "    #yhat_gbc = gbc.predict(X_test_scaled).reshape(-1,1)\n",
    "    print('19...\\n')\n",
    "    #yhat_gbr = gbr.predict(X_test_scaled).reshape(-1,1)\n",
    "    print('20...\\n')\n",
    "    #yhat_mlp = mlp.predict(X_test_scaled).reshape(-1,1)\n",
    "    \n",
    "    acc[i,0] = metrics.accuracy_score(y_test,yhat_rf)\n",
    "    acc[i,1] = metrics.accuracy_score(y_test,yhat_nn1)\n",
    "    acc[i,2] = metrics.accuracy_score(y_test,yhat_nn3)\n",
    "    acc[i,3] = metrics.accuracy_score(y_test,yhat_nn10)\n",
    "    acc[i,4] = metrics.accuracy_score(y_test,yhat_nn12)\n",
    "    acc[i,5] = metrics.accuracy_score(y_test,yhat_tr)\n",
    "    #acc[i,6] = metrics.accuracy_score(y_test,yhat_svm10)\n",
    "    #acc[i,7] = metrics.accuracy_score(y_test,yhat_svm100)\n",
    "    #acc[i,8] = metrics.accuracy_score(y_test,yhat_svm1000)\n",
    "    acc[i,6] = metrics.accuracy_score(y_test,yhat_GBC)\n",
    "    acc[i,7] = metrics.accuracy_score(y_test,yhat_nb)\n",
    "    acc[i,8] = metrics.accuracy_score(y_test,yhat_gauss)\n",
    "    acc[i,9] = metrics.accuracy_score(y_test,yhat_clf2)\n",
    "    acc[i,10] = metrics.accuracy_score(y_test,yhat_clf3)\n",
    "    #acc[i,14] = metrics.accuracy_score(y_test,yhat_clf5)\n",
    "    #acc[i,15] = metrics.accuracy_score(y_test,yhat_clf10)\n",
    "    #acc[i,16] = metrics.accuracy_score(y_test,yhat_etc)\n",
    "    #acc[i,17] = metrics.accuracy_score(y_test,yhat_abc)\n",
    "    #acc[i,18] = metrics.accuracy_score(y_test,yhat_gbc)\n",
    "    #acc[i,19] = metrics.accuracy_score(y_test,yhat_gbr)\n",
    "    #acc[i,20] = metrics.accuracy_score(y_test,yhat_mlp)\n",
    "\n",
    "    i = i+1\n",
    "    \n",
    "    \n",
    "fig = plt.figure()\n",
    "plt.boxplot(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = model_selection.KFold(n_splits = 10, shuffle=True, random_state=42)\n",
    "cv.get_n_splits(X)\n",
    "\n",
    "yhat = np.zeros((X.shape[0],1))\n",
    "acc = np.zeros((10,20))\n",
    "\n",
    "i = 0\n",
    "for train_idx, test_idx in cv.split(X):\n",
    "    X_train,y_train = X[train_idx,:],y_rt[train_idx]\n",
    "    X_test,y_test = X[test_idx,:],y_rt[test_idx]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled=scaler.fit_transform(X_train)\n",
    "    \n",
    "    rf.fit(X_train_scaled,y_train)\n",
    "    nn1.fit(X_train_scaled,y_train)\n",
    "    nn3.fit(X_train_scaled,y_train)\n",
    "    nn10.fit(X_train_scaled,y_train)\n",
    "    nn12.fit(X_train_scaled,y_train)\n",
    "    tr.fit(X_train_scaled,y_train)\n",
    "    svm10.fit(X_train_scaled,y_train)\n",
    "    svm100.fit(X_train_scaled,y_train)\n",
    "    svm1000.fit(X_train_scaled,y_train)\n",
    "    GBC.fit(X_train_scaled,y_train)\n",
    "    nb.fit(X_train_scaled,y_train)\n",
    "    gauss.fit(X_train_scaled,y_train)\n",
    "    clf2.fit(X_train_scaled,y_train)\n",
    "    clf3.fit(X_train_scaled,y_train)\n",
    "    clf5.fit(X_train_scaled,y_train)\n",
    "    clf10.fit(X_train_scaled,y_train)\n",
    "    etc.fit(X_train_scaled,y_train)\n",
    "    abc.fit(X_train_scaled,y_train)\n",
    "    gbc.fit(X_train_scaled,y_train)\n",
    "    gbr.fit(X_train_scaled,y_train)\n",
    "    mlp.fit(X_train_scaled,y_train)\n",
    "    \n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    yhat_rf = rf.predict(X_test_scaled).reshape(-1,1)\n",
    "    yhat_nn1 = nn1.predict(X_test_scaled).reshape(-1,1)\n",
    "    yhat_nn3 = nn3.predict(X_test_scaled).reshape(-1,1)\n",
    "    yhat_nn10 = nn10.predict(X_test_scaled).reshape(-1,1)\n",
    "    yhat_nn12 = nn12.predict(X_test_scaled).reshape(-1,1)\n",
    "    yhat_tr = tr.predict(X_test_scaled).reshape(-1,1)\n",
    "    yhat_svm10 = svm10.predict(X_test_scaled).reshape(-1,1)\n",
    "    yhat_svm100 = svm100.predict(X_test_scaled).reshape(-1,1)\n",
    "    yhat_svm1000 = svm1000.predict(X_test_scaled).reshape(-1,1)\n",
    "    yhat_GBC = GBC.predict(X_test_scaled).reshape(-1,1)\n",
    "    yhat_nb = nb.predict(X_test_scaled).reshape(-1,1)\n",
    "    yhat_gauss = gauss.predict(X_test_scaled).reshape(-1,1)\n",
    "    yhat_clf2 = clf2.predict(X_test_scaled).reshape(-1,1)\n",
    "    yhat_clf3 = clf3.predict(X_test_scaled).reshape(-1,1)\n",
    "    yhat_clf5 = clf5.predict(X_test_scaled).reshape(-1,1)\n",
    "    yhat_clf10 = clf10.predict(X_test_scaled).reshape(-1,1)\n",
    "    yhat_etc = etc.predict(X_test_scaled).reshape(-1,1)\n",
    "    yhat_abc = abc.predict(X_test_scaled).reshape(-1,1)\n",
    "    yhat_gbc = gbc.predict(X_test_scaled).reshape(-1,1)\n",
    "    yhat_gbr = gbr.predict(X_test_scaled).reshape(-1,1)\n",
    "    yhat_mlp = mlp.predict(X_test_scaled).reshape(-1,1)\n",
    "    \n",
    "    acc[i,0] = metrics.accuracy_score(y_test,yhat_tr)\n",
    "    acc[i,1] = metrics.accuracy_score(y_test,yhat_nn1)\n",
    "    acc[i,2] = metrics.accuracy_score(y_test,yhat_nn3)\n",
    "    acc[i,3] = metrics.accuracy_score(y_test,yhat_nn10)\n",
    "    acc[i,4] = metrics.accuracy_score(y_test,yhat_nn12)\n",
    "    acc[i,5] = metrics.accuracy_score(y_test,yhat_tr)\n",
    "    acc[i,6] = metrics.accuracy_score(y_test,yhat_svm10)\n",
    "    acc[i,7] = metrics.accuracy_score(y_test,yhat_svm100)\n",
    "    acc[i,8] = metrics.accuracy_score(y_test,yhat_svm1000)\n",
    "    acc[i,9] = metrics.accuracy_score(y_test,yhat_GBC)\n",
    "    acc[i,10] = metrics.accuracy_score(y_test,yhat_nb)\n",
    "    acc[i,11] = metrics.accuracy_score(y_test,yhat_gauss)\n",
    "    acc[i,12] = metrics.accuracy_score(y_test,yhat_clf2)\n",
    "    acc[i,13] = metrics.accuracy_score(y_test,yhat_clf3)\n",
    "    acc[i,14] = metrics.accuracy_score(y_test,yhat_clf5)\n",
    "    acc[i,15] = metrics.accuracy_score(y_test,yhat_clf10)\n",
    "    acc[i,16] = metrics.accuracy_score(y_test,yhat_etc)\n",
    "    acc[i,17] = metrics.accuracy_score(y_test,yhat_abc)\n",
    "    acc[i,18] = metrics.accuracy_score(y_test,yhat_gbc)\n",
    "    acc[i,19] = metrics.accuracy_score(y_test,yhat_gbr)\n",
    "    acc[i,20] = metrics.accuracy_score(y_test,yhat_mlp)\n",
    "\n",
    "    i = i+1\n",
    "    \n",
    "    \n",
    "fig = plt.figure()\n",
    "plt.boxplot(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
