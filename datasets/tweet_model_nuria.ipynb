{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import model_selection, linear_model, ensemble, svm, tree, metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import neighbors\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nuria\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (3968,3969,3970) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0\n",
       "0  18\n",
       "1   0\n",
       "2   4\n",
       "3  21\n",
       "4   0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.read_csv(\"X_tweet_nuria.csv\", header = None)\n",
    "y_fc = pd.read_csv(\"y_fc_tweet_nuria.csv\", header = None)\n",
    "y_rt = pd.read_csv(\"y_rt_tweet_nuria.csv\", header = None)\n",
    "y_fc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fc = np.array(y_fc)\n",
    "y_rt = np.array(y_rt)\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4290, 3971)\n",
      "(4289, 1)\n",
      "(4289, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y_rt.shape)\n",
    "print(y_fc.shape)\n",
    "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 4289 is out of bounds for axis 0 with size 4289",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-e257e5d34ea0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtrain_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_idx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_fc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_fc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 4289 is out of bounds for axis 0 with size 4289"
     ]
    }
   ],
   "source": [
    "cv = model_selection.KFold(n_splits = 10, shuffle=True, random_state=42)\n",
    "cv.get_n_splits(X)\n",
    "\n",
    "yhat = np.zeros((X.shape[0],1))\n",
    "acc = np.zeros((10,20))\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 11)\n",
    "nn1 = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "nn3 = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "nn10 = neighbors.KNeighborsClassifier(n_neighbors=10)\n",
    "nn12 = neighbors.KNeighborsClassifier(n_neighbors=12)\n",
    "tr = tree.DecisionTreeClassifier()\n",
    "svm10 = svm.SVC(C=10.0,gamma = 1e-5,random_state=42) \n",
    "svm100 = svm.SVC(C=100.0,gamma = 1e-5,random_state=42)\n",
    "svm1000 = svm.SVC(C=1000.0,gamma = 1e-6,random_state=42)\n",
    "GBC = ensemble.GradientBoostingClassifier(random_state=42)\n",
    "nb = BernoulliNB()\n",
    "gauss = GaussianNB()\n",
    "clf2 = KMeans(n_clusters=2)\n",
    "clf3 = KMeans(n_clusters=3)\n",
    "clf5 = KMeans(n_clusters=5)\n",
    "clf10 = KMeans(n_clusters=10)\n",
    "etc = ExtraTreesClassifier()\n",
    "abc = AdaBoostClassifier(n_estimators=100) \n",
    "gbc = GradientBoostingClassifier(n_estimators=100)\n",
    "gbr = GradientBoostingRegressor(n_estimators=100) \n",
    "mlp = MLPClassifier()\n",
    "\n",
    "i = 0\n",
    "for train_idx, test_idx in cv.split(X):\n",
    "    X_train,y_train = X[train_idx,:],y_fc[train_idx]\n",
    "    X_test,y_test = X[test_idx,:],y_fc[test_idx]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled=scaler.fit_transform(X_train)\n",
    "    \n",
    "    rf.fit(X_train_scaled,y_train)\n",
    "    nn1.fit(X_train_scaled,y_train)\n",
    "    nn3.fit(X_train_scaled,y_train)\n",
    "    nn10.fit(X_train_scaled,y_train)\n",
    "    nn12.fit(X_train_scaled,y_train)\n",
    "    tr.fit(X_train_scaled,y_train)\n",
    "    svm10.fit(X_train_scaled,y_train)\n",
    "    svm100.fit(X_train_scaled,y_train)\n",
    "    svm1000.fit(X_train_scaled,y_train)\n",
    "    GBC.fit(X_train_scaled,y_train)\n",
    "    nb.fit(X_train_scaled,y_train)\n",
    "    gauss.fit(X_train_scaled,y_train)\n",
    "    clf2.fit(X_train_scaled,y_train)\n",
    "    clf3.fit(X_train_scaled,y_train)\n",
    "    clf5.fit(X_train_scaled,y_train)\n",
    "    clf10.fit(X_train_scaled,y_train)\n",
    "    etc.fit(X_train_scaled,y_train)\n",
    "    abc.fit(X_train_scaled,y_train)\n",
    "    gbc.fit(X_train_scaled,y_train)\n",
    "    gbr.fit(X_train_scaled,y_train)\n",
    "    mlp.fit(X_train_scaled,y_train)\n",
    "    \n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    yhat_rf = rf.predict(X_test_scaled)\n",
    "    yhat_nn1 = nn1.predict(X_test_scaled)\n",
    "    yhat_nn3 = nn3.predict(X_test_scaled)\n",
    "    yhat_nn10 = nn10.predict(X_test_scaled)\n",
    "    yhat_nn12 = nn12.predict(X_test_scaled)\n",
    "    yhat_tr = tr.predict(X_test_scaled)\n",
    "    yhat_svm10 = svm10.predict(X_test_scaled)\n",
    "    yhat_svm100 = svm100.predict(X_test_scaled)\n",
    "    yhat_svm1000 = svm1000.predict(X_test_scaled)\n",
    "    yhat_GBC = GBC.predict(X_test_scaled)\n",
    "    yhat_nb = nb.predict(X_test_scaled)\n",
    "    yhat_gauss = gauss.predict(X_test_scaled)\n",
    "    yhat_clf2 = clf2.predict(X_test_scaled)\n",
    "    yhat_clf3 = clf3.predict(X_test_scaled)\n",
    "    yhat_clf5 = clf5.predict(X_test_scaled)\n",
    "    yhat_clf10 = clf10.predict(X_test_scaled)\n",
    "    yhat_etc = etc.predict(X_test_scaled)\n",
    "    yhat_abc = abc.predict(X_test_scaled)\n",
    "    yhat_gbc = gbc.predict(X_test_scaled)\n",
    "    yhat_gbr = gbr.predict(X_test_scaled)\n",
    "    yhat_mlp = mlp.predict(X_test_scaled)\n",
    "    \n",
    "    acc[i,0] = metrics.accuracy_score(y_test,yhat_tr)\n",
    "    acc[i,1] = metrics.accuracy_score(y_test,yhat_nn1)\n",
    "    acc[i,2] = metrics.accuracy_score(y_test,yhat_nn3)\n",
    "    acc[i,3] = metrics.accuracy_score(y_test,yhat_nn10)\n",
    "    acc[i,4] = metrics.accuracy_score(y_test,yhat_nn12)\n",
    "    acc[i,5] = metrics.accuracy_score(y_test,yhat_tr)\n",
    "    acc[i,6] = metrics.accuracy_score(y_test,yhat_svm10)\n",
    "    acc[i,7] = metrics.accuracy_score(y_test,yhat_svm100)\n",
    "    acc[i,8] = metrics.accuracy_score(y_test,yhat_svm1000)\n",
    "    acc[i,9] = metrics.accuracy_score(y_test,yhat_GBC)\n",
    "    acc[i,10] = metrics.accuracy_score(y_test,yhat_nb)\n",
    "    acc[i,11] = metrics.accuracy_score(y_test,yhat_gauss)\n",
    "    acc[i,12] = metrics.accuracy_score(y_test,yhat_clf2)\n",
    "    acc[i,13] = metrics.accuracy_score(y_test,yhat_clf3)\n",
    "    acc[i,14] = metrics.accuracy_score(y_test,yhat_clf5)\n",
    "    acc[i,15] = metrics.accuracy_score(y_test,yhat_clf10)\n",
    "    acc[i,16] = metrics.accuracy_score(y_test,yhat_etc)\n",
    "    acc[i,17] = metrics.accuracy_score(y_test,yhat_abc)\n",
    "    acc[i,18] = metrics.accuracy_score(y_test,yhat_gbc)\n",
    "    acc[i,19] = metrics.accuracy_score(y_test,yhat_gbr)\n",
    "    acc[i,20] = metrics.accuracy_score(y_test,yhat_mlp)\n",
    "\n",
    "    i = i+1\n",
    "    \n",
    "    \n",
    "fig = plt.figure()\n",
    "plt.boxplot(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
