{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import nltk\n",
    "import re\n",
    "from unicodedata import normalize\n",
    "\n",
    "file = pd.read_csv(\"tweet.csv\")\n",
    "file.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "file.drop('id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>created_at</th>\n",
       "      <th>entities</th>\n",
       "      <th>FC</th>\n",
       "      <th>RT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Desde el #FCJumilla damos nuestra m√°s sincera ...</td>\n",
       "      <td>2018-09-30 15:58:44</td>\n",
       "      <td>{'hashtags': [{'text': 'FCJumilla', 'indices':...</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Me estoy volviendo loca hasta por cada una de ...</td>\n",
       "      <td>2018-09-24 03:05:47</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>üèü | El #FCJumilla ya est√° en La Condomina   ‚öΩÔ∏è...</td>\n",
       "      <td>2018-09-30 15:38:18</td>\n",
       "      <td>{'hashtags': [{'text': 'FCJumilla', 'indices':...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>üìπ | El vestuario del #FCJumilla en La Condomin...</td>\n",
       "      <td>2018-09-30 15:19:29</td>\n",
       "      <td>{'hashtags': [{'text': 'FCJumilla', 'indices':...</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>üìë Jornada 6 | El colegiado andaluz Guzm√°n Mans...</td>\n",
       "      <td>2018-09-30 15:10:30</td>\n",
       "      <td>{'hashtags': [{'text': 'UCAMMurciaJumilla', 'i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet           created_at  \\\n",
       "0  Desde el #FCJumilla damos nuestra m√°s sincera ...  2018-09-30 15:58:44   \n",
       "1  Me estoy volviendo loca hasta por cada una de ...  2018-09-24 03:05:47   \n",
       "2  üèü | El #FCJumilla ya est√° en La Condomina   ‚öΩÔ∏è...  2018-09-30 15:38:18   \n",
       "3  üìπ | El vestuario del #FCJumilla en La Condomin...  2018-09-30 15:19:29   \n",
       "4  üìë Jornada 6 | El colegiado andaluz Guzm√°n Mans...  2018-09-30 15:10:30   \n",
       "\n",
       "                                            entities  FC  RT  \n",
       "0  {'hashtags': [{'text': 'FCJumilla', 'indices':...  18   4  \n",
       "1  {'hashtags': [], 'symbols': [], 'user_mentions...   0   0  \n",
       "2  {'hashtags': [{'text': 'FCJumilla', 'indices':...   4   2  \n",
       "3  {'hashtags': [{'text': 'FCJumilla', 'indices':...  21   6  \n",
       "4  {'hashtags': [{'text': 'UCAMMurciaJumilla', 'i...   0   0  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hashtags': [{'text': 'FCJumilla', 'indices': [9, 19]}], 'symbols': [], 'user_mentions': [{'screen_name': 'alejanvalverde', 'name': 'alejandro valverde', 'id': 248879448, 'id_str': '248879448', 'indices': [100, 115]}], 'urls': [{'url': 'https://t.co/XqLolr5sfl', 'expanded_url': 'https://twitter.com/i/web/status/1046429145914384386', 'display_url': 'twitter.com/i/web/status/1‚Ä¶', 'indices': [117, 140]}]}\n"
     ]
    }
   ],
   "source": [
    "print(file['entities'][0])\n",
    "#ens quedem amb:\n",
    "#hashtags\n",
    "#user_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nuria\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\Nuria\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\Nuria\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\Users\\Nuria\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\Nuria\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\Nuria\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "numl = len(file.index.values)\n",
    "file['hashtags']=np.zeros(numl)\n",
    "file['hashtags_text']=np.zeros(numl)\n",
    "file['user_mentions']=np.zeros(numl)\n",
    "file['urls']=np.zeros(numl)\n",
    "\n",
    "for line in range(numl):\n",
    "    file['entities'][line] =ast.literal_eval(file['entities'][line])\n",
    "    file['hashtags'][line] = file['entities'][line]['hashtags'] \n",
    "    file['user_mentions'][line] = file['entities'][line]['user_mentions']\n",
    "    file['urls'][line] = file['entities'][line]['urls']\n",
    "    if int(len(str(file['hashtags'][line]))>10):\n",
    "        file['hashtags_text'][line] = str(file['hashtags'][line]).split(':')[1].split(',')[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.drop('entities',axis=1,inplace=True)\n",
    "file.drop('hashtags',axis=1,inplace=True)\n",
    "file['hashtags_text'] = str(file['hashtags_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nuria\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Creem variable numerica amb l'hora del tweet\n",
    "file['hour'] = np.zeros(numl)\n",
    "for i in range(len(file)):\n",
    "    file['hour'][i] = int(file['created_at'][i][11:13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Tweet           created_at  FC  \\\n",
      "0  Desde el #FCJumilla damos nuestra m√°s sincera ...  2018-09-30 15:58:44  18   \n",
      "1  Me estoy volviendo loca hasta por cada una de ...  2018-09-24 03:05:47   0   \n",
      "2  üèü | El #FCJumilla ya est√° en La Condomina   ‚öΩÔ∏è...  2018-09-30 15:38:18   4   \n",
      "3  üìπ | El vestuario del #FCJumilla en La Condomin...  2018-09-30 15:19:29  21   \n",
      "4  üìë Jornada 6 | El colegiado andaluz Guzm√°n Mans...  2018-09-30 15:10:30   0   \n",
      "\n",
      "   RT           hashtags_text  \\\n",
      "0   4          [ 'FCJumilla']   \n",
      "1   0                       0   \n",
      "2   2          [ 'FCJumilla']   \n",
      "3   6          [ 'FCJumilla']   \n",
      "4   0  [ 'UCAMMurciaJumilla']   \n",
      "\n",
      "                                       user_mentions  \\\n",
      "0  [{'screen_name': 'alejanvalverde', 'name': 'al...   \n",
      "1                                                 []   \n",
      "2                                                 []   \n",
      "3  [{'screen_name': 'Pedrocc57C', 'name': 'Utille...   \n",
      "4                                                 []   \n",
      "\n",
      "                                                urls  hour  \n",
      "0  [{'url': 'https://t.co/XqLolr5sfl', 'expanded_...  15.0  \n",
      "1                                                 []   3.0  \n",
      "2  [{'url': 'https://t.co/1RLMpCm9bT', 'expanded_...  15.0  \n",
      "3  [{'url': 'https://t.co/GYXc4ymy2Y', 'expanded_...  15.0  \n",
      "4                                                 []  15.0  \n"
     ]
    }
   ],
   "source": [
    "print(file.head())\n",
    "file.to_csv('temporal1_tweet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import nltk\n",
    "import re\n",
    "from unicodedata import normalize\n",
    "\n",
    "file = pd.read_csv(\"temporal1_tweet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'FCJumilla', 'indices': [9, 19]}]\n",
      "[\" 'FCJumilla'\"]\n"
     ]
    }
   ],
   "source": [
    "file = file[:550][:]\n",
    "print(file['hashtags'][0])\n",
    "print(file['hashtags'][0].split(':')[1].split(',')[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "file['hashtags_text'] = str(file['hashtags_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treballem amb una mostra per agilitzar els calculs\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "X_1 = vectorizer.fit_transform(file['Tweet'])\n",
    "X_1 = pd.DataFrame(X_1.todense())\n",
    "X_2 = vectorizer.fit_transform(file['hashtags_text'])\n",
    "X_2 = pd.DataFrame(X_2.todense())\n",
    "X_3 = file['hour']\n",
    "\n",
    "X = pd.concat([X_1, X_2, X_3], axis=1)\n",
    "\n",
    "y = file['FC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nuria\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size = 0.7, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification accuracy: 0.46853146853146854\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.50      0.65      1124\n",
      "          1       0.13      0.25      0.17       158\n",
      "          2       0.03      0.60      0.05         5\n",
      "          3       0.00      0.00      0.00         0\n",
      "          4       0.00      0.00      0.00         0\n",
      "          5       0.00      0.00      0.00         0\n",
      "          6       0.00      0.00      0.00         0\n",
      "          7       0.00      0.00      0.00         0\n",
      "          8       0.00      0.00      0.00         0\n",
      "          9       0.00      0.00      0.00         0\n",
      "         10       0.00      0.00      0.00         0\n",
      "         11       0.00      0.00      0.00         0\n",
      "         12       0.00      0.00      0.00         0\n",
      "         13       0.00      0.00      0.00         0\n",
      "         14       0.00      0.00      0.00         0\n",
      "         15       0.00      0.00      0.00         0\n",
      "         16       0.00      0.00      0.00         0\n",
      "         17       0.00      0.00      0.00         0\n",
      "         18       0.00      0.00      0.00         0\n",
      "         19       0.00      0.00      0.00         0\n",
      "         20       0.00      0.00      0.00         0\n",
      "         21       0.00      0.00      0.00         0\n",
      "         24       0.00      0.00      0.00         0\n",
      "         25       0.00      0.00      0.00         0\n",
      "         29       0.00      0.00      0.00         0\n",
      "         31       0.00      0.00      0.00         0\n",
      "         33       0.00      0.00      0.00         0\n",
      "         34       0.00      0.00      0.00         0\n",
      "         35       0.00      0.00      0.00         0\n",
      "         41       0.00      0.00      0.00         0\n",
      "         43       0.00      0.00      0.00         0\n",
      "         45       0.00      0.00      0.00         0\n",
      "         48       0.00      0.00      0.00         0\n",
      "         50       0.00      0.00      0.00         0\n",
      "         52       0.00      0.00      0.00         0\n",
      "         53       0.00      0.00      0.00         0\n",
      "         54       0.00      0.00      0.00         0\n",
      "         81       0.00      0.00      0.00         0\n",
      "         93       0.00      0.00      0.00         0\n",
      "         98       0.00      0.00      0.00         0\n",
      "        103       0.00      0.00      0.00         0\n",
      "        136       0.00      0.00      0.00         0\n",
      "        142       0.00      0.00      0.00         0\n",
      "        161       0.00      0.00      0.00         0\n",
      "        170       0.00      0.00      0.00         0\n",
      "        214       0.00      0.00      0.00         0\n",
      "        222       0.00      0.00      0.00         0\n",
      "        405       0.00      0.00      0.00         0\n",
      "        594       0.00      0.00      0.00         0\n",
      "        658       0.00      0.00      0.00         0\n",
      "        703       0.00      0.00      0.00         0\n",
      "       1577       0.00      0.00      0.00         0\n",
      "       2921       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.82      0.47      0.58      1287\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nuria\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Let us tokenize the data\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "nb = BernoulliNB()\n",
    "nb.fit(X_train,y_train)\n",
    "\n",
    "y_hat = nb.predict(X_test)\n",
    "from sklearn import metrics   \n",
    "    \n",
    "print (\"classification accuracy:\", metrics.accuracy_score(y_hat, y_test))\n",
    "print (\"Classification Report:\")\n",
    "print (metrics.classification_report(y_hat,np.array(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the count number of instances considering that a word has a minimum support of two documents\n",
    "vectorizer = CountVectorizer(min_df=2, \n",
    "# stop words such as 'and', 'the', 'of' are removed                             \n",
    " stop_words='english', \n",
    " strip_accents='unicode')\n",
    "\n",
    "for i in range(len(file)):\n",
    "    #example of the tokenization\n",
    "    test_string = file['Tweet'][i]\n",
    "    #print (\"Example: \" + test_string +\"\\n\")\n",
    "    #print (\"Preprocessed: \" + vectorizer.build_preprocessor()(test_string)+\"\\n\")\n",
    "    #print (\"Tokenized:\" + str(vectorizer.build_tokenizer()(test_string))+\"\\n\")\n",
    "    print (\"Analyzed data string:\" + str(vectorizer.build_analyzer()(test_string))+\"\\n\")\n",
    "\n",
    "    \n",
    ">>> measurements = [\n",
    "...     {'city': 'Dubai', 'temperature': 33.},\n",
    "...     {'city': 'London', 'temperature': 12.},\n",
    "...     {'city': 'San Francisco', 'temperature': 18.},\n",
    "... ]\n",
    "\n",
    ">>> from sklearn.feature_extraction import DictVectorizer\n",
    ">>> vec = DictVectorizer()\n",
    "\n",
    ">>> vec.fit_transform(measurements).toarray()\n",
    "array([[ 1.,  0.,  0., 33.],\n",
    "       [ 0.,  1.,  0., 12.],\n",
    "       [ 0.,  0.,  1., 18.]])\n",
    "\n",
    ">>> vec.get_feature_names()\n",
    "['city=Dubai', 'city=London', 'city=San Francisco', 'temperature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nuria\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "C:\\Users\\Nuria\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>created_at</th>\n",
       "      <th>FC</th>\n",
       "      <th>RT</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>desde el #fcjumilla damos nuestra mas sincera ...</td>\n",
       "      <td>2018-09-30 15:58:44</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>[{'text': 'FCJumilla', 'indices': [9, 19]}]</td>\n",
       "      <td>[{'screen_name': 'alejanvalverde', 'name': 'al...</td>\n",
       "      <td>[{'url': 'https://t.co/XqLolr5sfl', 'expanded_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>me estoy volviendo loca hasta por cada una de ...</td>\n",
       "      <td>2018-09-24 03:05:47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>üèü | el #fcjumilla ya esta en la condomina   ‚öΩÔ∏è...</td>\n",
       "      <td>2018-09-30 15:38:18</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>[{'text': 'FCJumilla', 'indices': [7, 17]}, {'...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'url': 'https://t.co/1RLMpCm9bT', 'expanded_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>üìπ | el vestuario del #fcjumilla en la condomin...</td>\n",
       "      <td>2018-09-30 15:19:29</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>[{'text': 'FCJumilla', 'indices': [21, 31]}]</td>\n",
       "      <td>[{'screen_name': 'Pedrocc57C', 'name': 'Utille...</td>\n",
       "      <td>[{'url': 'https://t.co/GYXc4ymy2Y', 'expanded_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>üìë jornada 6 | el colegiado andaluz guzman mans...</td>\n",
       "      <td>2018-09-30 15:10:30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'text': 'UCAMMurciaJumilla', 'indices': [64,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              Tweet  \\\n",
       "0           0  desde el #fcjumilla damos nuestra mas sincera ...   \n",
       "1           1  me estoy volviendo loca hasta por cada una de ...   \n",
       "2           2  üèü | el #fcjumilla ya esta en la condomina   ‚öΩÔ∏è...   \n",
       "3           3  üìπ | el vestuario del #fcjumilla en la condomin...   \n",
       "4           4  üìë jornada 6 | el colegiado andaluz guzman mans...   \n",
       "\n",
       "            created_at  FC  RT  \\\n",
       "0  2018-09-30 15:58:44  18   4   \n",
       "1  2018-09-24 03:05:47   0   0   \n",
       "2  2018-09-30 15:38:18   4   2   \n",
       "3  2018-09-30 15:19:29  21   6   \n",
       "4  2018-09-30 15:10:30   0   0   \n",
       "\n",
       "                                            hashtags  \\\n",
       "0        [{'text': 'FCJumilla', 'indices': [9, 19]}]   \n",
       "1                                                 []   \n",
       "2  [{'text': 'FCJumilla', 'indices': [7, 17]}, {'...   \n",
       "3       [{'text': 'FCJumilla', 'indices': [21, 31]}]   \n",
       "4  [{'text': 'UCAMMurciaJumilla', 'indices': [64,...   \n",
       "\n",
       "                                       user_mentions  \\\n",
       "0  [{'screen_name': 'alejanvalverde', 'name': 'al...   \n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "3  [{'screen_name': 'Pedrocc57C', 'name': 'Utille...   \n",
       "4                                                 []   \n",
       "\n",
       "                                                urls  \n",
       "0  [{'url': 'https://t.co/XqLolr5sfl', 'expanded_...  \n",
       "1                                                 []  \n",
       "2  [{'url': 'https://t.co/1RLMpCm9bT', 'expanded_...  \n",
       "3  [{'url': 'https://t.co/GYXc4ymy2Y', 'expanded_...  \n",
       "4                                                 []  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(file)):\n",
    "    # Passem tots els tweets a minuscules\n",
    "    file['Tweet'][i] = file['Tweet'][i].lower()\n",
    "    # Treiem accents?\n",
    "    file['Tweet'][i] = re.sub(\n",
    "        r\"([^n\\u0300-\\u036f]|n(?!\\u0303(?![\\u0300-\\u036f])))[\\u0300-\\u036f]+\", r\"\\1\", \n",
    "        normalize( \"NFD\", file['Tweet'][i]), 0, re.I)\n",
    "file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'builtin_function_or_method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-95e51efa85b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Creem variable numerica amb l'hora del tweet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfile\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hour'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'created_at'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# Aplicar la pill de ML\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'builtin_function_or_method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "\n",
    "# Aplicar la pill de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'15'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 'holaquetal.be'\n",
    "x.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/eliaficapalvila/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####TWEET\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text preprocessing\n",
    "from nltk.tokenize import word_tokenize\n",
    "from stop_words import get_stop_words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
