{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import nltk\n",
    "import re\n",
    "from unicodedata import normalize\n",
    "\n",
    "file = pd.read_csv(\"tweet.csv\")\n",
    "file.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "file.drop('id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>created_at</th>\n",
       "      <th>entities</th>\n",
       "      <th>FC</th>\n",
       "      <th>RT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Desde el #FCJumilla damos nuestra m√°s sincera ...</td>\n",
       "      <td>2018-09-30 15:58:44</td>\n",
       "      <td>{'hashtags': [{'text': 'FCJumilla', 'indices':...</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Me estoy volviendo loca hasta por cada una de ...</td>\n",
       "      <td>2018-09-24 03:05:47</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>üèü | El #FCJumilla ya est√° en La Condomina   ‚öΩÔ∏è...</td>\n",
       "      <td>2018-09-30 15:38:18</td>\n",
       "      <td>{'hashtags': [{'text': 'FCJumilla', 'indices':...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>üìπ | El vestuario del #FCJumilla en La Condomin...</td>\n",
       "      <td>2018-09-30 15:19:29</td>\n",
       "      <td>{'hashtags': [{'text': 'FCJumilla', 'indices':...</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>üìë Jornada 6 | El colegiado andaluz Guzm√°n Mans...</td>\n",
       "      <td>2018-09-30 15:10:30</td>\n",
       "      <td>{'hashtags': [{'text': 'UCAMMurciaJumilla', 'i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet           created_at  \\\n",
       "0  Desde el #FCJumilla damos nuestra m√°s sincera ...  2018-09-30 15:58:44   \n",
       "1  Me estoy volviendo loca hasta por cada una de ...  2018-09-24 03:05:47   \n",
       "2  üèü | El #FCJumilla ya est√° en La Condomina   ‚öΩÔ∏è...  2018-09-30 15:38:18   \n",
       "3  üìπ | El vestuario del #FCJumilla en La Condomin...  2018-09-30 15:19:29   \n",
       "4  üìë Jornada 6 | El colegiado andaluz Guzm√°n Mans...  2018-09-30 15:10:30   \n",
       "\n",
       "                                            entities  FC  RT  \n",
       "0  {'hashtags': [{'text': 'FCJumilla', 'indices':...  18   4  \n",
       "1  {'hashtags': [], 'symbols': [], 'user_mentions...   0   0  \n",
       "2  {'hashtags': [{'text': 'FCJumilla', 'indices':...   4   2  \n",
       "3  {'hashtags': [{'text': 'FCJumilla', 'indices':...  21   6  \n",
       "4  {'hashtags': [{'text': 'UCAMMurciaJumilla', 'i...   0   0  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hashtags': [{'text': 'FCJumilla', 'indices': [9, 19]}], 'symbols': [], 'user_mentions': [{'screen_name': 'alejanvalverde', 'name': 'alejandro valverde', 'id': 248879448, 'id_str': '248879448', 'indices': [100, 115]}], 'urls': [{'url': 'https://t.co/XqLolr5sfl', 'expanded_url': 'https://twitter.com/i/web/status/1046429145914384386', 'display_url': 'twitter.com/i/web/status/1‚Ä¶', 'indices': [117, 140]}]}\n"
     ]
    }
   ],
   "source": [
    "print(file['entities'][0])\n",
    "#ens quedem amb:\n",
    "#hashtags\n",
    "#user_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nuria\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\Nuria\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\Nuria\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\Users\\Nuria\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\Nuria\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\Nuria\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "numl = len(file.index.values)\n",
    "file['hashtags']=np.zeros(numl)\n",
    "file['hashtags_text']=np.zeros(numl)\n",
    "file['user_mentions']=np.zeros(numl)\n",
    "file['urls']=np.zeros(numl)\n",
    "\n",
    "for line in range(numl):\n",
    "    file['entities'][line] =ast.literal_eval(file['entities'][line])\n",
    "    file['hashtags'][line] = file['entities'][line]['hashtags'] \n",
    "    file['user_mentions'][line] = file['entities'][line]['user_mentions']\n",
    "    file['urls'][line] = file['entities'][line]['urls']\n",
    "    if int(len(str(file['hashtags'][line]))>10):\n",
    "        file['hashtags_text'][line] = str(file['hashtags'][line]).split(':')[1].split(',')[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.drop('entities',axis=1,inplace=True)\n",
    "file.drop('hashtags',axis=1,inplace=True)\n",
    "file['hashtags_text'] = str(file['hashtags_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nuria\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Creem variable numerica amb l'hora del tweet\n",
    "file['hour'] = np.zeros(numl)\n",
    "for i in range(len(file)):\n",
    "    file['hour'][i] = int(file['created_at'][i][11:13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Tweet           created_at  FC  \\\n",
      "0  Desde el #FCJumilla damos nuestra m√°s sincera ...  2018-09-30 15:58:44  18   \n",
      "1  Me estoy volviendo loca hasta por cada una de ...  2018-09-24 03:05:47   0   \n",
      "2  üèü | El #FCJumilla ya est√° en La Condomina   ‚öΩÔ∏è...  2018-09-30 15:38:18   4   \n",
      "3  üìπ | El vestuario del #FCJumilla en La Condomin...  2018-09-30 15:19:29  21   \n",
      "4  üìë Jornada 6 | El colegiado andaluz Guzm√°n Mans...  2018-09-30 15:10:30   0   \n",
      "\n",
      "   RT           hashtags_text  \\\n",
      "0   4          [ 'FCJumilla']   \n",
      "1   0                       0   \n",
      "2   2          [ 'FCJumilla']   \n",
      "3   6          [ 'FCJumilla']   \n",
      "4   0  [ 'UCAMMurciaJumilla']   \n",
      "\n",
      "                                       user_mentions  \\\n",
      "0  [{'screen_name': 'alejanvalverde', 'name': 'al...   \n",
      "1                                                 []   \n",
      "2                                                 []   \n",
      "3  [{'screen_name': 'Pedrocc57C', 'name': 'Utille...   \n",
      "4                                                 []   \n",
      "\n",
      "                                                urls  hour  \n",
      "0  [{'url': 'https://t.co/XqLolr5sfl', 'expanded_...  15.0  \n",
      "1                                                 []   3.0  \n",
      "2  [{'url': 'https://t.co/1RLMpCm9bT', 'expanded_...  15.0  \n",
      "3  [{'url': 'https://t.co/GYXc4ymy2Y', 'expanded_...  15.0  \n",
      "4                                                 []  15.0  \n"
     ]
    }
   ],
   "source": [
    "print(file.head())\n",
    "file.to_csv('temporal1_tweet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import nltk\n",
    "import re\n",
    "from unicodedata import normalize\n",
    "\n",
    "file = pd.read_csv(\"temporal1_tweet.csv\")\n",
    "file['hashtags_text'] = str(file['hashtags_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treballem amb una mostra per agilitzar els calculs\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "X_1 = vectorizer.fit_transform(file['Tweet'])\n",
    "X_1 = pd.DataFrame(X_1.todense())\n",
    "X_2 = vectorizer.fit_transform(file['hashtags_text'])\n",
    "X_2 = pd.DataFrame(X_2.todense())\n",
    "X_3 = file['hour']\n",
    "\n",
    "X = pd.concat([X_1, X_2, X_3], axis=1)\n",
    "\n",
    "y_fc = file['FC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nuria\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "X_train_fc, X_test_fc, y_train_fc, y_test_fc = model_selection.train_test_split(X, y_fc, train_size = 0.7, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification accuracy: 0.46853146853146854\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.50      0.65      1124\n",
      "          1       0.13      0.25      0.17       158\n",
      "          2       0.03      0.60      0.05         5\n",
      "          3       0.00      0.00      0.00         0\n",
      "          4       0.00      0.00      0.00         0\n",
      "          5       0.00      0.00      0.00         0\n",
      "          6       0.00      0.00      0.00         0\n",
      "          7       0.00      0.00      0.00         0\n",
      "          8       0.00      0.00      0.00         0\n",
      "          9       0.00      0.00      0.00         0\n",
      "         10       0.00      0.00      0.00         0\n",
      "         11       0.00      0.00      0.00         0\n",
      "         12       0.00      0.00      0.00         0\n",
      "         13       0.00      0.00      0.00         0\n",
      "         14       0.00      0.00      0.00         0\n",
      "         15       0.00      0.00      0.00         0\n",
      "         16       0.00      0.00      0.00         0\n",
      "         17       0.00      0.00      0.00         0\n",
      "         18       0.00      0.00      0.00         0\n",
      "         19       0.00      0.00      0.00         0\n",
      "         20       0.00      0.00      0.00         0\n",
      "         21       0.00      0.00      0.00         0\n",
      "         24       0.00      0.00      0.00         0\n",
      "         25       0.00      0.00      0.00         0\n",
      "         29       0.00      0.00      0.00         0\n",
      "         31       0.00      0.00      0.00         0\n",
      "         33       0.00      0.00      0.00         0\n",
      "         34       0.00      0.00      0.00         0\n",
      "         35       0.00      0.00      0.00         0\n",
      "         41       0.00      0.00      0.00         0\n",
      "         43       0.00      0.00      0.00         0\n",
      "         45       0.00      0.00      0.00         0\n",
      "         48       0.00      0.00      0.00         0\n",
      "         50       0.00      0.00      0.00         0\n",
      "         52       0.00      0.00      0.00         0\n",
      "         53       0.00      0.00      0.00         0\n",
      "         54       0.00      0.00      0.00         0\n",
      "         81       0.00      0.00      0.00         0\n",
      "         93       0.00      0.00      0.00         0\n",
      "         98       0.00      0.00      0.00         0\n",
      "        103       0.00      0.00      0.00         0\n",
      "        136       0.00      0.00      0.00         0\n",
      "        142       0.00      0.00      0.00         0\n",
      "        161       0.00      0.00      0.00         0\n",
      "        170       0.00      0.00      0.00         0\n",
      "        214       0.00      0.00      0.00         0\n",
      "        222       0.00      0.00      0.00         0\n",
      "        405       0.00      0.00      0.00         0\n",
      "        594       0.00      0.00      0.00         0\n",
      "        658       0.00      0.00      0.00         0\n",
      "        703       0.00      0.00      0.00         0\n",
      "       1577       0.00      0.00      0.00         0\n",
      "       2921       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.82      0.47      0.58      1287\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nuria\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Let us tokenize the data\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "nb = BernoulliNB()\n",
    "nb.fit(X_train_fc,y_train_fc)\n",
    "\n",
    "y_hat_fc = nb.predict(X_test_fc)\n",
    "from sklearn import metrics   \n",
    "    \n",
    "print (\"classification accuracy:\", metrics.accuracy_score(y_hat_fc, y_test_fc))\n",
    "print (\"Classification Report:\")\n",
    "print (metrics.classification_report(y_hat_fc,np.array(y_test_fc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nuria\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification accuracy: 0.7801087801087802\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.79      0.88      1253\n",
      "          1       0.07      0.26      0.11        34\n",
      "          2       0.00      0.00      0.00         0\n",
      "          3       0.00      0.00      0.00         0\n",
      "          4       0.00      0.00      0.00         0\n",
      "          5       0.00      0.00      0.00         0\n",
      "          6       0.00      0.00      0.00         0\n",
      "          7       0.00      0.00      0.00         0\n",
      "          8       0.00      0.00      0.00         0\n",
      "          9       0.00      0.00      0.00         0\n",
      "         10       0.00      0.00      0.00         0\n",
      "         11       0.00      0.00      0.00         0\n",
      "         12       0.00      0.00      0.00         0\n",
      "         14       0.00      0.00      0.00         0\n",
      "         15       0.00      0.00      0.00         0\n",
      "         18       0.00      0.00      0.00         0\n",
      "         20       0.00      0.00      0.00         0\n",
      "         23       0.00      0.00      0.00         0\n",
      "         24       0.00      0.00      0.00         0\n",
      "         25       0.00      0.00      0.00         0\n",
      "         34       0.00      0.00      0.00         0\n",
      "         37       0.00      0.00      0.00         0\n",
      "         38       0.00      0.00      0.00         0\n",
      "         40       0.00      0.00      0.00         0\n",
      "         41       0.00      0.00      0.00         0\n",
      "         47       0.00      0.00      0.00         0\n",
      "         48       0.00      0.00      0.00         0\n",
      "         50       0.00      0.00      0.00         0\n",
      "         75       0.00      0.00      0.00         0\n",
      "         84       0.00      0.00      0.00         0\n",
      "         91       0.00      0.00      0.00         0\n",
      "         99       0.00      0.00      0.00         0\n",
      "        236       0.00      0.00      0.00         0\n",
      "        265       0.00      0.00      0.00         0\n",
      "        282       0.00      0.00      0.00         0\n",
      "        482       0.00      0.00      0.00         0\n",
      "        821       0.00      0.00      0.00         0\n",
      "       1632       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.96      0.78      0.86      1287\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nuria\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_rt = file['RT']\n",
    "X_train_rt, X_test_rt, y_train_rt, y_test_rt = model_selection.train_test_split(X, y_rt, train_size = 0.7, random_state = 42)\n",
    "nb = BernoulliNB()\n",
    "nb.fit(X_train_rt,y_train_rt)\n",
    "\n",
    "y_hat_rt = nb.predict(X_test_rt)\n",
    "from sklearn import metrics   \n",
    "    \n",
    "print (\"classification accuracy:\", metrics.accuracy_score(y_hat_rt, y_test_rt))\n",
    "print (\"Classification Report:\")\n",
    "print (metrics.classification_report(y_hat_rt,np.array(y_test_rt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
