{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import nltk\n",
    "import re\n",
    "from unicodedata import normalize\n",
    "\n",
    "file = pd.read_csv(\"tweet.csv\")\n",
    "file.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "file.drop('id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>j_user</th>\n",
       "      <th>created_at</th>\n",
       "      <th>entities</th>\n",
       "      <th>followers_user</th>\n",
       "      <th>FC</th>\n",
       "      <th>RT</th>\n",
       "      <th>trending_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Desde el #FCJumilla damos nuestra m√°s sincera ...</td>\n",
       "      <td>{'id': 2664945430, 'id_str': '2664945430', 'na...</td>\n",
       "      <td>2018-09-30 15:58:44</td>\n",
       "      <td>{'hashtags': [{'text': 'FCJumilla', 'indices':...</td>\n",
       "      <td>7162</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Me estoy volviendo loca hasta por cada una de ...</td>\n",
       "      <td>{'id': 713359736, 'id_str': '713359736', 'name...</td>\n",
       "      <td>2018-09-24 03:05:47</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>531</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>üèü | El #FCJumilla ya est√° en La Condomina   ‚öΩÔ∏è...</td>\n",
       "      <td>{'id': 2664945430, 'id_str': '2664945430', 'na...</td>\n",
       "      <td>2018-09-30 15:38:18</td>\n",
       "      <td>{'hashtags': [{'text': 'FCJumilla', 'indices':...</td>\n",
       "      <td>7162</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>üìπ | El vestuario del #FCJumilla en La Condomin...</td>\n",
       "      <td>{'id': 2664945430, 'id_str': '2664945430', 'na...</td>\n",
       "      <td>2018-09-30 15:19:29</td>\n",
       "      <td>{'hashtags': [{'text': 'FCJumilla', 'indices':...</td>\n",
       "      <td>7162</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>üìë Jornada 6 | El colegiado andaluz Guzm√°n Mans...</td>\n",
       "      <td>{'id': 2664945430, 'id_str': '2664945430', 'na...</td>\n",
       "      <td>2018-09-30 15:10:30</td>\n",
       "      <td>{'hashtags': [{'text': 'UCAMMurciaJumilla', 'i...</td>\n",
       "      <td>7162</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  \\\n",
       "0  Desde el #FCJumilla damos nuestra m√°s sincera ...   \n",
       "1  Me estoy volviendo loca hasta por cada una de ...   \n",
       "2  üèü | El #FCJumilla ya est√° en La Condomina   ‚öΩÔ∏è...   \n",
       "3  üìπ | El vestuario del #FCJumilla en La Condomin...   \n",
       "4  üìë Jornada 6 | El colegiado andaluz Guzm√°n Mans...   \n",
       "\n",
       "                                              j_user           created_at  \\\n",
       "0  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:58:44   \n",
       "1  {'id': 713359736, 'id_str': '713359736', 'name...  2018-09-24 03:05:47   \n",
       "2  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:38:18   \n",
       "3  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:19:29   \n",
       "4  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:10:30   \n",
       "\n",
       "                                            entities  followers_user  FC  RT  \\\n",
       "0  {'hashtags': [{'text': 'FCJumilla', 'indices':...            7162  18   4   \n",
       "1  {'hashtags': [], 'symbols': [], 'user_mentions...             531   0   0   \n",
       "2  {'hashtags': [{'text': 'FCJumilla', 'indices':...            7162   4   2   \n",
       "3  {'hashtags': [{'text': 'FCJumilla', 'indices':...            7162  21   6   \n",
       "4  {'hashtags': [{'text': 'UCAMMurciaJumilla', 'i...            7162   0   0   \n",
       "\n",
       "   trending_topic  \n",
       "0             0.0  \n",
       "1             0.0  \n",
       "2             0.0  \n",
       "3             0.0  \n",
       "4             0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hashtags': [{'text': 'FCJumilla', 'indices': [9, 19]}], 'symbols': [], 'user_mentions': [{'screen_name': 'alejanvalverde', 'name': 'alejandro valverde', 'id': 248879448, 'id_str': '248879448', 'indices': [100, 115]}], 'urls': [{'url': 'https://t.co/XqLolr5sfl', 'expanded_url': 'https://twitter.com/i/web/status/1046429145914384386', 'display_url': 'twitter.com/i/web/status/1‚Ä¶', 'indices': [117, 140]}]}\n"
     ]
    }
   ],
   "source": [
    "print(file['entities'][0])\n",
    "#ens quedem amb:\n",
    "#hashtags\n",
    "#user_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nuria\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\Nuria\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\Nuria\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\Users\\Nuria\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\Nuria\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\Nuria\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "numl = len(file.index.values)\n",
    "file['hashtags']=np.zeros(numl)\n",
    "file['hashtags_text']=np.zeros(numl)\n",
    "file['user_mentions']=np.zeros(numl)\n",
    "file['urls']=np.zeros(numl)\n",
    "\n",
    "for line in range(numl):\n",
    "    file['entities'][line] =ast.literal_eval(file['entities'][line])\n",
    "    file['hashtags'][line] = file['entities'][line]['hashtags'] \n",
    "    file['user_mentions'][line] = file['entities'][line]['user_mentions']\n",
    "    file['urls'][line] = file['entities'][line]['urls']\n",
    "    if int(len(str(file['hashtags'][line]))>10):\n",
    "        file['hashtags_text'][line] = str(file['hashtags'][line]).split(':')[1].split(',')[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.drop('entities',axis=1,inplace=True)\n",
    "file.drop('hashtags',axis=1,inplace=True)\n",
    "file['hashtags_text'] = str(file['hashtags_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nuria\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Creem variable numerica amb l'hora del tweet\n",
    "file['hour'] = np.zeros(numl)\n",
    "for i in range(len(file)):\n",
    "    file['hour'][i] = int(file['created_at'][i][11:13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Tweet  \\\n",
      "0  Desde el #FCJumilla damos nuestra m√°s sincera ...   \n",
      "1  Me estoy volviendo loca hasta por cada una de ...   \n",
      "2  üèü | El #FCJumilla ya est√° en La Condomina   ‚öΩÔ∏è...   \n",
      "3  üìπ | El vestuario del #FCJumilla en La Condomin...   \n",
      "4  üìë Jornada 6 | El colegiado andaluz Guzm√°n Mans...   \n",
      "\n",
      "                                              j_user           created_at  \\\n",
      "0  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:58:44   \n",
      "1  {'id': 713359736, 'id_str': '713359736', 'name...  2018-09-24 03:05:47   \n",
      "2  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:38:18   \n",
      "3  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:19:29   \n",
      "4  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:10:30   \n",
      "\n",
      "   followers_user  FC  RT  trending_topic  \\\n",
      "0            7162  18   4             0.0   \n",
      "1             531   0   0             0.0   \n",
      "2            7162   4   2             0.0   \n",
      "3            7162  21   6             0.0   \n",
      "4            7162   0   0             0.0   \n",
      "\n",
      "                                       hashtags_text  \\\n",
      "0  0               [ 'FCJumilla']\\n1             ...   \n",
      "1  0               [ 'FCJumilla']\\n1             ...   \n",
      "2  0               [ 'FCJumilla']\\n1             ...   \n",
      "3  0               [ 'FCJumilla']\\n1             ...   \n",
      "4  0               [ 'FCJumilla']\\n1             ...   \n",
      "\n",
      "                                       user_mentions  \\\n",
      "0  [{'screen_name': 'alejanvalverde', 'name': 'al...   \n",
      "1                                                 []   \n",
      "2                                                 []   \n",
      "3  [{'screen_name': 'Pedrocc57C', 'name': 'Utille...   \n",
      "4                                                 []   \n",
      "\n",
      "                                                urls  hour  \n",
      "0  [{'url': 'https://t.co/XqLolr5sfl', 'expanded_...  15.0  \n",
      "1                                                 []   3.0  \n",
      "2  [{'url': 'https://t.co/1RLMpCm9bT', 'expanded_...  15.0  \n",
      "3  [{'url': 'https://t.co/GYXc4ymy2Y', 'expanded_...  15.0  \n",
      "4                                                 []  15.0  \n"
     ]
    }
   ],
   "source": [
    "print(file.head())\n",
    "file.to_csv('temporal1_tweet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import nltk\n",
    "import re\n",
    "from unicodedata import normalize\n",
    "\n",
    "file = pd.read_csv(\"temporal1_tweet.csv\")\n",
    "#file['hashtags_text'] = str(file['hashtags_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituim per 0 els registres amb NaNs\n",
    "\n",
    "file[file[\"trending_topic\"].isnull()]\n",
    "#file= file.drop(file[file[\"trending_topic\"].isnull()].index,axis= 0) \n",
    "file = file.fillna(value={\"trending_topic\":0}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "elim = pd.read_excel('eliminar_paraules.xlsx', header=None)\n",
    "y=elim[0]\n",
    "for i in range(len(elim)):\n",
    "    y[i] = re.sub(\n",
    "            r\"([^n\\u0300-\\u036f]|n(?!\\u0303(?![\\u0300-\\u036f])))[\\u0300-\\u036f]+\", r\"\\1\", \n",
    "            normalize( \"NFD\", y[i]), 0, re.I)\n",
    "y = y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treballem amb una mostra per agilitzar els calculs\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer = CountVectorizer(min_df=2, \n",
    "# stop words such as 'and', 'the', 'of' are removed                             \n",
    " stop_words=y, \n",
    " strip_accents='unicode')\n",
    "X_1 = vectorizer.fit_transform(file['Tweet'])\n",
    "X_1 = pd.DataFrame(X_1.todense())\n",
    "X_2 = vectorizer.fit_transform(file['hashtags_text'])\n",
    "X_2 = pd.DataFrame(X_2.todense())\n",
    "X_3 = file[['hour', 'followers_user', 'trending_topic']]\n",
    "\n",
    "X = pd.concat([X_1, X_2, X_3], axis=1)\n",
    "\n",
    "y_fc = file['FC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nuria\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "X_train_fc, X_test_fc, y_train_fc, y_test_fc = model_selection.train_test_split(X, y_fc, train_size = 0.7, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification accuracy: 0.46386946386946387\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.49      0.64      1138\n",
      "          1       0.10      0.23      0.14       143\n",
      "          2       0.04      0.67      0.07         6\n",
      "          3       0.00      0.00      0.00         0\n",
      "          4       0.00      0.00      0.00         0\n",
      "          5       0.00      0.00      0.00         0\n",
      "          6       0.00      0.00      0.00         0\n",
      "          7       0.00      0.00      0.00         0\n",
      "          8       0.00      0.00      0.00         0\n",
      "          9       0.00      0.00      0.00         0\n",
      "         10       0.00      0.00      0.00         0\n",
      "         11       0.00      0.00      0.00         0\n",
      "         12       0.00      0.00      0.00         0\n",
      "         13       0.00      0.00      0.00         0\n",
      "         14       0.00      0.00      0.00         0\n",
      "         15       0.00      0.00      0.00         0\n",
      "         16       0.00      0.00      0.00         0\n",
      "         17       0.00      0.00      0.00         0\n",
      "         18       0.00      0.00      0.00         0\n",
      "         19       0.00      0.00      0.00         0\n",
      "         20       0.00      0.00      0.00         0\n",
      "         21       0.00      0.00      0.00         0\n",
      "         24       0.00      0.00      0.00         0\n",
      "         25       0.00      0.00      0.00         0\n",
      "         29       0.00      0.00      0.00         0\n",
      "         31       0.00      0.00      0.00         0\n",
      "         33       0.00      0.00      0.00         0\n",
      "         34       0.00      0.00      0.00         0\n",
      "         35       0.00      0.00      0.00         0\n",
      "         41       0.00      0.00      0.00         0\n",
      "         43       0.00      0.00      0.00         0\n",
      "         45       0.00      0.00      0.00         0\n",
      "         48       0.00      0.00      0.00         0\n",
      "         50       0.00      0.00      0.00         0\n",
      "         52       0.00      0.00      0.00         0\n",
      "         53       0.00      0.00      0.00         0\n",
      "         54       0.00      0.00      0.00         0\n",
      "         81       0.00      0.00      0.00         0\n",
      "         93       0.00      0.00      0.00         0\n",
      "         98       0.00      0.00      0.00         0\n",
      "        103       0.00      0.00      0.00         0\n",
      "        136       0.00      0.00      0.00         0\n",
      "        142       0.00      0.00      0.00         0\n",
      "        161       0.00      0.00      0.00         0\n",
      "        170       0.00      0.00      0.00         0\n",
      "        214       0.00      0.00      0.00         0\n",
      "        222       0.00      0.00      0.00         0\n",
      "        405       0.00      0.00      0.00         0\n",
      "        594       0.00      0.00      0.00         0\n",
      "        658       0.00      0.00      0.00         0\n",
      "        703       0.00      0.00      0.00         0\n",
      "       1577       0.00      0.00      0.00         0\n",
      "       2921       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.82      0.46      0.58      1287\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nuria\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Let us tokenize the data\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "nb = BernoulliNB()\n",
    "nb.fit(X_train_fc,y_train_fc)\n",
    "\n",
    "y_hat_fc = nb.predict(X_test_fc)\n",
    "from sklearn import metrics   \n",
    "    \n",
    "print (\"classification accuracy:\", metrics.accuracy_score(y_hat_fc, y_test_fc))\n",
    "print (\"Classification Report:\")\n",
    "print (metrics.classification_report(y_hat_fc,np.array(y_test_fc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nuria\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification accuracy: 0.7832167832167832\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.79      0.88      1256\n",
      "          1       0.08      0.32      0.13        31\n",
      "          2       0.00      0.00      0.00         0\n",
      "          3       0.00      0.00      0.00         0\n",
      "          4       0.00      0.00      0.00         0\n",
      "          5       0.00      0.00      0.00         0\n",
      "          6       0.00      0.00      0.00         0\n",
      "          7       0.00      0.00      0.00         0\n",
      "          8       0.00      0.00      0.00         0\n",
      "          9       0.00      0.00      0.00         0\n",
      "         10       0.00      0.00      0.00         0\n",
      "         11       0.00      0.00      0.00         0\n",
      "         12       0.00      0.00      0.00         0\n",
      "         14       0.00      0.00      0.00         0\n",
      "         15       0.00      0.00      0.00         0\n",
      "         18       0.00      0.00      0.00         0\n",
      "         20       0.00      0.00      0.00         0\n",
      "         23       0.00      0.00      0.00         0\n",
      "         24       0.00      0.00      0.00         0\n",
      "         25       0.00      0.00      0.00         0\n",
      "         34       0.00      0.00      0.00         0\n",
      "         37       0.00      0.00      0.00         0\n",
      "         38       0.00      0.00      0.00         0\n",
      "         40       0.00      0.00      0.00         0\n",
      "         41       0.00      0.00      0.00         0\n",
      "         47       0.00      0.00      0.00         0\n",
      "         48       0.00      0.00      0.00         0\n",
      "         50       0.00      0.00      0.00         0\n",
      "         75       0.00      0.00      0.00         0\n",
      "         84       0.00      0.00      0.00         0\n",
      "         91       0.00      0.00      0.00         0\n",
      "         99       0.00      0.00      0.00         0\n",
      "        236       0.00      0.00      0.00         0\n",
      "        265       0.00      0.00      0.00         0\n",
      "        282       0.00      0.00      0.00         0\n",
      "        482       0.00      0.00      0.00         0\n",
      "        821       0.00      0.00      0.00         0\n",
      "       1632       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.96      0.78      0.86      1287\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nuria\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_rt = file['RT']\n",
    "X_train_rt, X_test_rt, y_train_rt, y_test_rt = model_selection.train_test_split(X, y_rt, train_size = 0.7, random_state = 42)\n",
    "nb = BernoulliNB()\n",
    "nb.fit(X_train_rt,y_train_rt)\n",
    "\n",
    "y_hat_rt = nb.predict(X_test_rt)\n",
    "from sklearn import metrics   \n",
    "    \n",
    "print (\"classification accuracy:\", metrics.accuracy_score(y_hat_rt, y_test_rt))\n",
    "print (\"Classification Report:\")\n",
    "print (metrics.classification_report(y_hat_rt,np.array(y_test_rt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
