{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import nltk\n",
    "import re\n",
    "from unicodedata import normalize\n",
    "\n",
    "file = pd.read_csv(\"tweet.csv\")\n",
    "file.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "file.drop('id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>j_user</th>\n",
       "      <th>created_at</th>\n",
       "      <th>entities</th>\n",
       "      <th>followers_user</th>\n",
       "      <th>FC</th>\n",
       "      <th>RT</th>\n",
       "      <th>trending_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Desde el #FCJumilla damos nuestra m√°s sincera ...</td>\n",
       "      <td>{'id': 2664945430, 'id_str': '2664945430', 'na...</td>\n",
       "      <td>2018-09-30 15:58:44</td>\n",
       "      <td>{'hashtags': [{'text': 'FCJumilla', 'indices':...</td>\n",
       "      <td>7162</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Me estoy volviendo loca hasta por cada una de ...</td>\n",
       "      <td>{'id': 713359736, 'id_str': '713359736', 'name...</td>\n",
       "      <td>2018-09-24 03:05:47</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>531</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>üèü | El #FCJumilla ya est√° en La Condomina   ‚öΩÔ∏è...</td>\n",
       "      <td>{'id': 2664945430, 'id_str': '2664945430', 'na...</td>\n",
       "      <td>2018-09-30 15:38:18</td>\n",
       "      <td>{'hashtags': [{'text': 'FCJumilla', 'indices':...</td>\n",
       "      <td>7162</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>üìπ | El vestuario del #FCJumilla en La Condomin...</td>\n",
       "      <td>{'id': 2664945430, 'id_str': '2664945430', 'na...</td>\n",
       "      <td>2018-09-30 15:19:29</td>\n",
       "      <td>{'hashtags': [{'text': 'FCJumilla', 'indices':...</td>\n",
       "      <td>7162</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>üìë Jornada 6 | El colegiado andaluz Guzm√°n Mans...</td>\n",
       "      <td>{'id': 2664945430, 'id_str': '2664945430', 'na...</td>\n",
       "      <td>2018-09-30 15:10:30</td>\n",
       "      <td>{'hashtags': [{'text': 'UCAMMurciaJumilla', 'i...</td>\n",
       "      <td>7162</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  \\\n",
       "0  Desde el #FCJumilla damos nuestra m√°s sincera ...   \n",
       "1  Me estoy volviendo loca hasta por cada una de ...   \n",
       "2  üèü | El #FCJumilla ya est√° en La Condomina   ‚öΩÔ∏è...   \n",
       "3  üìπ | El vestuario del #FCJumilla en La Condomin...   \n",
       "4  üìë Jornada 6 | El colegiado andaluz Guzm√°n Mans...   \n",
       "\n",
       "                                              j_user           created_at  \\\n",
       "0  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:58:44   \n",
       "1  {'id': 713359736, 'id_str': '713359736', 'name...  2018-09-24 03:05:47   \n",
       "2  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:38:18   \n",
       "3  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:19:29   \n",
       "4  {'id': 2664945430, 'id_str': '2664945430', 'na...  2018-09-30 15:10:30   \n",
       "\n",
       "                                            entities  followers_user  FC  RT  \\\n",
       "0  {'hashtags': [{'text': 'FCJumilla', 'indices':...            7162  18   4   \n",
       "1  {'hashtags': [], 'symbols': [], 'user_mentions...             531   0   0   \n",
       "2  {'hashtags': [{'text': 'FCJumilla', 'indices':...            7162   4   2   \n",
       "3  {'hashtags': [{'text': 'FCJumilla', 'indices':...            7162  21   6   \n",
       "4  {'hashtags': [{'text': 'UCAMMurciaJumilla', 'i...            7162   0   0   \n",
       "\n",
       "   trending_topic  \n",
       "0             0.0  \n",
       "1             0.0  \n",
       "2             0.0  \n",
       "3             0.0  \n",
       "4             0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hashtags': [{'text': 'FCJumilla', 'indices': [9, 19]}], 'symbols': [], 'user_mentions': [{'screen_name': 'alejanvalverde', 'name': 'alejandro valverde', 'id': 248879448, 'id_str': '248879448', 'indices': [100, 115]}], 'urls': [{'url': 'https://t.co/XqLolr5sfl', 'expanded_url': 'https://twitter.com/i/web/status/1046429145914384386', 'display_url': 'twitter.com/i/web/status/1‚Ä¶', 'indices': [117, 140]}]}\n"
     ]
    }
   ],
   "source": [
    "print(file['entities'][0])\n",
    "#ens quedem amb:\n",
    "#hashtags\n",
    "#user_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nuria\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\Nuria\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\Nuria\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\Users\\Nuria\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\Nuria\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\Nuria\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "numl = len(file.index.values)\n",
    "file['hashtags']=np.zeros(numl)\n",
    "file['hashtags_text']=np.zeros(numl)\n",
    "file['user_mentions']=np.zeros(numl)\n",
    "file['urls']=np.zeros(numl)\n",
    "\n",
    "for line in range(numl):\n",
    "    file['entities'][line] =ast.literal_eval(file['entities'][line])\n",
    "    file['hashtags'][line] = file['entities'][line]['hashtags'] \n",
    "    file['user_mentions'][line] = file['entities'][line]['user_mentions']\n",
    "    file['urls'][line] = file['entities'][line]['urls']\n",
    "    if int(len(str(file['hashtags'][line]))>10):\n",
    "        file['hashtags_text'][line] = str(file['hashtags'][line]).split(':')[1].split(',')[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.drop('entities',axis=1,inplace=True)\n",
    "file.drop('hashtags',axis=1,inplace=True)\n",
    "file['hashtags_text'] = str(file['hashtags_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-41017ebae16a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Creem variable numerica amb l'hora del tweet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfile\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hour'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnuml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mfile\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hour'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'created_at'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Creem variable numerica amb l'hora del tweet\n",
    "file['hour'] = np.zeros(numl)\n",
    "for i in range(len(file)):\n",
    "    file['hour'][i] = int(file['created_at'][i][11:13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(file.head())\n",
    "file.to_csv('temporal1_tweet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import nltk\n",
    "import re\n",
    "from unicodedata import normalize\n",
    "\n",
    "file = pd.read_csv(\"temporal1_tweet.csv\")\n",
    "#file['hashtags_text'] = str(file['hashtags_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituim per 0 els registres amb NaNs\n",
    "\n",
    "file[file[\"trending_topic\"].isnull()]\n",
    "#file= file.drop(file[file[\"trending_topic\"].isnull()].index,axis= 0) \n",
    "file = file.fillna(value={\"trending_topic\":0}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "elim = pd.read_excel('eliminar_paraules.xlsx', header=None)\n",
    "y=elim[0]\n",
    "for i in range(len(elim)):\n",
    "    y[i] = re.sub(\n",
    "            r\"([^n\\u0300-\\u036f]|n(?!\\u0303(?![\\u0300-\\u036f])))[\\u0300-\\u036f]+\", r\"\\1\", \n",
    "            normalize( \"NFD\", y[i]), 0, re.I)\n",
    "y = y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    18\n",
      "1     0\n",
      "2     4\n",
      "3    21\n",
      "4     0\n",
      "Name: FC, dtype: int64\n",
      "0    4\n",
      "1    0\n",
      "2    2\n",
      "3    6\n",
      "4    0\n",
      "Name: RT, dtype: int64\n",
      "   0  1  2  3  4  5  6  7  8  9       ...        58  59  60  61  62  63  64  \\\n",
      "0  0  0  0  0  0  0  0  0  0  0       ...         1   1   1   1   8   1   1   \n",
      "1  0  0  0  0  0  0  0  0  0  0       ...         1   1   1   1   8   1   1   \n",
      "2  0  0  1  0  0  0  0  0  0  0       ...         1   1   1   1   8   1   1   \n",
      "3  0  0  0  0  0  0  0  0  0  0       ...         1   1   1   1   8   1   1   \n",
      "4  0  0  1  0  0  0  0  0  0  0       ...         1   1   1   1   8   1   1   \n",
      "\n",
      "   hour  followers_user  trending_topic  \n",
      "0  15.0            7162             0.0  \n",
      "1   3.0             531             0.0  \n",
      "2  15.0            7162             0.0  \n",
      "3  15.0            7162             0.0  \n",
      "4  15.0            7162             0.0  \n",
      "\n",
      "[5 rows x 3970 columns]\n"
     ]
    }
   ],
   "source": [
    "# Treballem amb una mostra per agilitzar els calculs\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer = CountVectorizer(min_df=0.0001,                            \n",
    " stop_words=y, \n",
    " strip_accents='unicode')\n",
    "X_1 = vectorizer.fit_transform(file['Tweet'])\n",
    "X_1 = pd.DataFrame(X_1.todense())\n",
    "X_2 = vectorizer.fit_transform(file['hashtags_text'])\n",
    "X_2 = pd.DataFrame(X_2.todense())\n",
    "X_3 = file[['hour', 'followers_user', 'trending_topic']]\n",
    "\n",
    "X = pd.concat([X_1, X_2, X_3], axis=1)\n",
    "\n",
    "y_fc = file['FC']\n",
    "y_rt = file['RT']\n",
    "\n",
    "print(y_fc.head())\n",
    "print(y_rt.head())\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4289, 3970)\n",
      "(4289,)\n",
      "(4289,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y_rt.shape)\n",
    "print(y_fc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv('X_tweet_nuria.csv')\n",
    "y_fc.to_csv('y_fc_tweet_nuria.csv', index = None)\n",
    "y_rt.to_csv('y_rt_tweet_nuria.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nuria\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "X_train_fc, X_test_fc, y_train_fc, y_test_fc = model_selection.train_test_split(X, y_fc, train_size = 0.7, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification accuracy: 0.46386946386946387\n"
     ]
    }
   ],
   "source": [
    "# Let us tokenize the data\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "nb = BernoulliNB()\n",
    "nb.fit(X_train_fc,y_train_fc)\n",
    "\n",
    "y_hat_fc = nb.predict(X_test_fc)\n",
    "from sklearn import metrics   \n",
    "    \n",
    "print (\"classification accuracy:\", metrics.accuracy_score(y_hat_fc, y_test_fc))\n",
    "#print (\"Classification Report:\")\n",
    "#print (metrics.classification_report(y_hat_fc,np.array(y_test_fc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification accuracy: 0.4794094794094794\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors = 10)\n",
    "clf.fit(X_train_fc, y_train_fc)\n",
    "y_hat_fc = clf.predict(X_test_fc)\n",
    "print (\"classification accuracy:\", metrics.accuracy_score(y_hat_fc, y_test_fc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification accuracy: 0.4716394716394716\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "clf = RandomForestClassifier(n_estimators = 11)\n",
    "\n",
    "clf.fit(X_train_fc,y_train_fc)\n",
    "    \n",
    "y_hat_fc = clf.predict(X_test_fc)\n",
    "print (\"classification accuracy:\", metrics.accuracy_score(y_hat_fc, y_test_fc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification accuracy: 0.4755244755244755\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors, linear_model, ensemble, svm, model_selection\n",
    "clf = svm.LinearSVC()\n",
    "clf.fit(X_train_fc,y_train_fc)\n",
    "    \n",
    "y_hat_fc = clf.predict(X_test_fc)\n",
    "print (\"classification accuracy:\", metrics.accuracy_score(y_hat_fc, y_test_fc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification accuracy: 0.47785547785547783\n"
     ]
    }
   ],
   "source": [
    "clf = linear_model.LogisticRegression()\n",
    "clf.fit(X_train_fc,y_train_fc)\n",
    "    \n",
    "y_hat_fc = clf.predict(X_test_fc)\n",
    "print (\"classification accuracy:\", metrics.accuracy_score(y_hat_fc, y_test_fc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification accuracy: 0.48484848484848486\n"
     ]
    }
   ],
   "source": [
    "clf = neighbors.KNeighborsClassifier(n_neighbors = 12)\n",
    "clf.fit(X_train_fc, y_train_fc)\n",
    "y_hat_fc = clf.predict(X_test_fc)\n",
    "print (\"classification accuracy:\", metrics.accuracy_score(y_hat_fc, y_test_fc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nuria\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification accuracy: 0.7832167832167832\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train_rt, X_test_rt, y_train_rt, y_test_rt = model_selection.train_test_split(X, y_rt, train_size = 0.7, random_state = 42)\n",
    "nb = BernoulliNB()\n",
    "nb.fit(X_train_rt,y_train_rt)\n",
    "\n",
    "y_hat_rt = nb.predict(X_test_rt)\n",
    "from sklearn import metrics   \n",
    "    \n",
    "print (\"classification accuracy:\", metrics.accuracy_score(y_hat_rt, y_test_rt))\n",
    "#print (\"Classification Report:\")\n",
    "#print (metrics.classification_report(y_hat_rt,np.array(y_test_rt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification accuracy: 0.7902097902097902\n"
     ]
    }
   ],
   "source": [
    "clf = neighbors.KNeighborsClassifier(n_neighbors = 10)\n",
    "clf.fit(X_train_rt,y_train_rt)\n",
    "\n",
    "y_hat_rt = clf.predict(X_test_rt)\n",
    "print (\"classification accuracy:\", metrics.accuracy_score(y_hat_rt, y_test_rt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification accuracy: 0.7746697746697747\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators = 11)\n",
    "clf.fit(X_train_rt,y_train_rt)\n",
    "\n",
    "y_hat_rt = clf.predict(X_test_rt)\n",
    "print (\"classification accuracy:\", metrics.accuracy_score(y_hat_rt, y_test_rt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification accuracy: 0.6993006993006993\n"
     ]
    }
   ],
   "source": [
    "clf = svm.LinearSVC()\n",
    "clf.fit(X_train_rt,y_train_rt)\n",
    "\n",
    "y_hat_rt = clf.predict(X_test_rt)\n",
    "print (\"classification accuracy:\", metrics.accuracy_score(y_hat_rt, y_test_rt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification accuracy: 0.7832167832167832\n"
     ]
    }
   ],
   "source": [
    "clf = linear_model.LogisticRegression()\n",
    "clf.fit(X_train_rt,y_train_rt)\n",
    "\n",
    "y_hat_rt = clf.predict(X_test_rt)\n",
    "print (\"classification accuracy:\", metrics.accuracy_score(y_hat_rt, y_test_rt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification accuracy: 0.7855477855477856\n"
     ]
    }
   ],
   "source": [
    "clf = neighbors.KNeighborsClassifier(n_neighbors = 9)\n",
    "clf.fit(X_train_rt,y_train_rt)\n",
    "\n",
    "y_hat_rt = clf.predict(X_test_rt)\n",
    "print (\"classification accuracy:\", metrics.accuracy_score(y_hat_rt, y_test_rt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification accuracy: 0.7917637917637917\n"
     ]
    }
   ],
   "source": [
    "clf = neighbors.KNeighborsClassifier(n_neighbors = 12)\n",
    "clf.fit(X_train_rt,y_train_rt)\n",
    "\n",
    "y_hat_rt = clf.predict(X_test_rt)\n",
    "print (\"classification accuracy:\", metrics.accuracy_score(y_hat_rt, y_test_rt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
